# Docker Swarm Stack for Distributed Data Miner
# Auto-generated from cluster.yaml
#
# Deployment:
#   1. Initialize swarm on master: docker swarm init --advertise-addr MASTER_IP
#   2. Join workers: docker swarm join --token TOKEN MASTER_IP:2377
#   3. Deploy: docker stack deploy -c docker-compose.swarm.yml dm
#   4. Scale: docker service scale dm_download=N

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: data_miner
    volumes:
    - ../data/postgres:/var/lib/postgresql/data
    healthcheck:
      test:
      - CMD-SHELL
      - pg_isready -U postgres -d data_miner
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
      restart_policy:
        condition: on-failure
  seaweed-master:
    image: chrislusf/seaweedfs
    command: master -ip=seaweed-master -defaultReplication=000 -volumeSizeLimitMB=1000
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
      restart_policy:
        condition: on-failure
  seaweed-filer:
    image: chrislusf/seaweedfs
    command: filer -master=seaweed-master:9333
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
      restart_policy:
        condition: on-failure
  seaweed-volume:
    image: chrislusf/seaweedfs
    command: volume -mserver=seaweed-master:9333 -dir=/data/seaweed -max=100
    volumes:
    - /data/seaweed:/data/seaweed
    networks:
    - dm-network
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
  seaweed-mount:
    image: chrislusf/seaweedfs
    command: mount -filer=seaweed-filer:8888 -dir=/mnt/swdshared -filer.path=/
    privileged: true
    devices:
    - /dev/fuse
    cap_add:
    - SYS_ADMIN
    volumes:
    - shared-data:/mnt/swdshared:shared
    networks:
    - dm-network
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
  download:
    environment:
      DATA_MINER_CONFIG: /app/config.yaml
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/data_miner
    volumes:
    - shared-data:/mnt/swdshared:shared
    image: ${REGISTRY:-localhost:5000}/data-miner:${TAG:-latest}
    configs:
    - source: worker-config
      target: /app/config.yaml
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: '10'
      placement:
        constraints:
        - node.role == worker
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 2G
  master-workers:
    environment:
      DATA_MINER_CONFIG: /app/config.yaml
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/data_miner
    volumes:
    - shared-data:/mnt/swdshared:shared
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities:
            - gpu
          generic_resources:
          - discrete_resource_spec:
              kind: gpu
              value: 1
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
      restart_policy:
        condition: on-failure
    image: ${REGISTRY:-localhost:5000}/data-miner:${TAG:-latest}
    configs:
    - source: master-config
      target: /app/config.yaml
    networks:
    - dm-network
  grafana:
    image: grafana/grafana:10.0.0
    ports:
    - 3000:3000
    volumes:
    - ../data/grafana:/var/lib/grafana
    environment:
      GF_AUTH_ANONYMOUS_ENABLED: 'true'
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
  loki:
    image: grafana/loki:2.9.0
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
    - ../data/loki:/loki
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
  adminer:
    image: adminer
    ports:
    - 8880:8080
    networks:
    - dm-network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
        - node.role == manager
volumes:
  shared-data: null
networks:
  dm-network:
    driver: overlay
    attachable: true
configs:
  master-config:
    file: ./master.yaml
  worker-config:
    file: ./worker.yaml
