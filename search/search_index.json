{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Data Miner","text":"<p>A PostgreSQL-backed, supervisor-managed video processing pipeline for generating large-scale computer vision datasets from YouTube videos.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd0d YouTube Search - Find videos by keywords and hashtags</li> <li>\ud83d\udce5 Smart Downloads - Rate-limited downloading with hashtag blocklists</li> <li>\ud83c\udfac Frame Extraction - Configurable sampling strategies (interval, time, keyframe)</li> <li>\ud83c\udfaf ML Filtering - SigLIP2-based image-text similarity filtering</li> <li>\ud83d\udd04 Deduplication - DINOv3/FAISS-based cross-video deduplication</li> <li>\ud83c\udfaf Object Detection - Open-set detection (GroundingDINO, OWLv2)</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"User Guide Developer Docs Installation Architecture Overview Configuration Database Models CLI Reference Worker System Quickstart Contributing"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart LR\n    subgraph Central[\"Central Pipeline\"]\n        D[Download] --&gt; E[Extract]\n    end\n\n    subgraph Project[\"Per-Project Pipeline\"]\n        F[Filter] --&gt; DU[Cross-Dedup] --&gt; DT[Detect]\n    end\n\n    E --&gt; F</code></pre> <p>The pipeline uses:</p> <ul> <li>PostgreSQL for state management with row-level locking</li> <li>Supervisor for worker process management</li> <li>Heartbeat-based locking for concurrent safety</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<pre><code># Install\npip install -e .\n\n# Initialize database\ndata-miner init-db\n\n# Add videos and run pipeline\ndata-miner populate --config config.yaml\ndata-miner workers setup --config config.yaml\ndata-miner workers start\n</code></pre> <p>See Quickstart for the complete workflow.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 cli.py              # CLI commands\n\u251c\u2500\u2500 config/             # Configuration system\n\u251c\u2500\u2500 db/                 # Database layer\n\u251c\u2500\u2500 workers/            # Supervisor-managed workers\n\u251c\u2500\u2500 modules/            # Core processing logic\n\u251c\u2500\u2500 models/             # ML model wrappers\n\u2514\u2500\u2500 utils/              # Utilities\n</code></pre>"},{"location":"architecture/database-models/","title":"Database Models","text":"<p>Data Miner uses SQLModel (Pydantic + SQLAlchemy) with PostgreSQL.</p>"},{"location":"architecture/database-models/#entity-relationship","title":"Entity Relationship","text":"<pre><code>erDiagram\n    PROJECT ||--o{ PROJECT_VIDEO : has\n    VIDEO ||--o{ PROJECT_VIDEO : referenced_by\n\n    PROJECT {\n        int project_id PK\n        string name UK\n        ProjectStatus project_stage\n        int total_videos\n        int videos_downloaded\n        int videos_extracted\n        int extracted_frames\n        int filtered_frames\n    }\n\n    VIDEO {\n        string video_id PK\n        string url\n        VideoStatus status\n        string video_path\n        string frames_dir\n        int frame_count\n    }\n\n    PROJECT_VIDEO {\n        int id PK\n        int project_id FK\n        string video_id FK\n        ProjectVideoStatus status\n        string filtered_dir\n        int passed_frames\n    }</code></pre>"},{"location":"architecture/database-models/#tables","title":"Tables","text":""},{"location":"architecture/database-models/#project","title":"Project","text":"<p>Tracks project-level state and cross-video operations.</p> Column Type Description <code>project_id</code> int Primary key <code>name</code> str Unique project name <code>project_stage</code> ProjectStatus Current stage <code>total_videos</code> int Total videos in project <code>videos_pending</code> int Videos pending download <code>videos_downloaded</code> int Videos downloaded (cumulative, includes extracted) <code>videos_extracted</code> int Videos with frames extracted <code>videos_failed</code> int Failed videos <code>extracted_frames</code> int Total frames extracted <code>filtered_frames</code> int Total frames passed filter <code>unique_frames</code> int Frames after dedup <code>dedup_dir</code> str Dedup output directory <code>detect_dir</code> str Detection output directory <p>Note: Video counts are cumulative where appropriate. <code>videos_downloaded</code> includes extracted videos.</p>"},{"location":"architecture/database-models/#video","title":"Video","text":"<p>Central video table, shared across projects. Tracks download and extraction.</p> Column Type Description <code>video_id</code> str YouTube video ID (PK) <code>url</code> str Full YouTube URL <code>source_type</code> SourceType <code>SEARCH</code>, <code>URL</code>, <code>FILE</code>, <code>MANUAL</code> <code>source_info</code> str Search query or filename <code>video_path</code> str Downloaded video path <code>frames_dir</code> str Extracted frames directory <code>frame_count</code> int Number of extracted frames <code>status</code> VideoStatus Current status <code>locked_by</code> str Worker ID holding lock <code>heartbeat_at</code> datetime Last heartbeat timestamp"},{"location":"architecture/database-models/#projectvideo","title":"ProjectVideo","text":"<p>Links videos to projects with project-specific processing state.</p> Column Type Description <code>id</code> int Primary key <code>project_id</code> int FK to projects <code>video_id</code> str FK to videos <code>filtered_dir</code> str Filtered frames directory <code>passed_frames</code> int Frames that passed filter <code>status</code> ProjectVideoStatus Current status <code>locked_by</code> str Worker ID holding lock <code>heartbeat_at</code> datetime Last heartbeat timestamp"},{"location":"architecture/database-models/#status-enums","title":"Status Enums","text":""},{"location":"architecture/database-models/#videostatus-central-stages","title":"VideoStatus (Central Stages)","text":"Status Description <code>PENDING</code> Ready for download <code>DOWNLOADING</code> Download in progress <code>DOWNLOADED</code> Download complete <code>EXTRACTING</code> Extraction in progress <code>EXTRACTED</code> Extraction complete <code>FAILED</code> Processing failed"},{"location":"architecture/database-models/#projectvideostatus-per-project-stages","title":"ProjectVideoStatus (Per-Project Stages)","text":"Status Description <code>PENDING</code> Ready for filtering <code>FILTERING</code> Filter in progress <code>FILTERED</code> Filtered with frames <code>FILTERED_EMPTY</code> Filtered, no frames passed <code>FAILED</code> Processing failed"},{"location":"architecture/database-models/#projectstatus-project-level","title":"ProjectStatus (Project-Level)","text":"Status Description <code>POPULATING</code> Videos being added <code>FILTERING</code> Filter workers active <code>DEDUP_READY</code> Ready for cross-dedup <code>DEDUPING</code> Cross-dedup in progress <code>DETECT_READY</code> Ready for detection <code>DETECTING</code> Detection in progress <code>COMPLETE</code> Pipeline finished"},{"location":"architecture/database-models/#concurrency-control","title":"Concurrency Control","text":"<p>All workers use row-level locking with heartbeats:</p> <pre><code># Claim pattern with FOR UPDATE SKIP LOCKED\nstmt = (\n    select(Video)\n    .where(Video.status == status)\n    .with_for_update(skip_locked=True)\n    .limit(1)\n)\n</code></pre> <p>Heartbeat Recovery: Workers update <code>heartbeat_at</code> every 30 seconds. The monitor worker resets locks older than <code>stale_threshold_minutes</code>.</p>"},{"location":"architecture/database-models/#related-docs","title":"Related Docs","text":"<ul> <li>Workers - Worker system architecture</li> <li>Architecture Overview - Full system design</li> </ul>"},{"location":"architecture/overview/","title":"Data Miner - Architecture &amp; Code Walkthrough","text":"<p>A comprehensive guide to the architecture, design decisions, and code flow of Data Miner, a production-grade video mining pipeline for generating large-scale computer vision datasets from YouTube.</p>"},{"location":"architecture/overview/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Executive Summary</li> <li>Architecture Overview</li> <li>Project Structure</li> <li>Database Architecture</li> <li>Worker System</li> <li>Processing Modules</li> <li>ML Model Wrappers</li> <li>Configuration System</li> <li>CLI Interface</li> <li>Data Flow</li> <li>Comparison with Earlier Versions</li> <li>Appendix A: Earlier Versions</li> </ol>"},{"location":"architecture/overview/#executive-summary","title":"Executive Summary","text":"<p>Data Miner is a PostgreSQL-backed, supervisor-managed video processing pipeline designed to:</p> <ul> <li>Search YouTube for videos by keywords/hashtags</li> <li>Download highest quality videos with rate limiting</li> <li>Extract frames using configurable sampling strategies</li> <li>Filter frames using SigLIP2 image-text similarity</li> <li>Deduplicate frames using DINOv3/SigLIP2 embeddings with FAISS</li> <li>Detect objects using open-set detection models (GroundingDINO, OWLv2)</li> </ul>"},{"location":"architecture/overview/#key-design-decisions","title":"Key Design Decisions","text":"Aspect Current Design Rationale State Management PostgreSQL with SQLModel ACID guarantees, concurrent access, query flexibility Worker Model Long-running supervisor processes Automatic restart, centralized logging, process isolation Concurrency Row-level locking with heartbeats Prevents stale locks, supports worker crashes Processing Scope Central (Video) + Per-Project (ProjectVideo) Reuse downloads across projects, project-specific filtering Configuration OmegaConf + Pydantic YAML merging, validation, type safety"},{"location":"architecture/overview/#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart TB\n    subgraph CLI[\"CLI (cli.py)\"]\n        POPULATE[populate]\n        STATUS[status]\n        WORKERS[workers]\n    end\n\n    subgraph Database[\"PostgreSQL\"]\n        PROJ[(projects)]\n        VID[(videos)]\n        PV[(project_videos)]\n    end\n\n    subgraph Workers[\"Supervisor-Managed Workers\"]\n        DW[Download Worker]\n        EW[Extract Worker]\n        FW[Filter Worker]\n        CDW[Cross-Dedup Worker]\n        DTW[Detect Worker]\n        MON[Monitor Worker]\n        BKP[Backup Worker]\n    end\n\n    subgraph Modules[\"Processing Modules\"]\n        DOWN[downloader.py]\n        EXT[frame_extractor.py]\n        FILT[frame_filter.py]\n        DEDUP[deduplicator.py]\n        DET[detector.py]\n    end\n\n    subgraph Models[\"ML Models\"]\n        SIGLIP[SigLIPModel]\n        DINO[DINOv3Model]\n        GRDINO[GroundingDINO]\n    end\n\n    CLI --&gt; Database\n    Workers --&gt; Database\n    DW --&gt; DOWN\n    EW --&gt; EXT\n    FW --&gt; FILT\n    CDW --&gt; DEDUP\n    DTW --&gt; DET\n    FILT --&gt; SIGLIP\n    DEDUP --&gt; DINO\n    DET --&gt; GRDINO</code></pre>"},{"location":"architecture/overview/#processing-pipeline","title":"Processing Pipeline","text":"<pre><code>flowchart LR\n    subgraph Central[\"Central Pipeline (Video table)\"]\n        direction LR\n        D[Download] --&gt; E[Extract]\n    end\n\n    subgraph Project[\"Per-Project Pipeline (ProjectVideo table)\"]\n        direction LR\n        F[Filter] --&gt; DU[Cross-Dedup] --&gt; DT[Detect]\n    end\n\n    style Central fill:#e1f5fe\n    style Project fill:#f3e5f5\n\n    E --&gt; F</code></pre>"},{"location":"architecture/overview/#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 __init__.py                      # Package init\n\u251c\u2500\u2500 cli.py                           # Click CLI (813 lines)\n\u251c\u2500\u2500 logging.py                       # Loguru + Loki logging\n\u2502\n\u251c\u2500\u2500 config/                          # Configuration system\n\u2502   \u251c\u2500\u2500 __init__.py                  # Exports all config getters\n\u2502   \u251c\u2500\u2500 config.py                    # Pydantic models (161 lines)\n\u2502   \u251c\u2500\u2500 constants.py                 # Enums, model IDs, status maps (162 lines)\n\u2502   \u251c\u2500\u2500 loader.py                    # OmegaConf loader with caching (232 lines)\n\u2502   \u251c\u2500\u2500 default.yaml                 # Default configuration\n\u2502   \u2514\u2500\u2500 blocked_hashtags.txt         # Hashtag blocklist\n\u2502\n\u251c\u2500\u2500 db/                              # Database layer\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 connection.py                # SQLModel engine + session\n\u2502   \u251c\u2500\u2500 models.py                    # Project, Video, ProjectVideo (110 lines)\n\u2502   \u2514\u2500\u2500 operations.py                # CRUD + claim/release functions (962 lines)\n\u2502\n\u251c\u2500\u2500 workers/                         # Long-running worker processes\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py                      # Base worker classes (368 lines)\n\u2502   \u251c\u2500\u2500 download.py                  # Download worker (66 lines)\n\u2502   \u251c\u2500\u2500 extract.py                   # Extraction worker\n\u2502   \u251c\u2500\u2500 filter.py                    # Filter worker (89 lines)\n\u2502   \u251c\u2500\u2500 dedup.py                     # Cross-dedup worker (128 lines)\n\u2502   \u251c\u2500\u2500 detect.py                    # Detection worker (111 lines)\n\u2502   \u251c\u2500\u2500 monitor.py                   # Project monitor (196 lines)\n\u2502   \u2514\u2500\u2500 backup.py                    # Backup worker\n\u2502\n\u251c\u2500\u2500 modules/                         # Core processing logic\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 downloader.py                # yt-dlp wrapper\n\u2502   \u251c\u2500\u2500 frame_extractor.py           # PyAV frame extraction\n\u2502   \u251c\u2500\u2500 frame_filter.py              # SigLIP-based filtering (243 lines)\n\u2502   \u251c\u2500\u2500 deduplicator.py              # FAISS-based dedup (470 lines)\n\u2502   \u2514\u2500\u2500 detector.py                  # Object detection\n\u2502\n\u251c\u2500\u2500 models/                          # ML model wrappers\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py                      # BaseModel abstract class\n\u2502   \u251c\u2500\u2500 siglip_model.py              # SigLIP2 wrapper\n\u2502   \u251c\u2500\u2500 dinov3_model.py              # DINOv3 wrapper\n\u2502   \u2514\u2500\u2500 detector_models.py           # Detection model factory\n\u2502\n\u2514\u2500\u2500 utils/                           # Utility functions\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 device.py                    # CUDA/CPU device management\n    \u251c\u2500\u2500 io.py                        # File I/O utilities\n    \u251c\u2500\u2500 validators.py                # Input validation\n    \u251c\u2500\u2500 query_generator.py           # YouTube query generation\n    \u251c\u2500\u2500 db_helper.py                 # Database utilities\n    \u251c\u2500\u2500 migrate_registry.py          # YAML \u2192 DB migration\n    \u2514\u2500\u2500 ssh_helper.py                # SSH for remote backup\n</code></pre>"},{"location":"architecture/overview/#database-architecture","title":"Database Architecture","text":"<p>The database uses SQLModel (Pydantic + SQLAlchemy) with PostgreSQL.</p>"},{"location":"architecture/overview/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>erDiagram\n    PROJECT ||--o{ PROJECT_VIDEO : has\n    VIDEO ||--o{ PROJECT_VIDEO : referenced_by\n\n    PROJECT {\n        int project_id PK\n        string name UK\n        string output_dir\n        ProjectStatus project_stage\n        int extracted_frames\n        int filtered_frames\n        int unique_frames\n        string dedup_dir\n        string detect_dir\n        datetime created_at\n    }\n\n    VIDEO {\n        string video_id PK\n        string url\n        SourceType source_type\n        string source_info\n        string video_path\n        string frames_dir\n        int frame_count\n        string title\n        VideoStatus status\n        string error\n        string locked_by\n        datetime locked_at\n        datetime heartbeat_at\n        bool backed_up\n        datetime backed_up_at\n        datetime created_at\n        datetime updated_at\n    }\n\n    PROJECT_VIDEO {\n        int id PK\n        int project_id FK\n        string video_id FK\n        string filtered_dir\n        int passed_frames\n        ProjectVideoStatus status\n        string error\n        string locked_by\n        datetime locked_at\n        datetime heartbeat_at\n        datetime created_at\n        datetime updated_at\n    }</code></pre>"},{"location":"architecture/overview/#status-enums","title":"Status Enums","text":""},{"location":"architecture/overview/#videostatus-central-stages","title":"VideoStatus (Central Stages)","text":"Status Description <code>PENDING</code> Ready for download <code>DOWNLOADING</code> Worker is downloading <code>DOWNLOADED</code> Download complete <code>EXTRACTING</code> Worker is extracting frames <code>EXTRACTED</code> Extraction complete <code>FAILED</code> Processing failed"},{"location":"architecture/overview/#projectvideostatus-per-project-filter-stage","title":"ProjectVideoStatus (Per-Project Filter Stage)","text":"Status Description <code>PENDING</code> Ready for filtering <code>FILTERING</code> Worker is filtering <code>FILTERED</code> Filtering complete with frames <code>FILTERED_EMPTY</code> Filtering complete, no frames passed <code>FAILED</code> Processing failed"},{"location":"architecture/overview/#projectstatus-project-level-stages","title":"ProjectStatus (Project-Level Stages)","text":"Status Description <code>POPULATING</code> Videos being added/processed <code>FILTERING</code> Filter workers active <code>DEDUP_READY</code> All videos filtered, ready for cross-dedup <code>DEDUPING</code> Cross-dedup in progress <code>DETECT_READY</code> Cross-dedup done, ready for detection <code>DETECTING</code> Detection in progress <code>COMPLETE</code> Pipeline finished <code>FAILED</code> Pipeline failed"},{"location":"architecture/overview/#key-database-operations","title":"Key Database Operations","text":""},{"location":"architecture/overview/#claimrelease-pattern","title":"Claim/Release Pattern","text":"<p>All workers use atomic <code>FOR UPDATE SKIP LOCKED</code> for concurrent safety:</p> <pre><code># claim_next_video() in operations.py\nstmt = (\n    select(Video)\n    .where(\n        and_(\n            Video.status == status,\n            or_(\n                Video.locked_by.is_(None),\n                Video.heartbeat_at &lt; threshold  # Stale lock recovery\n            )\n        )\n    )\n    .with_for_update(skip_locked=True)\n    .limit(1)\n)\n</code></pre>"},{"location":"architecture/overview/#heartbeat-system","title":"Heartbeat System","text":"<p>Workers update heartbeats every 30 seconds to prove liveness:</p> <pre><code>def update_video_heartbeat(session: Session, video_id: str, worker_id: str) -&gt; bool:\n    \"\"\"Returns False if lock was lost (another worker completed this).\"\"\"\n    video = session.get(Video, video_id)\n    if video.locked_by != worker_id:\n        return False  # Lost lock!\n    video.heartbeat_at = datetime.utcnow()\n    session.commit()\n    return True\n</code></pre>"},{"location":"architecture/overview/#worker-system","title":"Worker System","text":""},{"location":"architecture/overview/#worker-hierarchy","title":"Worker Hierarchy","text":"<pre><code>classDiagram\n    class _BaseWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +stage_name: StageName\n        +poll_interval: float\n        +heartbeat_interval: float\n        +_init_project()\n        +_start_heartbeat(item_id)\n        +_stop_heartbeat()\n        +_heartbeat_loop()*\n        +run()*\n    }\n\n    class BaseVideoWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +input_status()*\n        +in_progress_status()*\n        +output_status()*\n        +process(video: Video)*\n        +run()\n    }\n\n    class BaseProjectVideosWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +input_status()*\n        +in_progress_status()*\n        +output_status()*\n        +process(pv: ProjectVideo, video: Video)*\n        +run()\n    }\n\n    class BaseProjectStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +worker_name: str\n        +claim_project(session)*\n        +process(project: Project)*\n        +complete_project(session, project_id, result)*\n        +fail_project(session, project_id, error)*\n        +run()\n    }\n\n    _BaseWorker &lt;|-- BaseVideoWorker\n    _BaseWorker &lt;|-- BaseProjectVideosWorker\n    _BaseWorker &lt;|-- BaseProjectStageWorker\n\n    BaseVideoWorker &lt;|-- DownloadWorker\n    BaseVideoWorker &lt;|-- ExtractWorker\n    BaseProjectVideosWorker &lt;|-- FilterWorker\n    BaseProjectStageWorker &lt;|-- CrossDedupWorker\n    BaseProjectStageWorker &lt;|-- ProjectDetectWorker</code></pre>"},{"location":"architecture/overview/#worker-types","title":"Worker Types","text":"Worker Base Class Works On Responsibility <code>DownloadWorker</code> <code>BaseVideoWorker</code> Video table Download YouTube videos <code>ExtractWorker</code> <code>BaseVideoWorker</code> Video table Extract frames from videos <code>FilterWorker</code> <code>BaseProjectVideosWorker</code> ProjectVideo table Filter frames with SigLIP2 <code>CrossDedupWorker</code> <code>BaseProjectStageWorker</code> Project level Cross-video deduplication <code>ProjectDetectWorker</code> <code>BaseProjectStageWorker</code> Project level Object detection <code>ProjectMonitorWorker</code> Custom N/A Stage transitions, stale lock recovery <code>BackupWorker</code> Custom Video table rsync backup to remote"},{"location":"architecture/overview/#worker-lifecycle","title":"Worker Lifecycle","text":"<pre><code>sequenceDiagram\n    participant W as Worker\n    participant DB as PostgreSQL\n    participant M as Module\n\n    loop Main Loop\n        W-&gt;&gt;DB: claim_next_video(status, worker_id)\n        alt No work available\n            W-&gt;&gt;W: sleep(poll_interval)\n        else Work claimed\n            W-&gt;&gt;W: _start_heartbeat(video_id)\n            W-&gt;&gt;M: process(video)\n            alt Success\n                W-&gt;&gt;DB: release_video(new_status, **updates)\n            else Failure\n                W-&gt;&gt;DB: mark_video_failed(error)\n            end\n            W-&gt;&gt;W: _stop_heartbeat()\n        end\n    end</code></pre>"},{"location":"architecture/overview/#supervisor-integration","title":"Supervisor Integration","text":"<p>Workers are managed by supervisord:</p> <pre><code>[program:download]\ncommand=/path/to/.venv/bin/python -m data_miner.workers.download --config %(ENV_CONFIG)s\nnumprocs=3\nprocess_name=%(program_name)s_%(process_num)02d\nautorestart=true\nstartsecs=5\nstopwaitsecs=30\n</code></pre> <p>Generated via <code>data-miner workers setup --config path/to/config.yaml</code></p>"},{"location":"architecture/overview/#processing-modules","title":"Processing Modules","text":""},{"location":"architecture/overview/#1-downloader-downloaderpy","title":"1. Downloader (<code>downloader.py</code>)","text":"<p>Downloads YouTube videos using yt-dlp with configurable rate limiting.</p> <p>Key Features:</p> <ul> <li>Format selection (max 1080p by default)</li> <li>Rate limiting (sleep intervals between downloads)</li> <li>Hashtag blocklist filtering</li> <li>Timeout handling</li> </ul> <pre><code>class YouTubeDownloader:\n    def download_single(self, url: str) -&gt; DownloadResult:\n        \"\"\"Download a single video, returns path and metadata.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#2-frame-extractor-frame_extractorpy","title":"2. Frame Extractor (<code>frame_extractor.py</code>)","text":"<p>Extracts frames from videos using PyAV.</p> <p>Sampling Strategies: | Strategy | Description | |----------|-------------| | <code>interval</code> | Every N frames (default: 30) | | <code>time</code> | Every N seconds | | <code>keyframe</code> | Scene change detection |</p>"},{"location":"architecture/overview/#3-frame-filter-frame_filterpy","title":"3. Frame Filter (<code>frame_filter.py</code>)","text":"<p>Filters frames based on SigLIP2 image-text similarity.</p> <p>Two Modes:</p> <ol> <li>Positive-only: Frame passes if <code>max(positive_scores) &gt; threshold</code></li> <li>Positive + Negative: Also requires <code>max(positive) - max(negative) &gt; margin</code></li> </ol> <pre><code>class FrameFilter:\n    def filter_frames(\n        self,\n        frame_paths: list[Path],\n        video_id: str = \"unknown\",\n    ) -&gt; FilterResult:\n        \"\"\"\n        Filter frames based on similarity to text prompts.\n        Returns FilterResult with passing frames.\n        \"\"\"\n</code></pre>"},{"location":"architecture/overview/#4-deduplicator-deduplicatorpy","title":"4. Deduplicator (<code>deduplicator.py</code>)","text":"<p>Removes duplicate frames using embedding-based similarity with FAISS.</p> <p>Two-Phase Algorithm:</p> <ol> <li>Phase 1 - Per-Video: Remove temporal duplicates within each video using greedy selection</li> <li>Phase 2 - Cross-Video: Use FAISS ANN search to find and remove duplicates across all videos</li> </ol> <pre><code>flowchart LR\n    subgraph Phase1[\"Phase 1: Per-Video\"]\n        A[Embeddings] --&gt; B[Cosine Similarity]\n        B --&gt; C[Greedy Selection]\n    end\n\n    subgraph Phase2[\"Phase 2: Cross-Video\"]\n        C --&gt; D[FAISS Index]\n        D --&gt; E[KNN Search]\n        E --&gt; F[Union-Find Merge]\n    end\n\n    F --&gt; G[Unique Frames]</code></pre> <p>Supported Models:</p> <ul> <li>DINOv3 (default): Best quality embeddings</li> <li>SigLIP2: Memory-efficient, reuses filter model</li> </ul>"},{"location":"architecture/overview/#5-detector-detectorpy","title":"5. Detector (<code>detector.py</code>)","text":"<p>Runs open-set object detection on frames.</p> <p>Supported Detectors: | Detector | Model | Notes | |----------|-------|-------| | GroundingDINO | <code>IDEA-Research/grounding-dino-base</code> | Text-guided detection | | OWLv2 | <code>google/owlv2-base-patch16-ensemble</code> | Open-vocabulary |</p>"},{"location":"architecture/overview/#ml-model-wrappers","title":"ML Model Wrappers","text":""},{"location":"architecture/overview/#base-model-pattern","title":"Base Model Pattern","text":"<p>All ML models follow a consistent pattern:</p> <pre><code>class BaseModel(ABC):\n    def __init__(self):\n        self.model = None\n        self.processor = None\n        self._loaded = False\n\n    @abstractmethod\n    def load(self) -&gt; None:\n        \"\"\"Load model to device.\"\"\"\n\n    def unload(self) -&gt; None:\n        \"\"\"Free GPU memory.\"\"\"\n        del self.model, self.processor\n        torch.cuda.empty_cache()\n\n    def __enter__(self): self.load(); return self\n    def __exit__(self, *args): self.unload()\n</code></pre>"},{"location":"architecture/overview/#siglipmodel-siglip_modelpy","title":"SigLIPModel (<code>siglip_model.py</code>)","text":"<p>Wrapper for Google's SigLIP2 for image-text similarity:</p> <pre><code>class SigLIPModel(BaseModel):\n    def compute_similarity(\n        self, \n        images: list, \n        texts: list[str], \n        batch_size: int = 16\n    ) -&gt; np.ndarray:\n        \"\"\"Returns (N_images, N_texts) similarity matrix.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#dinov3model-dinov3_modelpy","title":"DINOv3Model (<code>dinov3_model.py</code>)","text":"<p>Wrapper for Meta's DINOv3/DINOv2 for image embeddings:</p> <pre><code>class DINOv3Model(BaseModel):\n    def get_embeddings(\n        self, \n        images: list, \n        batch_size: int = 32, \n        normalize: bool = True\n    ) -&gt; np.ndarray:\n        \"\"\"Returns (N_images, embedding_dim) array.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#configuration-system","title":"Configuration System","text":""},{"location":"architecture/overview/#architecture","title":"Architecture","text":"<pre><code>flowchart LR\n    A[default.yaml] --&gt; C[OmegaConf Merge]\n    B[user.yaml] --&gt; C\n    C --&gt; D[lru_cache]\n    D --&gt; E[\"get_*_config()\"]\n    E --&gt; F[Pydantic Model]</code></pre>"},{"location":"architecture/overview/#pydantic-config-models","title":"Pydantic Config Models","text":"Config Key Fields <code>DownloadConfig</code> <code>output_dir</code>, <code>format</code>, <code>max_resolution</code>, <code>sleep_interval</code>, <code>blocked_hashtag_patterns</code> <code>ExtractionConfig</code> <code>output_dir</code>, <code>strategy</code>, <code>interval_frames</code>, <code>max_frames_per_video</code> <code>FilterConfig</code> <code>output_dir</code>, <code>model_id</code>, <code>positive_prompts</code>, <code>negative_prompts</code>, <code>threshold</code>, <code>margin_threshold</code> <code>DeduplicationConfig</code> <code>output_dir</code>, <code>model_type</code>, <code>dino_model_id</code>, <code>threshold</code>, <code>k_neighbors</code> <code>DetectionConfig</code> <code>output_dir</code>, <code>detector</code>, <code>confidence_threshold</code>, <code>save_visualizations</code> <code>DatabaseConfig</code> <code>url</code> <code>SupervisorConfig</code> <code>download_workers</code>, <code>extract_workers</code>, <code>filter_workers</code>, <code>dedup_workers</code>, <code>detect_workers</code> <code>MonitorConfig</code> <code>poll_interval</code>, <code>stale_threshold_minutes</code>, <code>cleanup_extracted_videos</code> <code>BackupConfig</code> <code>enabled</code>, <code>remote_dest</code>, <code>delete_after_backup</code>"},{"location":"architecture/overview/#config-loading","title":"Config Loading","text":"<pre><code>from data_miner.config import get_filter_config, get_download_config\n\n# Automatically loads from DATA_MINER_CONFIG env var or default.yaml\nconfig = get_filter_config()\nprint(config.positive_prompts)  # Type-safe access\n</code></pre>"},{"location":"architecture/overview/#cli-interface","title":"CLI Interface","text":"<p>Built with Click, the CLI provides commands for:</p>"},{"location":"architecture/overview/#core-commands","title":"Core Commands","text":"Command Description <code>init-db</code> Initialize database tables <code>populate</code> Add videos from config sources (search, URLs, files) <code>status</code> Show pipeline status <code>add-video</code> Add a single video URL"},{"location":"architecture/overview/#worker-management","title":"Worker Management","text":"Command Description <code>workers setup</code> Generate supervisor config <code>workers start</code> Start all workers <code>workers stop</code> Stop all workers <code>workers restart</code> Restart all workers <code>workers status</code> Show worker status"},{"location":"architecture/overview/#maintenance","title":"Maintenance","text":"Command Description <code>delete-project</code> Delete project and optionally files <code>delete-videos</code> Delete videos with filters <code>cleanup-orphans</code> Remove orphaned videos <code>force-dedup</code> Re-run cross-dedup for project <code>force-detect</code> Re-run detection for project"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>flowchart TB\n    subgraph Input[\"Input Sources\"]\n        YAML[Config YAML] --&gt; POP[populate command]\n        SEARCH[YouTube Search] --&gt; POP\n        URLS[URL Files] --&gt; POP\n    end\n\n    subgraph Central[\"Central Processing\"]\n        POP --&gt; VID[(Video Table)]\n        VID --&gt; DL[Download Worker]\n        DL --&gt; EX[Extract Worker]\n        EX --&gt; VID2[(Video: EXTRACTED)]\n    end\n\n    subgraph Project[\"Per-Project Processing\"]\n        VID2 --&gt; PV[(ProjectVideo Table)]\n        PV --&gt; FIL[Filter Worker]\n        FIL --&gt; PV2[(ProjectVideo: FILTERED)]\n        PV2 --&gt; MON[Monitor: DEDUP_READY]\n        MON --&gt; DEDUP[Cross-Dedup Worker]\n        DEDUP --&gt; DET[Detect Worker]\n    end\n\n    subgraph Output[\"Outputs\"]\n        DL --&gt; VIDS[videos/]\n        EX --&gt; RAW[frames_raw/]\n        FIL --&gt; FILT[frames_filtered/]\n        DEDUP --&gt; UNIQ[frames_dedup/]\n        DET --&gt; ANN[detections/annotations.json]\n    end</code></pre>"},{"location":"architecture/overview/#output-directory-structure","title":"Output Directory Structure","text":"<pre><code>output/\n\u251c\u2500\u2500 videos/                    # Downloaded videos (optional deletion)\n\u2502   \u2514\u2500\u2500 {video_id}.mp4\n\u251c\u2500\u2500 frames_raw/{video_id}/     # All extracted frames\n\u2502   \u2514\u2500\u2500 frame_{N:05d}.jpg\n\u251c\u2500\u2500 frames_filtered/{video_id}/ # Frames passing filter\n\u2502   \u2514\u2500\u2500 frame_{N:05d}.jpg\n\u251c\u2500\u2500 frames_dedup/              # Unique frames (flat)\n\u2502   \u2514\u2500\u2500 {video_id}_frame_{N:05d}.jpg\n\u2514\u2500\u2500 detections/\n    \u251c\u2500\u2500 annotations.json       # COCO-format annotations\n    \u2514\u2500\u2500 visualizations/        # Bounding box images\n</code></pre>"},{"location":"architecture/overview/#comparison-with-earlier-versions","title":"Comparison with Earlier Versions","text":""},{"location":"architecture/overview/#key-differences-current-vs-v3-earlier","title":"Key Differences: Current vs V3 (Earlier)","text":"Aspect Current Version V3 (Earlier) State Storage PostgreSQL database YAML file (<code>video_registry.yaml</code>) Worker Model Supervisor-managed long-running processes Single CLI command with sequential stages Concurrency Row-level locking with heartbeats Thread locks in-memory Multi-Project Native support (ProjectVideo table) Single registry per run Scalability Horizontal (multiple workers) Vertical (single machine) Fault Tolerance Worker restart, stale lock recovery Manual restart required Config OmegaConf with caching OmegaConf without caching Status Tracking Database queries YAML file reads"},{"location":"architecture/overview/#architecture-evolution","title":"Architecture Evolution","text":"<pre><code>timeline\n    title Data Miner Evolution\n    V3 : File-based registry\n       : Sequential pipeline\n       : Single threaded\n       : CLI-driven execution\n    Current : PostgreSQL backend\n            : Supervisor-managed workers\n            : Concurrent processing\n            : Heartbeat-based locking\n            : Project-level isolation</code></pre>"},{"location":"architecture/overview/#migration-benefits","title":"Migration Benefits","text":"<ol> <li>Reliability: Automatic worker restart on failure</li> <li>Scalability: Multiple workers for each stage</li> <li>Visibility: Database queries for status monitoring</li> <li>Isolation: Per-project filtering without re-downloading</li> <li>Recovery: Stale lock detection and reset</li> </ol>"},{"location":"architecture/overview/#appendix-a-earlier-versions","title":"Appendix A: Earlier Versions","text":""},{"location":"architecture/overview/#v3-architecture-file-based","title":"V3 Architecture (File-Based)","text":"<p>The earlier V3 version used a different architecture:</p>"},{"location":"architecture/overview/#key-components","title":"Key Components","text":"<ol> <li>Video Registry (<code>registry.py</code>): Pydantic-based YAML registry tracking video processing status</li> <li>Pipeline Orchestrator (<code>pipeline.py</code>): Sequential stage execution with lazy model loading</li> <li>CLI Commands: <code>run-config</code>, <code>validate-config</code>, registry management</li> </ol>"},{"location":"architecture/overview/#registry-structure","title":"Registry Structure","text":"<pre><code>metadata:\n  created: \"2024-01-01T00:00:00\"\n  version: \"3.0\"\n\nvideos:\n  dQw4w9WgXcQ:\n    video_id: dQw4w9WgXcQ\n    url: https://youtube.com/watch?v=dQw4w9WgXcQ\n    status: filtered\n    stages:\n      download:\n        completed: true\n        path: output/videos/dQw4w9WgXcQ.mp4\n      extraction:\n        completed: true\n        frame_count: 450\n</code></pre>"},{"location":"architecture/overview/#proposed-async-enhancement","title":"Proposed Async Enhancement","text":"<p>The original async pipeline implementation plan proposed an async evolution:</p> <ul> <li><code>asyncio</code> event loop for orchestration</li> <li><code>ThreadPoolExecutor</code> for blocking operations</li> <li><code>asyncio.Queue</code> for stage communication</li> <li><code>BaseStageWorker</code> abstract class</li> </ul> <p>This design influenced the current worker architecture but was adapted for database-backed state management instead of in-memory queues.</p>"},{"location":"architecture/overview/#parallel-pipeline-options","title":"Parallel Pipeline Options","text":"<p>Two approaches were considered in the parallel pipeline design:</p> <ol> <li>Per-Video Streaming: Each video flows through all stages concurrently</li> <li>Stage-Level Async Queues: Separate workers per stage with folder-based message passing</li> </ol> <p>The current implementation adopted Option 2 (stage-level workers) with database-backed coordination instead of async queues.</p>"},{"location":"architecture/overview/#summary","title":"Summary","text":"<p>Data Miner is a production-grade video mining pipeline featuring:</p> <ul> <li>PostgreSQL-backed state management with SQLModel for type safety</li> <li>Supervisor-managed workers for reliability and scalability</li> <li>Heartbeat-based locking for concurrent worker safety</li> <li>Project-level isolation enabling reuse of downloads across projects</li> <li>Two-phase deduplication with FAISS for O(N log N) scalability</li> <li>Flexible configuration with OmegaConf + Pydantic validation</li> <li>Multiple ML backends for filtering (SigLIP2) and detection (GroundingDINO, OWLv2)</li> </ul>"},{"location":"architecture/workers/","title":"Worker System","text":"<p>Data Miner uses supervisor-managed long-running worker processes.</p>"},{"location":"architecture/workers/#worker-hierarchy","title":"Worker Hierarchy","text":"<pre><code>classDiagram\n    class _BaseWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +stage_name: StageName\n        +poll_interval: float\n        +heartbeat_interval: float\n        +run()*\n    }\n\n    class BaseVideoWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +process(video: Video)*\n    }\n\n    class BaseProjectVideosWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +process(pv: ProjectVideo, video: Video)*\n    }\n\n    class BaseProjectStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +claim_project(session)*\n        +process(project)*\n        +complete_project()*\n    }\n\n    _BaseWorker &lt;|-- BaseVideoWorker\n    _BaseWorker &lt;|-- BaseProjectVideosWorker\n    _BaseWorker &lt;|-- BaseProjectStageWorker\n\n    BaseVideoWorker &lt;|-- DownloadWorker\n    BaseVideoWorker &lt;|-- ExtractWorker\n    BaseProjectVideosWorker &lt;|-- FilterWorker\n    BaseProjectStageWorker &lt;|-- CrossDedupWorker\n    BaseProjectStageWorker &lt;|-- DetectWorker</code></pre>"},{"location":"architecture/workers/#worker-types","title":"Worker Types","text":"Worker Base Class Table Responsibility <code>DownloadWorker</code> <code>BaseVideoWorker</code> Video Download YouTube videos <code>ExtractWorker</code> <code>BaseVideoWorker</code> Video Extract frames <code>FilterWorker</code> <code>BaseProjectVideosWorker</code> ProjectVideo Filter with SigLIP2 <code>CrossDedupWorker</code> <code>BaseProjectStageWorker</code> Project Cross-video dedup <code>DetectWorker</code> <code>BaseProjectStageWorker</code> Project Object detection <code>MonitorWorker</code> Custom \u2014 Stage transitions <code>BackupWorker</code> Custom Video Remote backup"},{"location":"architecture/workers/#worker-lifecycle","title":"Worker Lifecycle","text":"<pre><code>sequenceDiagram\n    participant W as Worker\n    participant DB as PostgreSQL\n    participant M as Module\n\n    loop Main Loop\n        W-&gt;&gt;DB: claim_next_item()\n        alt No work\n            W-&gt;&gt;W: sleep(poll_interval)\n        else Work claimed\n            W-&gt;&gt;W: start_heartbeat()\n            W-&gt;&gt;M: process()\n            W-&gt;&gt;DB: release_item()\n            W-&gt;&gt;W: stop_heartbeat()\n        end\n    end</code></pre>"},{"location":"architecture/workers/#supervisor-configuration","title":"Supervisor Configuration","text":"<p>Workers are managed by supervisord. Generated via:</p> <pre><code>data-miner workers setup --config config.yaml\n</code></pre> <p>Creates <code>/etc/supervisor/conf.d/data_miner.conf</code>:</p> <pre><code>[program:download]\ncommand=/path/.venv/bin/python -m data_miner.workers.download\nnumprocs=3\nprocess_name=%(program_name)s_%(process_num)02d\nautorestart=true\nstartsecs=5\nstopwaitsecs=30\n</code></pre>"},{"location":"architecture/workers/#heartbeat-system","title":"Heartbeat System","text":"<p>Workers update heartbeat timestamps every 30 seconds to prove liveness:</p> <pre><code>def _heartbeat_loop(self):\n    while not self._stop_event.wait(30):\n        with get_session() as session:\n            still_owner = update_heartbeat(session, item_id, worker_id)\n            if not still_owner:\n                os._exit(1)  # Supervisor restarts\n</code></pre> <p>Stale Lock Recovery: The monitor worker resets locks older than <code>stale_threshold_minutes</code>.</p>"},{"location":"architecture/workers/#implementing-custom-workers","title":"Implementing Custom Workers","text":""},{"location":"architecture/workers/#per-video-worker","title":"Per-Video Worker","text":"<pre><code>from data_miner.workers.base import BaseVideoWorker\nfrom data_miner.config import StageName\n\nclass MyWorker(BaseVideoWorker):\n    stage_name = StageName.DOWNLOAD  # Define stage\n\n    def process(self, video: Video) -&gt; dict:\n        # Do work...\n        return {\"video_path\": \"/path/to/video.mp4\"}\n</code></pre>"},{"location":"architecture/workers/#project-level-worker","title":"Project-Level Worker","text":"<pre><code>from data_miner.workers.base import BaseProjectStageWorker\n\nclass MyProjectWorker(BaseProjectStageWorker):\n    worker_name = \"my-stage\"\n\n    def claim_project(self, session):\n        # Claim project with specific status\n        pass\n\n    def process(self, project):\n        # Process entire project\n        return {\"unique_frames\": 500}\n\n    def complete_project(self, session, project_id, result):\n        # Update project status\n        pass\n</code></pre>"},{"location":"architecture/workers/#related-docs","title":"Related Docs","text":"<ul> <li>Database Models - Table schemas</li> <li>Architecture Overview - Full system design</li> </ul>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Guidelines for contributing to Data Miner.</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone and install in dev mode\ngit clone https://github.com/tycoai/data_miner.git\ncd data_miner\npip install -e \".[dev]\"\n\n# Start PostgreSQL\ndocker compose up -d\n\n# Initialize database\ndata-miner init-db\n</code></pre>"},{"location":"development/contributing/#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 cli.py              # Click CLI commands\n\u251c\u2500\u2500 config/             # Pydantic configs + OmegaConf\n\u251c\u2500\u2500 db/                 # SQLModel + PostgreSQL\n\u251c\u2500\u2500 workers/            # Long-running workers\n\u251c\u2500\u2500 modules/            # Core processing logic\n\u251c\u2500\u2500 models/             # ML model wrappers\n\u2514\u2500\u2500 utils/              # Utilities\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<ul> <li>Python 3.12+ features allowed</li> <li>Type hints required for public functions</li> <li>Docstrings for classes and public methods</li> <li>Black for formatting (line length 100)</li> <li>isort for imports</li> </ul>"},{"location":"development/contributing/#adding-a-new-worker","title":"Adding a New Worker","text":"<ol> <li>Create <code>workers/my_worker.py</code></li> <li>Extend appropriate base class:</li> <li><code>BaseVideoWorker</code> for per-video processing</li> <li><code>BaseProjectVideosWorker</code> for per-project-video processing</li> <li> <p><code>BaseProjectStageWorker</code> for project-level operations</p> </li> <li> <p>Implement <code>process()</code> method</p> </li> <li>Add to supervisor config in <code>cli.py</code></li> </ol>"},{"location":"development/contributing/#testing","title":"Testing","text":"<pre><code># Run tests\npytest\n\n# With coverage\npytest --cov=data_miner\n</code></pre>"},{"location":"development/contributing/#database-migrations","title":"Database Migrations","text":"<p>Currently using SQLModel's <code>create_all()</code>. For schema changes:</p> <ol> <li>Update models in <code>db/models.py</code></li> <li>Run <code>data-miner init-db --force</code> (destroys data!)</li> </ol>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make changes with tests</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>Include: - Python version - PostgreSQL version - Config file (anonymized) - Error logs - Steps to reproduce</p>"},{"location":"reference/legacy/","title":"Legacy Documentation","text":"<p>Archived documentation from earlier versions of Data Miner.</p>"},{"location":"reference/legacy/#documents","title":"Documents","text":"<ul> <li>Async Pipeline Implementation Plan - Original async/queue-based design proposal</li> <li>Video Miner V3 Async - V3 async implementation notes</li> <li>Video Miner V3 Code Walkthrough - V3 file-based registry walkthrough</li> </ul> <p>Note: These documents describe earlier versions of the pipeline. The current architecture uses PostgreSQL-backed state management and supervisor-managed workers. See Architecture Overview for current documentation.</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/","title":"Async Pipeline Implementation Design","text":"<p>Goal: Process 1000s of videos efficiently with stage-level parallelism</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#1-concurrency-model-analysis","title":"1. Concurrency Model Analysis","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#comparison-matrix","title":"Comparison Matrix","text":"Aspect <code>asyncio</code> <code>threading</code> <code>multiprocessing</code> GIL Impact N/A (single thread) Blocked for CPU No GIL (separate process) I/O Bound \u2705 Excellent \u2705 Good \u26a0\ufe0f Overkill CPU Bound \u274c Poor \u274c Poor (GIL) \u2705 Excellent GPU Sharing \u2705 Easy (same process) \u2705 Works \u274c Complex (IPC) Memory Low Moderate High (per-process) Queue Overhead Minimal Minimal Serialization cost"},{"location":"reference/legacy/async_pipeline_implementation_plan/#workload-analysis","title":"Workload Analysis","text":"Stage I/O vs CPU Best Fit Download Network I/O <code>asyncio</code> + <code>aiohttp</code> or ThreadPool Extract Disk I/O + CPU decode ThreadPool (PyAV releases GIL) Filter GPU compute ThreadPool (PyTorch releases GIL) Dedup GPU compute ThreadPool Detect GPU compute ThreadPool"},{"location":"reference/legacy/async_pipeline_implementation_plan/#recommendation","title":"Recommendation","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  asyncio Event Loop (Main Orchestrator)                     \u2502\n\u2502  \u251c\u2500\u2500 manages queues and flow control                        \u2502\n\u2502  \u2514\u2500\u2500 spawns ThreadPoolExecutor for blocking operations      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Hybrid approach: <code>asyncio</code> for orchestration + <code>ThreadPoolExecutor</code> for blocking calls.</p> <ul> <li>PyTorch and PyAV release the GIL during heavy computation</li> <li>Keeps GPU in single process (avoids CUDA context issues)</li> <li>Simple queue semantics with <code>asyncio.Queue</code></li> </ul>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#2-queue-communication-analysis","title":"2. Queue Communication Analysis","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#options","title":"Options","text":"Queue Type Pros Cons Best For <code>asyncio.Queue</code> Simple, in-memory Single process only Our use case <code>queue.Queue</code> Thread-safe Blocks event loop Mixed threading <code>multiprocessing.Queue</code> Cross-process Serialization overhead Not needed Redis/RabbitMQ Distributed, persistent External dependency Multi-machine"},{"location":"reference/legacy/async_pipeline_implementation_plan/#message-protocol","title":"Message Protocol","text":"<p>Principle: Pass folder paths (lightweight), not data (heavy).</p> <pre><code>@dataclass\nclass StageMessage:\n    video_id: str\n    input_path: Path      # Folder/file from previous stage\n    metadata: dict        # Optional stage-specific data\n    timestamp: float      # For monitoring latency\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#queue-sizing","title":"Queue Sizing","text":"<pre><code>max_queue_size = 2 \u00d7 num_workers_next_stage\n</code></pre> <p>This provides backpressure without blocking upstream workers.</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#3-architecture-design","title":"3. Architecture Design","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#class-hierarchy-reusable-components","title":"Class Hierarchy (Reusable Components)","text":"<pre><code>classDiagram\n    class BaseStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +input_queue: Queue\n        +output_queue: Queue\n        +executor: ThreadPoolExecutor\n        +shutdown: Event\n        +process(msg: StageMessage)* StageMessage\n        +run_loop()\n        +_run_blocking(func, *args)\n    }\n\n    class DownloadWorker {\n        +downloader: YouTubeDownloader\n        +process(msg) StageMessage\n    }\n\n    class ExtractWorker {\n        +extractor: FrameExtractor\n        +process(msg) StageMessage\n    }\n\n    class FilterWorker {\n        +filter: FrameFilter\n        +process(msg) StageMessage\n    }\n\n    class DedupCollector {\n        +collected: dict\n        +process(msg) StageMessage\n    }\n\n    BaseStageWorker &lt;|-- DownloadWorker\n    BaseStageWorker &lt;|-- ExtractWorker\n    BaseStageWorker &lt;|-- FilterWorker\n    BaseStageWorker &lt;|-- DedupCollector</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#base-worker-pattern","title":"Base Worker Pattern","text":"<pre><code>class BaseStageWorker(ABC):\n    \"\"\"Abstract base for all pipeline stage workers.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        input_queue: asyncio.Queue,\n        output_queue: asyncio.Queue,\n        executor: ThreadPoolExecutor,\n    ):\n        self.name = name\n        self.input_queue = input_queue\n        self.output_queue = output_queue\n        self.executor = executor\n        self.shutdown = asyncio.Event()\n        self.processed_count = 0\n\n    @abstractmethod\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        \"\"\"Process one message. Return None to drop.\"\"\"\n        pass\n\n    async def run_loop(self):\n        \"\"\"Main worker loop - DO NOT OVERRIDE.\"\"\"\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.input_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            try:\n                # Run blocking process() in thread pool\n                result = await self._run_blocking(self.process, msg)\n                if result:\n                    await self.output_queue.put(result)\n                self.processed_count += 1\n            except Exception as e:\n                logger.error(f\"{self.name} failed on {msg.video_id}: {e}\")\n            finally:\n                self.input_queue.task_done()\n\n    async def _run_blocking(self, func, *args):\n        \"\"\"Execute blocking function in thread pool.\"\"\"\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(self.executor, func, *args)\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#pipeline-orchestrator","title":"Pipeline Orchestrator","text":"<pre><code>flowchart TB\n    subgraph Queues\n        Q0[(URL Queue)]\n        Q1[(Download Queue)]\n        Q2[(Extract Queue)]\n        Q3[(Filter Queue)]\n        Q4[(Dedup Collector)]\n    end\n\n    subgraph Workers\n        DW1[Download 1]\n        DW2[Download 2]\n        EW1[Extract 1]\n        EW2[Extract 2]\n        FW[Filter - GPU]\n    end\n\n    Q0 --&gt; DW1 &amp; DW2\n    DW1 &amp; DW2 --&gt; Q1\n    Q1 --&gt; EW1 &amp; EW2\n    EW1 &amp; EW2 --&gt; Q2\n    Q2 --&gt; FW\n    FW --&gt; Q3\n    Q3 --&gt; Q4\n    Q4 --&gt; Dedup[Final Dedup]</code></pre> <pre><code>class AsyncPipelineOrchestrator:\n    \"\"\"Manages all stages and workers.\"\"\"\n\n    def __init__(self, config: PipelineConfig):\n        self.config = config\n\n        # Shared thread pool for blocking ops\n        self.executor = ThreadPoolExecutor(max_workers=8)\n\n        # Queues (sized for backpressure)\n        self.url_queue = asyncio.Queue()\n        self.download_queue = asyncio.Queue(maxsize=4)\n        self.extract_queue = asyncio.Queue(maxsize=4)\n        self.filter_queue = asyncio.Queue(maxsize=2)\n        self.dedup_queue = asyncio.Queue()\n\n        # Workers\n        self.workers = []\n\n    def _create_workers(self):\n        # Download workers (I/O bound, 2-3 concurrent)\n        for i in range(2):\n            self.workers.append(DownloadWorker(\n                name=f\"download-{i}\",\n                input_queue=self.url_queue,\n                output_queue=self.download_queue,\n                executor=self.executor,\n                config=self.config.download,\n            ))\n\n        # Extract workers (CPU bound, 2 concurrent)\n        for i in range(2):\n            self.workers.append(ExtractWorker(\n                name=f\"extract-{i}\",\n                input_queue=self.download_queue,\n                output_queue=self.extract_queue,\n                executor=self.executor,\n                config=self.config.extraction,\n            ))\n\n        # Filter worker (GPU, single to avoid contention)\n        self.workers.append(FilterWorker(\n            name=\"filter-gpu\",\n            input_queue=self.extract_queue,\n            output_queue=self.filter_queue,\n            executor=self.executor,\n            config=self.config.filter,\n        ))\n\n        # Dedup collector (accumulates results)\n        self.dedup_collector = DedupCollector(\n            input_queue=self.filter_queue,\n            output_queue=self.dedup_queue,\n        )\n        self.workers.append(self.dedup_collector)\n\n    async def run(self, urls: list[str]):\n        # Seed URL queue\n        for url in urls:\n            await self.url_queue.put(StageMessage(\n                video_id=get_video_id(url),\n                input_path=url,\n                metadata={},\n                timestamp=time.time(),\n            ))\n\n        # Start all workers\n        self._create_workers()\n        tasks = [asyncio.create_task(w.run_loop()) for w in self.workers]\n\n        # Wait for pipeline to drain\n        await self.url_queue.join()\n        await self.download_queue.join()\n        await self.extract_queue.join()\n        await self.filter_queue.join()\n\n        # Shutdown workers\n        for w in self.workers:\n            w.shutdown.set()\n        await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Final cross-video dedup\n        return await self._run_final_dedup()\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#4-worker-implementations-reusing-base","title":"4. Worker Implementations (Reusing Base)","text":"<p>Each worker only implements <code>process()</code>:</p> <pre><code>class DownloadWorker(BaseStageWorker):\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self.downloader = YouTubeDownloader(config)\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        result = self.downloader.download_single(msg.input_path)\n        if not result.success:\n            return None\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=result.output_path,\n            metadata={\"title\": result.title, \"duration\": result.duration},\n            timestamp=time.time(),\n        )\n\nclass ExtractWorker(BaseStageWorker):\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self.extractor = FrameExtractor(config)\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        result = self.extractor.extract_video(msg.input_path, msg.video_id)\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=result.output_dir,  # Folder of frames\n            metadata={\"frame_count\": result.frame_count},\n            timestamp=time.time(),\n        )\n\nclass FilterWorker(BaseStageWorker):\n    def __init__(self, config, classes, **kwargs):\n        super().__init__(**kwargs)\n        self.filter = FrameFilter(config)\n        self.classes = classes\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        frames = sorted(Path(msg.input_path).glob(\"*.jpg\"))\n        result = self.filter.filter_frames(frames, self.classes, msg.video_id)\n\n        if result.passed_frames == 0:\n            return None\n\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=self.filter.config.output_dir / msg.video_id,\n            metadata={\"passed\": result.passed_frames, \"total\": result.total_frames},\n            timestamp=time.time(),\n        )\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#5-scaling-considerations","title":"5. Scaling Considerations","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#worker-count-guidelines","title":"Worker Count Guidelines","text":"Stage Workers Rationale Download 2-3 Network limited, yt-dlp is heavy Extract 2 CPU decode, disk I/O Filter 1 GPU bound, avoid VRAM contention Dedup Collector 1 Just accumulates"},{"location":"reference/legacy/async_pipeline_implementation_plan/#memory-management","title":"Memory Management","text":"<pre><code># Cleanup raw frames after filtering\nif config.cleanup_intermediate:\n    shutil.rmtree(msg.input_path)  # Delete frames_raw/video_id\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#monitoring","title":"Monitoring","text":"<pre><code>@dataclass\nclass PipelineMetrics:\n    stage_counts: dict[str, int]      # processed per stage\n    stage_latencies: dict[str, float] # avg time per stage\n    queue_depths: dict[str, int]      # current queue sizes\n    errors: list[tuple[str, str]]     # (video_id, error)\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#6-file-structure","title":"6. File Structure","text":"<pre><code>video_miner_v3/\n\u251c\u2500\u2500 async_pipeline/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base_worker.py      # BaseStageWorker\n\u2502   \u251c\u2500\u2500 messages.py         # StageMessage dataclass\n\u2502   \u251c\u2500\u2500 workers/\n\u2502   \u2502   \u251c\u2500\u2500 download.py     # DownloadWorker\n\u2502   \u2502   \u251c\u2500\u2500 extract.py      # ExtractWorker\n\u2502   \u2502   \u251c\u2500\u2500 filter.py       # FilterWorker\n\u2502   \u2502   \u2514\u2500\u2500 dedup.py        # DedupCollector\n\u2502   \u251c\u2500\u2500 orchestrator.py     # AsyncPipelineOrchestrator\n\u2502   \u2514\u2500\u2500 metrics.py          # PipelineMetrics\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#7-migration-path","title":"7. Migration Path","text":"<ol> <li>Phase 1: Create <code>async_pipeline/</code> module alongside existing <code>pipeline.py</code></li> <li>Phase 2: Add CLI flag <code>--async-mode</code> to select new pipeline</li> <li>Phase 3: Validate with 100 videos, compare results</li> <li>Phase 4: Deprecate old sequential pipeline</li> </ol>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#summary","title":"Summary","text":"Decision Choice Reasoning Concurrency asyncio + ThreadPool GPU in single process, GIL released by PyTorch Queue Type <code>asyncio.Queue</code> Simple, backpressure built-in Message Format Folder paths Lightweight, no serialization GPU Workers Single Avoid VRAM contention Base Class <code>BaseStageWorker</code> DRY principle, common <code>run_loop()</code>"},{"location":"reference/legacy/video_miner_v3_async/","title":"Parallel Pipeline Design Options","text":"<p>Two architectural approaches for parallelizing download \u2192 extract \u2192 filter stages.</p>"},{"location":"reference/legacy/video_miner_v3_async/#option-1-per-video-streaming-pipeline","title":"Option 1: Per-Video Streaming Pipeline","text":"<p>Concept: Each video flows through download\u2192extract\u2192filter as a unit, multiple videos processed concurrently.</p> <pre><code>flowchart LR\n    subgraph Parallel Workers\n        A1[Video 1] --&gt; B1[Download] --&gt; C1[Extract] --&gt; D1[Filter]\n        A2[Video 2] --&gt; B2[Download] --&gt; C2[Extract] --&gt; D2[Filter]\n        A3[Video 3] --&gt; B3[Download] --&gt; C3[Extract] --&gt; D3[Filter]\n    end\n\n    D1 --&gt; E[Collect Filtered]\n    D2 --&gt; E\n    D3 --&gt; E\n    E --&gt; F[Cross-Video Dedup]\n    F --&gt; G[Detection]</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#implementation-sketch","title":"Implementation Sketch","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor, as_completed\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass VideoProcessResult:\n    video_id: str\n    filtered_dir: Path\n    frame_count: int\n\nclass StreamingPipeline:\n    def __init__(self, config, registry):\n        self.config = config\n        self.registry = registry\n        self.downloader = YouTubeDownloader(config.download)\n        self.extractor = FrameExtractor(config.extraction)\n        # Shared filter model (thread-safe for inference)\n        self.filter = FrameFilter(config.filter)\n\n    def process_single_video(self, url: str) -&gt; VideoProcessResult:\n        \"\"\"Process one video through download \u2192 extract \u2192 filter.\"\"\"\n        video_id = get_video_id(url)\n\n        # Stage 1: Download\n        download_result = self.downloader.download_single(url)\n        if not download_result.success:\n            return None\n\n        # Stage 2: Extract frames\n        extraction_result = self.extractor.extract_video(\n            download_result.output_path, video_id\n        )\n\n        # Stage 3: Filter frames\n        filter_result = self.filter.filter_frames(\n            frame_paths=extraction_result.output_paths,\n            classes=self.config.classes,\n            video_id=video_id,\n        )\n\n        # Optional: Delete raw frames to save disk\n        if self.config.cleanup_raw_frames:\n            shutil.rmtree(extraction_result.output_dir)\n\n        return VideoProcessResult(\n            video_id=video_id,\n            filtered_dir=self.config.filter.output_dir / video_id,\n            frame_count=filter_result.passed_frames,\n        )\n\n    def run(self, urls: list[str], max_workers: int = 3):\n        \"\"\"Run parallel video processing.\"\"\"\n        results = []\n\n        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = {\n                executor.submit(self.process_single_video, url): url\n                for url in urls\n            }\n\n            for future in as_completed(futures):\n                result = future.result()\n                if result:\n                    results.append(result)\n                    # Update registry per-video\n                    self.registry.update_video(result.video_id, status=\"filtered\")\n\n        # Cross-video deduplication (after all videos filtered)\n        all_filtered_frames = self._collect_filtered_frames(results)\n        dedup_result = self.deduplicator.deduplicate_cross_video(all_filtered_frames)\n\n        return dedup_result\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#proscons","title":"Pros/Cons","text":"Pros Cons Simple mental model Limited by slowest stage Easy error handling per-video Filter model loaded N times if not shared Good for small batches Thread contention on GPU"},{"location":"reference/legacy/video_miner_v3_async/#option-2-stage-level-async-queues-folder-based","title":"Option 2: Stage-Level Async Queues (Folder-Based)","text":"<p>Concept: Separate workers for each stage, communicate via folder paths in queues. Each stage runs independently.</p> <pre><code>flowchart TB\n    subgraph Download Workers\n        DW1[Worker 1]\n        DW2[Worker 2]\n    end\n\n    subgraph Extract Workers\n        EW1[Worker 1]\n        EW2[Worker 2]\n    end\n\n    subgraph Filter Workers\n        FW1[Worker 1 - GPU]\n    end\n\n    Q1[(Download Queue)]\n    Q2[(Extract Queue)]\n    Q3[(Filter Queue)]\n    Q4[(Dedup Queue)]\n\n    URLs --&gt; Q1\n    Q1 --&gt; DW1 &amp; DW2\n    DW1 &amp; DW2 --&gt; Q2\n    Q2 --&gt; EW1 &amp; EW2\n    EW1 &amp; EW2 --&gt; Q3\n    Q3 --&gt; FW1\n    FW1 --&gt; Q4\n    Q4 --&gt; Dedup[Cross-Video Dedup]</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#implementation-sketch_1","title":"Implementation Sketch","text":"<pre><code>import asyncio\nfrom asyncio import Queue\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass StageMessage:\n    video_id: str\n    folder_path: Path  # Pass folder, not frames\n    stage: str\n\nclass AsyncQueuePipeline:\n    def __init__(self, config):\n        self.config = config\n        # Async queues between stages\n        self.download_queue = Queue()   # Input: URLs\n        self.extract_queue = Queue()    # Input: video paths\n        self.filter_queue = Queue()     # Input: frame folders\n        self.dedup_queue = Queue()      # Input: filtered folders\n\n        self.shutdown = asyncio.Event()\n\n    # =========== DOWNLOAD WORKER ===========\n    async def download_worker(self, worker_id: int):\n        \"\"\"Download videos, output video file path to extract queue.\"\"\"\n        downloader = YouTubeDownloader(self.config.download)\n\n        while not self.shutdown.is_set():\n            try:\n                url = await asyncio.wait_for(\n                    self.download_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            # Run blocking download in thread pool\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None, downloader.download_single, url\n            )\n\n            if result.success:\n                # Pass VIDEO FOLDER to next stage\n                await self.extract_queue.put(StageMessage(\n                    video_id=result.video_id,\n                    folder_path=result.output_path,\n                    stage=\"downloaded\",\n                ))\n\n            self.download_queue.task_done()\n\n    # =========== EXTRACT WORKER ===========\n    async def extract_worker(self, worker_id: int):\n        \"\"\"Extract frames, output frames folder to filter queue.\"\"\"\n        extractor = FrameExtractor(self.config.extraction)\n\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.extract_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                extractor.extract_video,\n                msg.folder_path,\n                msg.video_id,\n            )\n\n            # Pass FRAMES FOLDER to next stage\n            await self.filter_queue.put(StageMessage(\n                video_id=msg.video_id,\n                folder_path=result.output_dir,  # Folder of frames\n                stage=\"extracted\",\n            ))\n\n            self.extract_queue.task_done()\n\n    # =========== FILTER WORKER (GPU) ===========\n    async def filter_worker(self):\n        \"\"\"Filter frames using GPU. Single worker to avoid GPU contention.\"\"\"\n        filter_model = FrameFilter(self.config.filter)\n\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.filter_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            # Get all frame paths from folder\n            frame_paths = sorted(msg.folder_path.glob(\"*.jpg\"))\n\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                filter_model.filter_frames,\n                frame_paths,\n                self.config.classes,\n                msg.video_id,\n            )\n\n            # Pass FILTERED FOLDER to dedup\n            await self.dedup_queue.put(StageMessage(\n                video_id=msg.video_id,\n                folder_path=self.config.filter.output_dir / msg.video_id,\n                stage=\"filtered\",\n            ))\n\n            # Optional: cleanup raw frames\n            if self.config.cleanup_raw_frames:\n                shutil.rmtree(msg.folder_path)\n\n            self.filter_queue.task_done()\n\n    # =========== MAIN RUNNER ===========\n    async def run(self, urls: list[str]):\n        \"\"\"Run the full async pipeline.\"\"\"\n        # Seed the download queue\n        for url in urls:\n            await self.download_queue.put(url)\n\n        # Start workers\n        workers = [\n            asyncio.create_task(self.download_worker(1)),\n            asyncio.create_task(self.download_worker(2)),\n            asyncio.create_task(self.extract_worker(1)),\n            asyncio.create_task(self.extract_worker(2)),\n            asyncio.create_task(self.filter_worker()),  # Single GPU worker\n        ]\n\n        # Wait for all queues to drain\n        await self.download_queue.join()\n        await self.extract_queue.join()\n        await self.filter_queue.join()\n\n        # Signal shutdown\n        self.shutdown.set()\n        await asyncio.gather(*workers, return_exceptions=True)\n\n        # Collect all filtered folders for dedup\n        filtered_folders = {}\n        while not self.dedup_queue.empty():\n            msg = self.dedup_queue.get_nowait()\n            filtered_folders[msg.video_id] = list(msg.folder_path.glob(\"*.jpg\"))\n\n        # Final cross-video dedup\n        deduplicator = Deduplicator(self.config.deduplication)\n        return deduplicator.deduplicate_cross_video(filtered_folders)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#proscons_1","title":"Pros/Cons","text":"Pros Cons Maximum parallelism More complex error handling Each stage scales independently Debugging harder Natural backpressure via queues Need careful queue sizing GPU worker isolation asyncio learning curve"},{"location":"reference/legacy/video_miner_v3_async/#comparison-summary","title":"Comparison Summary","text":"Aspect Option 1 (Per-Video) Option 2 (Async Queues) Complexity Low High Parallelism Per-video Per-stage GPU Utilization Moderate High (dedicated worker) Memory Higher (multiple videos in flight) Controlled via queue size Error Recovery Easy (per-video retry) Complex (stage isolation) Best For &lt; 50 videos 100+ videos"},{"location":"reference/legacy/video_miner_v3_async/#recommendation","title":"Recommendation","text":"<ul> <li>Start with Option 1 for simplicity</li> <li>Migrate to Option 2 if you need to process 100+ videos or want better GPU utilization</li> <li>Key insight: Pass folder paths between stages, not frame data, to minimize memory usage</li> </ul>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/","title":"Video Miner V3 - Detailed Code Walkthrough","text":"<p>A comprehensive guide to the architecture and code flow of Video Miner V3, a high-performance video mining pipeline for generating large-scale computer vision datasets from YouTube videos.</p> <p></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Project Overview</li> <li>Directory Structure</li> <li>Architecture Diagram</li> <li>Entry Points</li> <li>Configuration System</li> <li>Pipeline Orchestration</li> <li>Processing Modules</li> <li>ML Model Wrappers</li> <li>Video Registry System</li> <li>Utility Functions</li> <li>Data Flow</li> </ol>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#project-overview","title":"Project Overview","text":"<p>Video Miner V3 is designed to: - Search YouTube for videos by keyword - Download highest quality videos - Extract frames with configurable sampling - Filter frames using SigLIP2 semantic similarity - Deduplicate frames using DINOv2/v3 or SigLIP2 embeddings - Detect objects using open-set detection models</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#directory-structure","title":"Directory Structure","text":"<pre><code>video_miner_v3/\n\u251c\u2500\u2500 cli.py                 # Click CLI interface (509 lines)\n\u251c\u2500\u2500 config.py              # Pydantic configuration models (203 lines)\n\u251c\u2500\u2500 config_loader.py       # OmegaConf YAML loading (232 lines)\n\u251c\u2500\u2500 constants.py           # Centralized model IDs &amp; defaults (91 lines)\n\u251c\u2500\u2500 pipeline.py            # Main pipeline orchestrator (688 lines)\n\u251c\u2500\u2500 registry.py            # Video tracking registry (420 lines)\n\u251c\u2500\u2500 search.py              # YouTube search via yt-dlp (281 lines)\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 base.py            # BaseModel class, shared utilities\n\u2502   \u251c\u2500\u2500 siglip_model.py    # SigLIP2 wrapper for filtering\n\u2502   \u251c\u2500\u2500 dinov3_model.py    # DINOv2/v3 wrapper for dedup\n\u2502   \u2514\u2500\u2500 detector_models.py # Florence2, GroundingDINO, Moondream\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 downloader.py      # YouTube video download\n\u2502   \u251c\u2500\u2500 frame_extractor.py # Frame extraction with PyAV\n\u2502   \u251c\u2500\u2500 frame_filter.py    # SigLIP-based filtering\n\u2502   \u251c\u2500\u2500 deduplicator.py    # Embedding-based dedup with FAISS\n\u2502   \u2514\u2500\u2500 detector.py        # Object detection orchestrator\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 device.py          # CUDA/CPU device management\n    \u251c\u2500\u2500 io.py              # File I/O, video ID extraction\n    \u251c\u2500\u2500 validators.py      # Input validation\n    \u2514\u2500\u2500 query_generator.py # Query generation utilities\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#entry-points","title":"Entry Points","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#cli-clipy","title":"CLI (<code>cli.py</code>)","text":"<p>The main entry point is the <code>video-miner</code> CLI built with Click:</p> <pre><code>@click.group()\n@click.option('--verbose', '-v', is_flag=True)\n@click.pass_context\ndef main(ctx: click.Context, verbose: bool):\n    \"\"\"Video Miner v3 - High-performance video mining pipeline.\"\"\"\n    setup_logging(verbose)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#key-commands","title":"Key Commands","text":"Command Function Description <code>run-config</code> <code>run_config()</code> Run pipeline from YAML config file(s) <code>validate-config</code> <code>validate_config_cmd()</code> Validate YAML config without running <code>registry status</code> <code>registry_status()</code> Show registry statistics <code>registry list</code> <code>registry_list()</code> List videos in registry <code>registry export</code> <code>registry_export()</code> Export URLs to file"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pipeline-execution-flow","title":"Pipeline Execution Flow","text":"<pre><code>flowchart TD\n    A[run-config command] --&gt; B[Load YAML with OmegaConf]\n    B --&gt; C[validate_config]\n    C --&gt; D{Valid?}\n    D --&gt;|No| E[Print errors &amp; exit]\n    D --&gt;|Yes| F[_execute_pipeline]\n    F --&gt; G[gather_input_urls]\n    G --&gt; H[Create PipelineConfig]\n    H --&gt; I[VideoPipeline.run]</code></pre> <p>The <code>_execute_pipeline()</code> function: 1. Loads/creates the video registry 2. Executes optional search stage 3. Gathers URLs from config, files, or registry 4. Builds <code>PipelineConfig</code> with all stage configurations 5. Instantiates <code>VideoPipeline</code> and calls <code>run()</code></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#configuration-system","title":"Configuration System","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pydantic-models-configpy","title":"Pydantic Models (<code>config.py</code>)","text":"<p>All configuration uses Pydantic for validation:</p> <pre><code>classDiagram\n    PipelineConfig *-- DownloadConfig\n    PipelineConfig *-- ExtractionConfig\n    PipelineConfig *-- FilterConfig\n    PipelineConfig *-- DeduplicationConfig\n    PipelineConfig *-- DetectionConfig\n\n    class PipelineConfig {\n        +urls: list~str~\n        +classes: list~str~\n        +stages: list~str~\n        +device: str\n        +use_fp16: bool\n        +output_dir: Path\n        +get_urls() list~str~\n    }\n\n    class DownloadConfig {\n        +force: bool\n        +output_dir: Path\n        +max_concurrent: int\n        +timeout: int\n    }\n\n    class ExtractionConfig {\n        +force: bool\n        +output_dir: Path\n        +strategy: SamplingStrategy\n        +interval: int\n        +max_frames: int\n        +image_format: str\n        +quality: int\n    }\n\n    class FilterConfig {\n        +force: bool\n        +threshold: float\n        +model: FilterModel\n        +batch_size: int\n        +output_dir: Path\n        +model_id() str\n    }\n\n    class DeduplicationConfig {\n        +force: bool\n        +threshold: float\n        +use_siglip: bool\n        +batch_size: int\n        +output_dir: Path\n        +dino_model_id: str\n        +model_type() str\n    }\n\n    class DetectionConfig {\n        +force: bool\n        +detector: DetectorType\n        +confidence_threshold: float\n        +save_visualizations: bool\n        +output_dir: Path\n        +batch_size: int\n    }</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#enums","title":"Enums","text":"Enum Values Location <code>DetectorType</code> dino-x, moondream3, florence2, grounding-dino <code>config.py:35-40</code> <code>SamplingStrategy</code> interval, time, keyframe <code>config.py:43-47</code> <code>FilterModel</code> siglip2-so400m, siglip2-giant <code>config.py:50-53</code>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#omegaconf-loader-config_loaderpy","title":"OmegaConf Loader (<code>config_loader.py</code>)","text":"<p>Supports layered configuration merging:</p> <pre><code>def load_config(user_config, overrides, resolve=True):\n    \"\"\"\n    Merge order (later overrides earlier):\n    1. config/default.yaml (base defaults)\n    2. user_config (user overrides)\n    3. overrides dict (CLI/programmatic overrides)\n    \"\"\"\n</code></pre> <p>Key functions: - <code>load_config()</code> - Load and merge YAML configs - <code>validate_config()</code> - Validate required fields - <code>print_config()</code> - Pretty print configuration</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#constants-constantspy","title":"Constants (<code>constants.py</code>)","text":"<p>Centralized source of truth for all model IDs and defaults:</p> Category Models Default SigLIP2 siglip2-so400m, siglip2-giant siglip2-so400m DINO dinov3-small/base/large/huge/giant, dinov2-base/large dinov2-base Detectors dino-x, moondream3, florence2, grounding-dino moondream3 <p>Default thresholds: - Filter: 0.25 - Dedup: 0.90 - Detection: 0.3</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pipeline-orchestration","title":"Pipeline Orchestration","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#videopipeline-pipelinepy","title":"VideoPipeline (<code>pipeline.py</code>)","text":"<p>The main orchestrator coordinates all processing stages:</p> <pre><code>flowchart LR\n    subgraph Stage 1\n        A[Download] --&gt; B[DownloadResult]\n    end\n    subgraph Stage 2\n        B --&gt; C[Extract Frames]\n        C --&gt; D[ExtractionResult]\n    end\n    subgraph Stage 3\n        D --&gt; E[Filter Frames]\n        E --&gt; F[FilterResult]\n    end\n    subgraph Stage 4\n        F --&gt; G[Deduplicate]\n        G --&gt; H[DeduplicationResult]\n    end\n    subgraph Stage 5\n        H --&gt; I[Detection]\n        I --&gt; J[DetectionBatchResult]\n    end\n    J --&gt; K[PipelineResult]</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#constructor","title":"Constructor","text":"<pre><code>class VideoPipeline:\n    def __init__(self, config: PipelineConfig, registry: Optional[\"VideoRegistry\"] = None):\n        self.config = config\n        self.registry = registry\n        # Lazy-loaded modules\n        self._downloader = None\n        self._extractor = None\n        self._frame_filter = None\n        self._deduplicator = None\n        self._detector = None\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#main-run-method","title":"Main Run Method","text":"<p><code>VideoPipeline.run()</code>:</p> <pre><code>def run(self, show_progress: bool = True) -&gt; PipelineResult:\n    stages = self.config.stages  # e.g., [\"download\", \"extract\", \"filter\", \"dedup\", \"detect\"]\n\n    if \"download\" in stages:\n        download_results = self._run_download(show_progress)\n        self._update_registry_downloads(download_results)\n\n    if \"extract\" in stages:\n        extraction_results = self._run_extraction(download_results, show_progress)\n        self._update_registry_extractions(extraction_results)\n\n    if \"filter\" in stages:\n        filter_results = self._run_filter(extraction_results, show_progress)\n        self._update_registry_filters(filter_results)\n\n    if \"dedup\" in stages:\n        dedup_result = self._run_deduplication(filter_results, show_progress)\n        self._update_registry_deduplication(dedup_result)\n\n    if \"detect\" in stages:\n        detection_result = self._run_detection(dedup_result, show_progress)\n        self._update_registry_detections(detection_result)\n\n    return PipelineResult(...)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#registry-aware-filtering","title":"Registry-Aware Filtering","text":"<p>The pipeline uses <code>_filter_by_registry()</code> to skip already-processed videos:</p> <pre><code>def _filter_by_registry(self, items, get_video_id, stage_name, force=False):\n    \"\"\"Skip items that have already completed the stage in registry.\"\"\"\n    if force or self.registry is None:\n        return items\n\n    filtered = []\n    for item in items:\n        video_id = get_video_id(item)\n        if not self.registry.is_stage_complete(video_id, stage_name):\n            filtered.append(item)\n    return filtered\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#processing-modules","title":"Processing Modules","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#1-downloader-downloaderpy","title":"1. Downloader (<code>downloader.py</code>)","text":"<p>Downloads YouTube videos using yt-dlp with concurrent processing.</p> <pre><code>flowchart TD\n    A[URL List] --&gt; B[ThreadPoolExecutor]\n    B --&gt; C1[download_single]\n    B --&gt; C2[download_single]\n    B --&gt; C3[download_single]\n    C1 --&gt; D[yt-dlp]\n    C2 --&gt; D\n    C3 --&gt; D\n    D --&gt; E[DownloadResult]</code></pre> <p>Key Classes: - <code>DownloadResult</code> - Dataclass with url, video_id, success, output_path, title, duration - <code>YouTubeDownloader</code> - Main downloader class</p> <p>Key Methods: - <code>download_single()</code> - Download one video - <code>download_batch()</code> - Concurrent batch download - <code>gather_input_urls()</code> - Collect URLs from config sources</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#2-frame-extractor-frame_extractorpy","title":"2. Frame Extractor (<code>frame_extractor.py</code>)","text":"<p>Extracts frames from videos using PyAV with configurable sampling strategies.</p> <p>Sampling Strategies:</p> Strategy Description <code>interval</code> Every N frames (default: 30) <code>time</code> Every N seconds <code>keyframe</code> Scene change detection <p>Key Classes: - <code>FrameInfo</code> - Dataclass with video_path, video_id, frame_number, timestamp, image - <code>ExtractionResult</code> - Dataclass with frame_count, output_paths, output_dir - <code>FrameExtractor</code> - Main extractor class</p> <p>Key Methods: - <code>iterate_frames()</code> - Generator yielding FrameInfo - <code>extract_video()</code> - Extract and save frames - <code>extract_batch()</code> - Concurrent batch extraction</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#3-frame-filter-frame_filterpy","title":"3. Frame Filter (<code>frame_filter.py</code>)","text":"<p>Filters frames using SigLIP2 text-image similarity.</p> <pre><code>flowchart LR\n    A[Frame Images] --&gt; B[SigLIPModel]\n    C[Text Classes] --&gt; B\n    B --&gt; D{Score &gt; Threshold?}\n    D --&gt;|Yes| E[Keep Frame]\n    D --&gt;|No| F[Discard]</code></pre> <p>Key Classes: - <code>FilteredFrame</code> - Dataclass with source_path, best_class, score, all_scores - <code>FilterResult</code> - Dataclass with total_frames, passed_frames, filtered_frames - <code>FrameFilter</code> - Main filter class</p> <p>Key Methods: - <code>filter_frames()</code> - Filter single video frames - <code>filter_batch()</code> - Filter multiple videos</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#4-deduplicator-deduplicatorpy","title":"4. Deduplicator (<code>deduplicator.py</code>)","text":"<p>Removes duplicate frames using embedding-based similarity with FAISS.</p> <p>Two-Phase Deduplication:</p> <pre><code>flowchart TD\n    subgraph Phase1[\"Phase 1: Per-Video\"]\n        A[All Frames] --&gt; B[Compute Embeddings]\n        B --&gt; C[Cosine Similarity]\n        C --&gt; D[Greedy Selection]\n    end\n\n    subgraph Phase2[\"Phase 2: Cross-Video\"]\n        D --&gt; E[FAISS Index]\n        E --&gt; F[KNN Search]\n        F --&gt; G[Merge Duplicates]\n    end\n\n    G --&gt; H[Unique Frames]</code></pre> <p>Algorithm Flow: 1. Phase 1 - Per-Video: Remove temporal duplicates within each video using greedy selection 2. Phase 2 - Cross-Video: Use FAISS ANN search to find and remove duplicates across all videos</p> <p>Supported Models: - DINOv2/v3 (default) - Best quality embeddings - SigLIP2 - Memory-efficient, reuses filter model</p> <p>Key Methods: - <code>deduplicate()</code> - Single batch deduplication - <code>deduplicate_cross_video()</code> - Two-phase cross-video dedup - <code>_faiss_dedup()</code> - FAISS-based O(N log N) dedup</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#5-object-detector-detectorpy","title":"5. Object Detector (<code>detector.py</code>)","text":"<p>Runs open-set object detection on frames.</p> <p>Supported Detectors:</p> Detector Model ID Notes Moondream3 <code>vikhyatk/moondream2</code> VQA + detection Florence-2 <code>microsoft/Florence-2-large</code> Multi-task Grounding DINO <code>IDEA-Research/grounding-dino-base</code> Stable <p>Key Methods: - <code>detect_single()</code> - Detect in one image - <code>detect_batch()</code> - Batch detection with progress</p> <p>Output: - <code>annotations.json</code> - COCO-format annotations - <code>visualizations/</code> - Images with bounding boxes</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#ml-model-wrappers","title":"ML Model Wrappers","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#base-model-basepy","title":"Base Model (<code>base.py</code>)","text":"<p>Abstract base class providing common functionality:</p> <pre><code>class BaseModel(ABC):\n    def __init__(self):\n        self.model = None\n        self.processor = None\n        self._loaded = False\n\n    @abstractmethod\n    def load(self) -&gt; None: pass\n\n    def unload(self) -&gt; None:\n        del self.model, self.processor\n        clear_gpu_cache()\n\n    def __enter__(self): self.load(); return self\n    def __exit__(self, *args): self.unload()\n</code></pre> <p>Utilities: - <code>load_image()</code> - Convert Path/np.array/PIL to RGB Image - <code>create_batch_iterator()</code> - Batch iterator with tqdm - <code>load_model_with_fallback()</code> - Try multiple model IDs</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#siglip-model-siglip_modelpy","title":"SigLIP Model (<code>siglip_model.py</code>)","text":"<p>Wrapper for Google's SigLIP2 for image-text similarity:</p> <pre><code>class SigLIPModel(BaseModel):\n    def compute_similarity(self, images, texts, batch_size=16):\n        \"\"\"Returns (N_images, N_texts) similarity matrix.\"\"\"\n        # Precompute text features\n        text_features = self.model.get_text_features(...)\n\n        # Process images in batches\n        for batch in create_batch_iterator(images, batch_size):\n            image_features = self.model.get_image_features(...)\n            logits = (image_features @ text_features.T) * self.model.logit_scale.exp()\n            scores = torch.sigmoid(logits)  # SigLIP uses sigmoid\n\n        return np.vstack(all_scores)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#dinov3-model-dinov3_modelpy","title":"DINOv3 Model (<code>dinov3_model.py</code>)","text":"<p>Wrapper for Meta's DINOv2/v3 for image embeddings:</p> <pre><code>class DINOv3Model(BaseModel):\n    def get_embeddings(self, images, batch_size=32, normalize=True):\n        \"\"\"Returns (N_images, embedding_dim) array.\"\"\"\n        for batch in create_batch_iterator(images, batch_size):\n            outputs = self.model(**inputs)\n            embeddings = outputs.pooler_output  # or last_hidden_state[:, 0]\n\n        if normalize:\n            embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n        return embeddings\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#detector-models-detector_modelspy","title":"Detector Models (<code>detector_models.py</code>)","text":"<p>Unified interface for multiple detection backends:</p> <pre><code>classDiagram\n    BaseDetector &lt;|-- Florence2Detector\n    BaseDetector &lt;|-- GroundingDINODetector\n    BaseDetector &lt;|-- MoondreamDetector\n\n    class BaseDetector {\n        &lt;&lt;abstract&gt;&gt;\n        +device_map: str\n        +model: Any\n        +processor: Any\n        +load()*\n        +unload()*\n        +detect(image, prompt, threshold)* DetectionResult\n        -_load_image(image) Image\n    }\n\n    class Florence2Detector {\n        +model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }\n\n    class GroundingDINODetector {\n        +model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }\n\n    class MoondreamDetector {\n        +model_id: str\n        +_actual_model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }</code></pre> <p>Factory function: <pre><code>def get_detector(detector_type: DetectorType, model_id: str, device_map: str):\n    if detector_type == DetectorType.FLORENCE2:\n        return Florence2Detector(model_id, device_map)\n    elif detector_type == DetectorType.GROUNDING_DINO:\n        return GroundingDINODetector(model_id, device_map)\n    elif detector_type == DetectorType.MOONDREAM3:\n        return MoondreamDetector(model_id, device_map)\n</code></pre></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#video-registry-system","title":"Video Registry System","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#videoregistry-registrypy","title":"VideoRegistry (<code>registry.py</code>)","text":"<p>Pydantic-based YAML registry for tracking video processing status:</p> <pre><code>classDiagram\n    VideoRegistry *-- RegistryMetadata\n    VideoRegistry \"1\" *-- \"*\" VideoEntry : videos\n    VideoEntry *-- PipelineStages\n    PipelineStages *-- DownloadStage\n    PipelineStages *-- ExtractionStage\n    PipelineStages *-- FilterStage\n    PipelineStages *-- DeduplicationStage\n    PipelineStages *-- DetectionStage\n\n    class VideoRegistry {\n        +metadata: RegistryMetadata\n        +videos: dict~str VideoEntry~\n        +_lock: threading.Lock\n        +add_video(video_id, url, title) bool\n        +get_pending() list~VideoEntry~\n        +get_by_status(status) list~VideoEntry~\n        +update_stage(video_id, stage, data)\n        +is_stage_complete(video_id, stage) bool\n        +save(file_path)\n        +load(file_path)$ VideoRegistry\n        +load_or_create(file_path)$ VideoRegistry\n    }\n\n    class RegistryMetadata {\n        +created: str\n        +updated: str\n        +total_videos: int\n        +keywords_searched: list~str~\n        +version: str\n    }\n\n    class VideoEntry {\n        +video_id: str\n        +url: str\n        +title: str\n        +channel: str\n        +duration_seconds: int\n        +source_keyword: str\n        +status: VideoStatus\n        +added: str\n        +stages: PipelineStages\n        +notes: str\n        +is_processed() bool\n        +get_summary() dict\n    }\n\n    class PipelineStages {\n        +download: DownloadStage\n        +extraction: ExtractionStage\n        +filter: FilterStage\n        +deduplication: DeduplicationStage\n        +detection: DetectionStage\n    }\n\n    class DownloadStage {\n        +completed: bool\n        +path: str\n        +size_mb: float\n        +duration_seconds: float\n        +error: str\n    }\n\n    class FilterStage {\n        +completed: bool\n        +input_frames: int\n        +passed_frames: int\n        +output_dir: str\n        +pass_rate() float\n    }</code></pre> <p>VideoStatus Enum: <pre><code>class VideoStatus(str, Enum):\n    PENDING = \"pending\"\n    DOWNLOADING = \"downloading\"\n    DOWNLOADED = \"downloaded\"\n    EXTRACTING = \"extracting\"\n    EXTRACTED = \"extracted\"\n    FILTERING = \"filtering\"\n    FILTERED = \"filtered\"\n    DEDUPLICATING = \"deduplicating\"\n    DEDUPLICATED = \"deduplicated\"\n    DETECTING = \"detecting\"\n    DETECTED = \"detected\"\n    COMPLETE = \"complete\"\n    FAILED = \"failed\"\n    SKIPPED = \"skipped\"\n</code></pre></p> <p>Key Methods: - <code>add_video()</code> - Add video to registry - <code>update_stage()</code> - Update stage completion - <code>get_pending()</code> - Get unprocessed videos - <code>save()</code> - Thread-safe YAML save</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#utility-functions","title":"Utility Functions","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#device-management-devicepy","title":"Device Management (<code>device.py</code>)","text":"<pre><code>def resolve_device(device_map: str = \"auto\") -&gt; str:\n    \"\"\"Resolve device_map for HuggingFace model loading.\"\"\"\n    num_gpus = torch.cuda.device_count()\n    if device_map == \"auto\":\n        if num_gpus &gt; 1: return \"auto\"  # Multi-GPU\n        elif num_gpus == 1: return \"cuda\"\n        else: return \"cpu\"\n\ndef clear_gpu_cache():\n    \"\"\"Clear GPU cache to free memory.\"\"\"\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#io-utilities-iopy","title":"I/O Utilities (<code>io.py</code>)","text":"Function Description <code>ensure_dir()</code> Create directory if not exists <code>save_json()</code> / <code>load_json()</code> JSON file operations <code>get_video_id()</code> Extract YouTube video ID from URL <code>get_safe_filename()</code> Sanitize string for filesystem"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#data-flow","title":"Data Flow","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>flowchart TB\n    subgraph Input\n        A[YAML Config] --&gt; B[load_config]\n        C[URL File/List] --&gt; D[gather_input_urls]\n        E[Registry] --&gt; D\n    end\n\n    subgraph Pipeline\n        D --&gt; F[YouTubeDownloader.download_batch]\n        F --&gt; G[FrameExtractor.extract_batch]\n        G --&gt; H[FrameFilter.filter_batch]\n        H --&gt; I[Deduplicator.deduplicate_cross_video]\n        I --&gt; J[ObjectDetector.detect_batch]\n    end\n\n    subgraph Models\n        K[SigLIPModel] --&gt; H\n        L[DINOv3Model] --&gt; I\n        M[Detector Models] --&gt; J\n    end\n\n    subgraph Output\n        F --&gt; N[videos/]\n        G --&gt; O[frames_raw/]\n        H --&gt; P[frames_filtered/]\n        I --&gt; Q[frames_deduplicated/]\n        J --&gt; R[detections/annotations.json]\n        J --&gt; S[detections/visualizations/]\n    end\n\n    subgraph Registry\n        F --&gt; T[Update download stage]\n        G --&gt; T\n        H --&gt; T\n        I --&gt; T\n        J --&gt; T\n        T --&gt; U[video_registry.yaml]\n    end</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#output-directory-structure","title":"Output Directory Structure","text":"<pre><code>output/\n\u251c\u2500\u2500 video_registry.yaml        # Video tracking\n\u251c\u2500\u2500 videos/                    # Downloaded videos\n\u2502   \u2514\u2500\u2500 {video_id}.mp4\n\u251c\u2500\u2500 frames_raw/{video_id}/     # All extracted frames\n\u2502   \u2514\u2500\u2500 frame_00001.jpg\n\u251c\u2500\u2500 frames_filtered/{video_id}/ # Frames passing filter\n\u2502   \u2514\u2500\u2500 frame_00042.jpg\n\u251c\u2500\u2500 frames_deduplicated/       # Unique frames\n\u2502   \u2514\u2500\u2500 frame_00042.jpg\n\u251c\u2500\u2500 detections/\n\u2502   \u251c\u2500\u2500 annotations.json       # COCO-format\n\u2502   \u2514\u2500\u2500 visualizations/        # Bounding box images\n\u2514\u2500\u2500 pipeline_result.json       # Summary statistics\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#summary","title":"Summary","text":"<p>Video Miner V3 is a well-architected pipeline with:</p> <ul> <li>Clean separation of concerns - Each module handles one stage</li> <li>Pydantic configuration - Type-safe, validated configs</li> <li>Registry tracking - Resume capability, no reprocessing</li> <li>Lazy model loading - Models loaded only when needed</li> <li>FAISS deduplication - O(N log N) scalable dedup</li> <li>Multiple detector backends - Florence2, GroundingDINO, Moondream</li> <li>Multi-GPU support - HuggingFace device_map=\"auto\"</li> </ul>"},{"location":"user-guide/cli-reference/","title":"CLI Reference","text":"<p>All commands are available via the <code>data-miner</code> CLI.</p> <pre><code>data-miner --help\n</code></pre>"},{"location":"user-guide/cli-reference/#core-commands","title":"Core Commands","text":""},{"location":"user-guide/cli-reference/#init-db","title":"<code>init-db</code>","text":"<p>Initialize database tables.</p> <pre><code>data-miner init-db\ndata-miner init-db --force  # Drop and recreate tables\n</code></pre>"},{"location":"user-guide/cli-reference/#populate","title":"<code>populate</code>","text":"<p>Add videos to the database from config sources (search queries, URLs, files).</p> <pre><code># Use config file\ndata-miner populate --config config.yaml\n\n# Dry run (show what would be added)\ndata-miner populate --config config.yaml --dry-run\n</code></pre>"},{"location":"user-guide/cli-reference/#add-video","title":"<code>add-video</code>","text":"<p>Add a single video URL.</p> <pre><code>data-miner add-video \"https://youtube.com/watch?v=...\" \\\n    --project my_project \\\n    --source-type url\n</code></pre> <p>Options: - <code>--project</code> - Project name (default: from config) - <code>--source-type</code> - <code>url</code>, <code>search</code>, or <code>file</code> - <code>--source-info</code> - Additional metadata</p>"},{"location":"user-guide/cli-reference/#status","title":"<code>status</code>","text":"<p>Show pipeline status.</p> <pre><code># All projects\ndata-miner status\n\n# Specific project\ndata-miner status --project my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#worker-management","title":"Worker Management","text":""},{"location":"user-guide/cli-reference/#workers-setup","title":"<code>workers setup</code>","text":"<p>Generate supervisor configuration.</p> <pre><code>data-miner workers setup --config config.yaml\n</code></pre> <p>This creates <code>/etc/supervisor/conf.d/data_miner.conf</code> with worker definitions.</p>"},{"location":"user-guide/cli-reference/#workers-start","title":"<code>workers start</code>","text":"<p>Start all workers.</p> <pre><code>data-miner workers start\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-stop","title":"<code>workers stop</code>","text":"<p>Stop all workers.</p> <pre><code>data-miner workers stop\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-restart","title":"<code>workers restart</code>","text":"<p>Restart all workers.</p> <pre><code>data-miner workers restart\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-status","title":"<code>workers status</code>","text":"<p>Show supervisor worker status.</p> <pre><code>data-miner workers status\n</code></pre>"},{"location":"user-guide/cli-reference/#maintenance-commands","title":"Maintenance Commands","text":""},{"location":"user-guide/cli-reference/#delete-project","title":"<code>delete-project</code>","text":"<p>Delete a project and optionally its files.</p> <pre><code># Delete project (keep files)\ndata-miner delete-project my_project\n\n# Delete project and files\ndata-miner delete-project my_project --files\n\n# Also delete orphaned videos\ndata-miner delete-project my_project --files --orphans\n\n# Skip confirmation\ndata-miner delete-project my_project --yes\n</code></pre>"},{"location":"user-guide/cli-reference/#delete-videos","title":"<code>delete-videos</code>","text":"<p>Delete project-videos with optional filters.</p> <pre><code># Delete all FAILED videos\ndata-miner delete-videos --project my_project --pv-status FAILED\n\n# Delete videos and files\ndata-miner delete-videos --project my_project --pv-status FAILED --files\n</code></pre>"},{"location":"user-guide/cli-reference/#cleanup-orphans","title":"<code>cleanup-orphans</code>","text":"<p>Remove orphaned videos not linked to any project.</p> <pre><code>data-miner cleanup-orphans\ndata-miner cleanup-orphans --files  # Also delete files\n</code></pre>"},{"location":"user-guide/cli-reference/#force-dedup","title":"<code>force-dedup</code>","text":"<p>Force project back to DEDUP_READY stage (re-run cross-dedup).</p> <pre><code>data-miner force-dedup my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#force-detect","title":"<code>force-detect</code>","text":"<p>Force project back to DETECT_READY stage (re-run detection).</p> <pre><code>data-miner force-detect my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#environment-variables","title":"Environment Variables","text":"Variable Description <code>DATA_MINER_CONFIG</code> Path to config file <code>DATABASE_URL</code> PostgreSQL connection string <code>HF_TOKEN</code> HuggingFace token for private models <code>DATA_MINER_DEBUG</code> Set to <code>1</code> to disable heartbeat (dev only)"},{"location":"user-guide/cli-reference/#next-steps","title":"Next Steps","text":"<ul> <li>Quickstart - End-to-end tutorial</li> <li>Configuration - Config options</li> </ul>"},{"location":"user-guide/configuration/","title":"Configuration","text":"<p>Data Miner uses YAML configuration files with OmegaConf for variable interpolation and Pydantic for validation.</p>"},{"location":"user-guide/configuration/#configuration-loading","title":"Configuration Loading","text":"<p>The config system supports three modes:</p> <ol> <li>Default config - Built-in defaults from <code>data_miner/config/default.yaml</code></li> <li>User config - Override with <code>--config path/to/config.yaml</code></li> <li>Environment variable - Set <code>DATA_MINER_CONFIG=/path/to/config.yaml</code></li> </ol> <p>User configs are merged with defaults, so you only need to specify overrides.</p>"},{"location":"user-guide/configuration/#minimal-config-example","title":"Minimal Config Example","text":"<pre><code># config.yaml\nproject_name: \"glass_doors\"\noutput_dir: \"./output\"\n\ninput:\n  search_queries:\n    - \"glass door installation\"\n    - \"sliding glass door\"\n  max_results_per_query: 50\n\nfilter:\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding door\"\n</code></pre>"},{"location":"user-guide/configuration/#full-configuration-reference","title":"Full Configuration Reference","text":""},{"location":"user-guide/configuration/#project-settings","title":"Project Settings","text":"<pre><code>project_name: \"my_project\"\noutput_dir: \"./output\"\nproject_output_dir: \"${output_dir}/projects/${project_name}\"\ndevice: \"auto\"  # auto, cuda, cuda:0, cpu\n</code></pre> <p>Variable Interpolation: Use <code>${section.key}</code> to reference other config values.</p>"},{"location":"user-guide/configuration/#input-sources","title":"Input Sources","text":"<pre><code>input:\n  # YouTube search\n  search_enabled: true\n  search_queries:\n    - \"glass door installation\"\n  max_results_per_query: 50\n\n  # Direct URLs\n  urls:\n    - \"https://www.youtube.com/watch?v=abc123\"\n\n  # URL file (one URL per line)\n  url_file: \"urls.txt\"\n</code></pre>"},{"location":"user-guide/configuration/#database","title":"Database","text":"<pre><code>database:\n  url: \"postgresql://postgres:postgres@localhost:5432/data_miner\"\n</code></pre>"},{"location":"user-guide/configuration/#supervisor-worker-counts","title":"Supervisor (Worker Counts)","text":"<pre><code>supervisor:\n  download_workers: 3    # Parallel downloaders\n  extract_workers: 2     # Frame extractors\n  filter_workers: 1      # ML filter workers (GPU-bound)\n  dedup_workers: 1       # Deduplication workers\n  detect_workers: 1      # Detection workers\n</code></pre> <p>Set any worker count to <code>0</code> to disable that stage.</p>"},{"location":"user-guide/configuration/#download-stage","title":"Download Stage","text":"<pre><code>download:\n  output_dir: \"${output_dir}/videos\"\n  format: \"bestvideo[height&lt;=1080]+bestaudio/best[height&lt;=1080]\"\n  max_resolution: 1080\n  timeout: 300\n\n  # Rate limiting (avoid YouTube blocks)\n  sleep_interval: 30         # Min seconds between downloads\n  max_sleep_interval: 60     # Max seconds (randomized)\n  sleep_requests: 10         # Seconds between API requests\n\n  # Hashtag blocklist file\n  blocked_hashtag_patterns: \"blocked_hashtags.txt\"\n</code></pre>"},{"location":"user-guide/configuration/#extract-stage","title":"Extract Stage","text":"<pre><code>extract:\n  output_dir: \"${output_dir}/frames_raw\"\n  strategy: \"interval\"       # interval, time, keyframe\n  interval_frames: 30        # Every N frames\n  interval_seconds: 1.0      # Every N seconds (for time strategy)\n  max_frames_per_video: 5000\n  image_format: \"jpg\"        # jpg, png, webp\n  quality: 95                # JPEG/WebP quality (1-100)\n</code></pre>"},{"location":"user-guide/configuration/#filter-stage-siglip2","title":"Filter Stage (SigLIP2)","text":"<pre><code>filter:\n  output_dir: \"${project_output_dir}/frames_filtered\"\n  device: \"${device}\"\n  model_id: \"siglip2-so400m\"   # siglip2-so400m, siglip2-giant\n  batch_size: 32\n\n  # Thresholds\n  threshold: 0.25              # Min positive match score\n  margin_threshold: 0.05       # Positive must beat negative by this\n\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding door\"\n\n  negative_prompts:\n    - \"a glass wall\"\n    - \"a mirror\"\n</code></pre>"},{"location":"user-guide/configuration/#dedup-stage-faiss","title":"Dedup Stage (FAISS)","text":"<pre><code>dedup:\n  output_dir: \"${project_output_dir}/frames_dedup\"\n  device: \"${device}\"\n  model_type: \"dino\"           # dino, siglip\n  dino_model_id: \"dinov3-base\" # dinov2-base, dinov3-base, etc.\n  threshold: 0.90              # Similarity threshold\n  batch_size: 64\n  k_neighbors: 50              # FAISS KNN search depth\n</code></pre>"},{"location":"user-guide/configuration/#detect-stage","title":"Detect Stage","text":"<pre><code>detect:\n  output_dir: \"${project_output_dir}/detections\"\n  device: \"${device}\"\n  detector: \"grounding_dino\"   # grounding_dino, owlv2, florence2\n  threshold: 0.3\n  confidence_threshold: 0.3\n  batch_size: 16\n  save_visualizations: true\n</code></pre>"},{"location":"user-guide/configuration/#monitor-settings","title":"Monitor Settings","text":"<p>The monitor worker handles:</p> <ul> <li>Project stage transitions (e.g., FILTERING \u2192 DEDUP_READY)</li> <li>Stale lock recovery (resets locks from crashed workers)</li> <li>Frame count aggregation</li> </ul> <pre><code>monitor:\n  poll_interval: 10                   # Seconds between checks\n  stale_threshold_minutes: 2          # Reset stale locks after N minutes\n  long_running_threshold_minutes: 30  # Warn about old locks\n  cleanup_extracted_videos: false     # Delete videos after extraction\n</code></pre>"},{"location":"user-guide/configuration/#backup-settings","title":"Backup Settings","text":"<p>The backup worker syncs <code>frames_raw/</code> to a remote destination after videos are extracted.</p> <pre><code>backup:\n  enabled: false                    # Enable backup worker\n  remote_dest: \"user@host:/path\"    # SSH destination or local path\n  delete_after_backup: false        # Delete local frames after verified backup\n  poll_interval: 300                # Seconds between backup checks\n  verification_timeout: 1800        # Seconds for rsync verification\n</code></pre> <p>Note: Backup uses rsync over SSH. Ensure SSH keys are configured for passwordless access.</p>"},{"location":"user-guide/configuration/#logging-grafana-loki","title":"Logging (Grafana + Loki)","text":"<pre><code>logging:\n  level: \"INFO\"                                        # DEBUG, INFO, WARNING, ERROR\n  loki_url: \"http://localhost:3100/loki/api/v1/push\"   # Loki push endpoint\n  log_dir: \"output/logs\"                               # Local log directory\n</code></pre> <p>Logs are automatically sent to:</p> <ol> <li>Console - Always enabled</li> <li>File - If <code>LOG_FILE</code> env var is set</li> <li>Loki - If <code>python-logging-loki</code> is installed and Loki is running</li> </ol> <p>Access logs in Grafana:</p> <ol> <li>Open <code>http://localhost:3000</code></li> <li>Add Loki data source: <code>http://loki:3100</code></li> <li>Use LogQL queries: <code>{application=\"data_miner\"}</code></li> </ol>"},{"location":"user-guide/configuration/#model-id-reference","title":"Model ID Reference","text":"Stage Model ID Full HuggingFace Path Filter <code>siglip2-so400m</code> <code>google/siglip2-so400m-patch14-384</code> Filter <code>siglip2-giant</code> <code>google/siglip2-giant-opt-patch16-384</code> Dedup <code>dinov3-base</code> <code>facebook/dinov3-vitb16-pretrain-lvd1689m</code> Dedup <code>dinov2-large</code> <code>facebook/dinov2-large</code> Detect <code>grounding_dino</code> <code>IDEA-Research/grounding-dino-base</code> Detect <code>florence2</code> <code>microsoft/Florence-2-large</code>"},{"location":"user-guide/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>CLI Reference - Available commands</li> <li>Quickstart - Run the pipeline</li> </ul>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers installing Data Miner and its dependencies.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+</li> <li>PostgreSQL 15+ (local or remote)</li> <li>FFmpeg (for video processing)</li> </ul>"},{"location":"user-guide/installation/#quick-install","title":"Quick Install","text":"<pre><code># Clone repository\ngit clone https://github.com/tycoai/data_miner.git\ncd data_miner\n\n# Install with uv (recommended)\nuv pip install -e .\n\n# Or with pip\npip install -e .\n</code></pre>"},{"location":"user-guide/installation/#postgresql-setup","title":"PostgreSQL Setup","text":""},{"location":"user-guide/installation/#option-1-docker-compose-recommended","title":"Option 1: Docker Compose (Recommended)","text":"<pre><code># Start PostgreSQL container\ndocker compose up -d\n\n# Verify it's running\ndocker compose ps\n</code></pre> <p>The included <code>docker-compose.yaml</code> starts PostgreSQL on port 5432 with default credentials. It also includes:</p> <ul> <li>Loki - Log aggregation at <code>http://localhost:3100</code></li> <li>Grafana - Log visualization at <code>http://localhost:3000</code></li> <li>Adminer - Database admin UI at <code>http://localhost:8880</code></li> </ul> <pre><code># Fix permissions for Loki and Grafana (first time only)\nsudo chown -R 10001:10001 data/loki\nsudo chown -R 472:472 data/grafana\n</code></pre>"},{"location":"user-guide/installation/#option-2-local-postgresql","title":"Option 2: Local PostgreSQL","text":"<pre><code># Create database\ncreatedb data_miner\n\n# Or via psql\npsql -c \"CREATE DATABASE data_miner;\"\n</code></pre>"},{"location":"user-guide/installation/#environment-configuration","title":"Environment Configuration","text":"<p>Copy the example environment file:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> with your settings:</p> <pre><code># Database URL (default works with Docker Compose)\nDATABASE_URL=postgresql://postgres:postgres@localhost:5432/data_miner\n\n# Hugging Face token (optional, for private models)\n# Get from: https://huggingface.co/settings/tokens\nHF_TOKEN=your_token_here\n\n# Debug mode (disables heartbeat - for development only)\n# DATA_MINER_DEBUG=1\n</code></pre>"},{"location":"user-guide/installation/#initialize-database","title":"Initialize Database","text":"<pre><code># Create tables\ndata-miner init-db\n\n# Verify connection\ndata-miner status\n</code></pre>"},{"location":"user-guide/installation/#gpu-setup-optional","title":"GPU Setup (Optional)","text":"<p>For ML inference, ensure CUDA is available:</p> <pre><code># Check CUDA availability\npython -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre> <p>The pipeline automatically falls back to CPU if CUDA is unavailable.</p>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Check CLI is available\ndata-miner --help\n\n# Check database connection\ndata-miner status\n</code></pre>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - Set up your pipeline config</li> <li>Quickstart - Run your first pipeline</li> </ul>"},{"location":"user-guide/quickstart/","title":"Quickstart","text":"<p>This guide walks through running a complete video mining pipeline.</p>"},{"location":"user-guide/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Data Miner installed</li> <li>PostgreSQL running (via Docker Compose or local)</li> <li>Database initialized (<code>data-miner init-db</code>)</li> </ul>"},{"location":"user-guide/quickstart/#step-1-create-configuration","title":"Step 1: Create Configuration","text":"<p>Create a config file <code>config.yaml</code>:</p> <pre><code>project_name: \"glass_doors_demo\"\noutput_dir: \"./output\"\n\ninput:\n  search_queries:\n    - \"glass door installation tutorial\"\n  max_results_per_query: 10  # Start small for testing\n\n# Reduced workers for demo\nsupervisor:\n  download_workers: 2\n  extract_workers: 1\n  filter_workers: 1\n  dedup_workers: 1\n  detect_workers: 1\n\nfilter:\n  threshold: 0.25\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding glass door\"\n  negative_prompts:\n    - \"a window\"\n    - \"a mirror\"\n</code></pre>"},{"location":"user-guide/quickstart/#step-2-initialize-database","title":"Step 2: Initialize Database","text":"<pre><code># Create tables (first time only)\ndata-miner init-db\n\n# Verify\ndata-miner status\n</code></pre>"},{"location":"user-guide/quickstart/#step-3-populate-videos","title":"Step 3: Populate Videos","text":"<pre><code># Search YouTube and add videos to database\ndata-miner populate --config config.yaml\n\n# Check status\ndata-miner status --project glass_doors_demo\n</code></pre> <p>Expected output: <pre><code>Project: glass_doors_demo\n  Stage: POPULATING\n  Videos: 10 total\n    PENDING: 10\n</code></pre></p>"},{"location":"user-guide/quickstart/#step-4-setup-workers","title":"Step 4: Setup Workers","text":"<pre><code># Generate supervisor config\ndata-miner workers setup --config config.yaml\n\n# Verify config was created\ncat /etc/supervisor/conf.d/data_miner.conf\n</code></pre>"},{"location":"user-guide/quickstart/#step-5-start-pipeline","title":"Step 5: Start Pipeline","text":"<pre><code># Start all workers\ndata-miner workers start\n\n# Monitor progress\nwatch -n 5 \"data-miner status --project glass_doors_demo\"\n</code></pre>"},{"location":"user-guide/quickstart/#step-6-monitor-progress","title":"Step 6: Monitor Progress","text":"<pre><code># Check worker status\ndata-miner workers status\n\n# Check pipeline status\ndata-miner status --project glass_doors_demo\n</code></pre> <p>As the pipeline progresses, you'll see:</p> <ol> <li>POPULATING \u2192 Videos being downloaded/extracted</li> <li>FILTERING \u2192 Frames being filtered</li> <li>DEDUP_READY \u2192 All videos filtered, cross-dedup starting</li> <li>DETECT_READY \u2192 Dedup complete, detection starting</li> <li>COMPLETE \u2192 Pipeline finished</li> </ol>"},{"location":"user-guide/quickstart/#step-7-view-results","title":"Step 7: View Results","text":"<pre><code># Output directory structure\ntree output/projects/glass_doors_demo/\n</code></pre> <pre><code>output/projects/glass_doors_demo/\n\u251c\u2500\u2500 frames_filtered/     # Frames that passed filter\n\u2502   \u2514\u2500\u2500 {video_id}/\n\u251c\u2500\u2500 frames_dedup/        # Unique frames (flat)\n\u2514\u2500\u2500 detections/\n    \u251c\u2500\u2500 annotations.json # COCO-format annotations\n    \u2514\u2500\u2500 visualizations/  # Bounding box images\n</code></pre>"},{"location":"user-guide/quickstart/#common-workflows","title":"Common Workflows","text":""},{"location":"user-guide/quickstart/#re-run-deduplication","title":"Re-run Deduplication","text":"<pre><code>data-miner force-dedup glass_doors_demo\ndata-miner workers restart\n</code></pre>"},{"location":"user-guide/quickstart/#re-run-detection","title":"Re-run Detection","text":"<pre><code>data-miner force-detect glass_doors_demo\ndata-miner workers restart\n</code></pre>"},{"location":"user-guide/quickstart/#stop-pipeline","title":"Stop Pipeline","text":"<pre><code>data-miner workers stop\n</code></pre>"},{"location":"user-guide/quickstart/#delete-and-start-over","title":"Delete and Start Over","text":"<pre><code>data-miner delete-project glass_doors_demo --files --yes\ndata-miner init-db --force\n</code></pre>"},{"location":"user-guide/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/quickstart/#workers-not-starting","title":"Workers Not Starting","text":"<pre><code># Check supervisor logs\nsudo tail -f /var/log/supervisor/supervisord.log\n\n# Check worker logs\ntail -f output/logs/download_*.log\n</code></pre>"},{"location":"user-guide/quickstart/#videos-stuck","title":"Videos Stuck","text":"<pre><code># Check for stale locks (monitor worker handles this automatically)\ndata-miner status --project glass_doors_demo\n</code></pre>"},{"location":"user-guide/quickstart/#gpu-memory-issues","title":"GPU Memory Issues","text":"<p>Reduce batch size in config:</p> <pre><code>filter:\n  batch_size: 16  # Default: 32\n\ndedup:\n  batch_size: 32  # Default: 64\n</code></pre>"},{"location":"user-guide/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - All config options</li> <li>Architecture Overview - System design</li> </ul>"}]}