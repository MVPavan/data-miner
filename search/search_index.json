{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Data Miner","text":"<p>A PostgreSQL-backed, supervisor-managed video processing pipeline for generating large-scale computer vision datasets from YouTube videos.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd0d YouTube Search - Find videos by keywords and hashtags</li> <li>\ud83d\udce5 Smart Downloads - Rate-limited downloading with hashtag blocklists</li> <li>\ud83c\udfac Frame Extraction - Configurable sampling strategies (interval, time, keyframe)</li> <li>\ud83c\udfaf ML Filtering - SigLIP2-based image-text similarity filtering</li> <li>\ud83d\udd04 Deduplication - DINOv3/FAISS-based cross-video deduplication</li> <li>\ud83c\udfaf Object Detection - Open-set detection (GroundingDINO, OWLv2)</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"User Guide Developer Docs Installation Architecture Overview Configuration Database Models CLI Reference Worker System Quickstart Contributing"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart LR\n    subgraph Central[\"Central Pipeline\"]\n        D[Download] --&gt; E[Extract]\n    end\n\n    subgraph Project[\"Per-Project Pipeline\"]\n        F[Filter] --&gt; DU[Cross-Dedup] --&gt; DT[Detect]\n    end\n\n    E --&gt; F</code></pre> <p>The pipeline uses:</p> <ul> <li>PostgreSQL for state management with row-level locking</li> <li>Supervisor for worker process management</li> <li>Heartbeat-based locking for concurrent safety</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<pre><code># Install\npip install -e .\n\n# Initialize database\ndata-miner init-db\n\n# Add videos and run pipeline\ndata-miner populate --config config.yaml\ndata-miner workers setup --config config.yaml\ndata-miner workers start\n</code></pre> <p>See Quickstart for the complete workflow.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 cli.py              # CLI commands\n\u251c\u2500\u2500 config/             # Configuration system\n\u251c\u2500\u2500 db/                 # Database layer\n\u251c\u2500\u2500 workers/            # Supervisor-managed workers\n\u251c\u2500\u2500 modules/            # Core processing logic\n\u251c\u2500\u2500 models/             # ML model wrappers\n\u2514\u2500\u2500 utils/              # Utilities\n</code></pre>"},{"location":"architecture/database-models/","title":"Database Models","text":"<p>Data Miner uses SQLModel (Pydantic + SQLAlchemy) with PostgreSQL.</p>"},{"location":"architecture/database-models/#entity-relationship","title":"Entity Relationship","text":"<pre><code>erDiagram\n    PROJECT ||--o{ PROJECT_VIDEO : has\n    VIDEO ||--o{ PROJECT_VIDEO : referenced_by\n\n    PROJECT {\n        int project_id PK\n        string name UK\n        ProjectStatus project_stage\n        int total_videos\n        int videos_downloaded\n        int videos_extracted\n        int extracted_frames\n        int filtered_frames\n    }\n\n    VIDEO {\n        string video_id PK\n        string url\n        VideoStatus status\n        string video_path\n        string frames_dir\n        int frame_count\n    }\n\n    PROJECT_VIDEO {\n        int id PK\n        int project_id FK\n        string video_id FK\n        ProjectVideoStatus status\n        string filtered_dir\n        int passed_frames\n    }</code></pre>"},{"location":"architecture/database-models/#tables","title":"Tables","text":""},{"location":"architecture/database-models/#project","title":"Project","text":"<p>Tracks project-level state and cross-video operations.</p> Column Type Description <code>project_id</code> int Primary key <code>name</code> str Unique project name <code>project_stage</code> ProjectStatus Current stage <code>total_videos</code> int Total videos in project <code>videos_pending</code> int Videos pending download <code>videos_downloaded</code> int Videos downloaded (cumulative, includes extracted) <code>videos_extracted</code> int Videos with frames extracted <code>videos_failed</code> int Failed videos <code>extracted_frames</code> int Total frames extracted <code>filtered_frames</code> int Total frames passed filter <code>unique_frames</code> int Frames after dedup <code>dedup_dir</code> str Dedup output directory <code>detect_dir</code> str Detection output directory <p>Note: Video counts are cumulative where appropriate. <code>videos_downloaded</code> includes extracted videos.</p>"},{"location":"architecture/database-models/#video","title":"Video","text":"<p>Central video table, shared across projects. Tracks download and extraction.</p> Column Type Description <code>video_id</code> str YouTube video ID (PK) <code>url</code> str Full YouTube URL <code>source_type</code> SourceType <code>SEARCH</code>, <code>URL</code>, <code>FILE</code>, <code>MANUAL</code> <code>source_info</code> str Search query or filename <code>video_path</code> str Downloaded video path <code>frames_dir</code> str Extracted frames directory <code>frame_count</code> int Number of extracted frames <code>status</code> VideoStatus Current status <code>locked_by</code> str Worker ID holding lock <code>heartbeat_at</code> datetime Last heartbeat timestamp"},{"location":"architecture/database-models/#projectvideo","title":"ProjectVideo","text":"<p>Links videos to projects with project-specific processing state.</p> Column Type Description <code>id</code> int Primary key <code>project_id</code> int FK to projects <code>video_id</code> str FK to videos <code>filtered_dir</code> str Filtered frames directory <code>passed_frames</code> int Frames that passed filter <code>status</code> ProjectVideoStatus Current status <code>locked_by</code> str Worker ID holding lock <code>heartbeat_at</code> datetime Last heartbeat timestamp"},{"location":"architecture/database-models/#status-enums","title":"Status Enums","text":""},{"location":"architecture/database-models/#videostatus-central-stages","title":"VideoStatus (Central Stages)","text":"Status Description <code>PENDING</code> Ready for download <code>DOWNLOADING</code> Download in progress <code>DOWNLOADED</code> Download complete <code>EXTRACTING</code> Extraction in progress <code>EXTRACTED</code> Extraction complete <code>FAILED</code> Processing failed"},{"location":"architecture/database-models/#projectvideostatus-per-project-stages","title":"ProjectVideoStatus (Per-Project Stages)","text":"Status Description <code>PENDING</code> Ready for filtering <code>FILTERING</code> Filter in progress <code>FILTERED</code> Filtered with frames <code>FILTERED_EMPTY</code> Filtered, no frames passed <code>FAILED</code> Processing failed"},{"location":"architecture/database-models/#projectstatus-project-level","title":"ProjectStatus (Project-Level)","text":"Status Description <code>POPULATING</code> Videos being added <code>FILTERING</code> Filter workers active <code>DEDUP_READY</code> Ready for cross-dedup <code>DEDUPING</code> Cross-dedup in progress <code>DETECT_READY</code> Ready for detection <code>DETECTING</code> Detection in progress <code>COMPLETE</code> Pipeline finished"},{"location":"architecture/database-models/#concurrency-control","title":"Concurrency Control","text":"<p>All workers use row-level locking with heartbeats:</p> <pre><code># Claim pattern with FOR UPDATE SKIP LOCKED\nstmt = (\n    select(Video)\n    .where(Video.status == status)\n    .with_for_update(skip_locked=True)\n    .limit(1)\n)\n</code></pre> <p>Heartbeat Recovery: Workers update <code>heartbeat_at</code> every 30 seconds. The monitor worker resets locks older than <code>stale_threshold_minutes</code>.</p>"},{"location":"architecture/database-models/#related-docs","title":"Related Docs","text":"<ul> <li>Workers - Worker system architecture</li> <li>Architecture Overview - Full system design</li> </ul>"},{"location":"architecture/overview/","title":"Data Miner - Architecture &amp; Code Walkthrough","text":"<p>A comprehensive guide to the architecture, design decisions, and code flow of Data Miner, a production-grade video mining pipeline for generating large-scale computer vision datasets from YouTube.</p>"},{"location":"architecture/overview/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Executive Summary</li> <li>Architecture Overview</li> <li>Project Structure</li> <li>Database Architecture</li> <li>Worker System</li> <li>Processing Modules</li> <li>ML Model Wrappers</li> <li>Configuration System</li> <li>CLI Interface</li> <li>Data Flow</li> <li>Comparison with Earlier Versions</li> <li>Appendix A: Earlier Versions</li> </ol>"},{"location":"architecture/overview/#executive-summary","title":"Executive Summary","text":"<p>Data Miner is a PostgreSQL-backed, supervisor-managed video processing pipeline designed to:</p> <ul> <li>Search YouTube for videos by keywords/hashtags</li> <li>Download highest quality videos with rate limiting</li> <li>Extract frames using configurable sampling strategies</li> <li>Filter frames using SigLIP2 image-text similarity</li> <li>Deduplicate frames using DINOv3/SigLIP2 embeddings with FAISS</li> <li>Detect objects using open-set detection models (GroundingDINO, OWLv2)</li> </ul>"},{"location":"architecture/overview/#key-design-decisions","title":"Key Design Decisions","text":"Aspect Current Design Rationale State Management PostgreSQL with SQLModel ACID guarantees, concurrent access, query flexibility Worker Model Long-running supervisor processes Automatic restart, centralized logging, process isolation Concurrency Row-level locking with heartbeats Prevents stale locks, supports worker crashes Processing Scope Central (Video) + Per-Project (ProjectVideo) Reuse downloads across projects, project-specific filtering Configuration OmegaConf + Pydantic YAML merging, validation, type safety"},{"location":"architecture/overview/#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart TB\n    subgraph CLI[\"CLI (cli.py)\"]\n        POPULATE[populate]\n        STATUS[status]\n        WORKERS[workers]\n    end\n\n    subgraph Database[\"PostgreSQL\"]\n        PROJ[(projects)]\n        VID[(videos)]\n        PV[(project_videos)]\n    end\n\n    subgraph Workers[\"Supervisor-Managed Workers\"]\n        DW[Download Worker]\n        EW[Extract Worker]\n        FW[Filter Worker]\n        CDW[Cross-Dedup Worker]\n        DTW[Detect Worker]\n        MON[Monitor Worker]\n        BKP[Backup Worker]\n    end\n\n    subgraph Modules[\"Processing Modules\"]\n        DOWN[downloader.py]\n        EXT[frame_extractor.py]\n        FILT[frame_filter.py]\n        DEDUP[deduplicator.py]\n        DET[detector.py]\n    end\n\n    subgraph Models[\"ML Models\"]\n        SIGLIP[SigLIPModel]\n        DINO[DINOv3Model]\n        GRDINO[GroundingDINO]\n    end\n\n    CLI --&gt; Database\n    Workers --&gt; Database\n    DW --&gt; DOWN\n    EW --&gt; EXT\n    FW --&gt; FILT\n    CDW --&gt; DEDUP\n    DTW --&gt; DET\n    FILT --&gt; SIGLIP\n    DEDUP --&gt; DINO\n    DET --&gt; GRDINO</code></pre>"},{"location":"architecture/overview/#processing-pipeline","title":"Processing Pipeline","text":"<pre><code>flowchart LR\n    subgraph Central[\"Central Pipeline (Video table)\"]\n        direction LR\n        D[Download] --&gt; E[Extract]\n    end\n\n    subgraph Project[\"Per-Project Pipeline (ProjectVideo table)\"]\n        direction LR\n        F[Filter] --&gt; DU[Cross-Dedup] --&gt; DT[Detect]\n    end\n\n    style Central fill:#e1f5fe\n    style Project fill:#f3e5f5\n\n    E --&gt; F</code></pre>"},{"location":"architecture/overview/#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 __init__.py                      # Package init\n\u251c\u2500\u2500 cli.py                           # Click CLI (813 lines)\n\u251c\u2500\u2500 logging.py                       # Loguru + Loki logging\n\u2502\n\u251c\u2500\u2500 config/                          # Configuration system\n\u2502   \u251c\u2500\u2500 __init__.py                  # Exports all config getters\n\u2502   \u251c\u2500\u2500 config.py                    # Pydantic models (161 lines)\n\u2502   \u251c\u2500\u2500 constants.py                 # Enums, model IDs, status maps (162 lines)\n\u2502   \u251c\u2500\u2500 loader.py                    # OmegaConf loader with caching (232 lines)\n\u2502   \u251c\u2500\u2500 default.yaml                 # Default configuration\n\u2502   \u2514\u2500\u2500 blocked_hashtags.txt         # Hashtag blocklist\n\u2502\n\u251c\u2500\u2500 db/                              # Database layer\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 connection.py                # SQLModel engine + session\n\u2502   \u251c\u2500\u2500 models.py                    # Project, Video, ProjectVideo (110 lines)\n\u2502   \u2514\u2500\u2500 operations.py                # CRUD + claim/release functions (962 lines)\n\u2502\n\u251c\u2500\u2500 workers/                         # Long-running worker processes\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py                      # Base worker classes (368 lines)\n\u2502   \u251c\u2500\u2500 download.py                  # Download worker (66 lines)\n\u2502   \u251c\u2500\u2500 extract.py                   # Extraction worker\n\u2502   \u251c\u2500\u2500 filter.py                    # Filter worker (89 lines)\n\u2502   \u251c\u2500\u2500 dedup.py                     # Cross-dedup worker (128 lines)\n\u2502   \u251c\u2500\u2500 detect.py                    # Detection worker (111 lines)\n\u2502   \u251c\u2500\u2500 monitor.py                   # Project monitor (196 lines)\n\u2502   \u2514\u2500\u2500 backup.py                    # Backup worker\n\u2502\n\u251c\u2500\u2500 modules/                         # Core processing logic\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 downloader.py                # yt-dlp wrapper\n\u2502   \u251c\u2500\u2500 frame_extractor.py           # PyAV frame extraction\n\u2502   \u251c\u2500\u2500 frame_filter.py              # SigLIP-based filtering (243 lines)\n\u2502   \u251c\u2500\u2500 deduplicator.py              # FAISS-based dedup (470 lines)\n\u2502   \u2514\u2500\u2500 detector.py                  # Object detection\n\u2502\n\u251c\u2500\u2500 models/                          # ML model wrappers\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base.py                      # BaseModel abstract class\n\u2502   \u251c\u2500\u2500 siglip_model.py              # SigLIP2 wrapper\n\u2502   \u251c\u2500\u2500 dinov3_model.py              # DINOv3 wrapper\n\u2502   \u2514\u2500\u2500 detector_models.py           # Detection model factory\n\u2502\n\u2514\u2500\u2500 utils/                           # Utility functions\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 device.py                    # CUDA/CPU device management\n    \u251c\u2500\u2500 io.py                        # File I/O utilities\n    \u251c\u2500\u2500 validators.py                # Input validation\n    \u251c\u2500\u2500 query_generator.py           # YouTube query generation\n    \u251c\u2500\u2500 db_helper.py                 # Database utilities\n    \u251c\u2500\u2500 migrate_registry.py          # YAML \u2192 DB migration\n    \u2514\u2500\u2500 ssh_helper.py                # SSH for remote backup\n</code></pre>"},{"location":"architecture/overview/#database-architecture","title":"Database Architecture","text":"<p>The database uses SQLModel (Pydantic + SQLAlchemy) with PostgreSQL.</p>"},{"location":"architecture/overview/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>erDiagram\n    PROJECT ||--o{ PROJECT_VIDEO : has\n    VIDEO ||--o{ PROJECT_VIDEO : referenced_by\n\n    PROJECT {\n        int project_id PK\n        string name UK\n        string output_dir\n        ProjectStatus project_stage\n        int extracted_frames\n        int filtered_frames\n        int unique_frames\n        string dedup_dir\n        string detect_dir\n        datetime created_at\n    }\n\n    VIDEO {\n        string video_id PK\n        string url\n        SourceType source_type\n        string source_info\n        string video_path\n        string frames_dir\n        int frame_count\n        string title\n        VideoStatus status\n        string error\n        string locked_by\n        datetime locked_at\n        datetime heartbeat_at\n        bool backed_up\n        datetime backed_up_at\n        datetime created_at\n        datetime updated_at\n    }\n\n    PROJECT_VIDEO {\n        int id PK\n        int project_id FK\n        string video_id FK\n        string filtered_dir\n        int passed_frames\n        ProjectVideoStatus status\n        string error\n        string locked_by\n        datetime locked_at\n        datetime heartbeat_at\n        datetime created_at\n        datetime updated_at\n    }</code></pre>"},{"location":"architecture/overview/#status-enums","title":"Status Enums","text":""},{"location":"architecture/overview/#videostatus-central-stages","title":"VideoStatus (Central Stages)","text":"Status Description <code>PENDING</code> Ready for download <code>DOWNLOADING</code> Worker is downloading <code>DOWNLOADED</code> Download complete <code>EXTRACTING</code> Worker is extracting frames <code>EXTRACTED</code> Extraction complete <code>FAILED</code> Processing failed"},{"location":"architecture/overview/#projectvideostatus-per-project-filter-stage","title":"ProjectVideoStatus (Per-Project Filter Stage)","text":"Status Description <code>PENDING</code> Ready for filtering <code>FILTERING</code> Worker is filtering <code>FILTERED</code> Filtering complete with frames <code>FILTERED_EMPTY</code> Filtering complete, no frames passed <code>FAILED</code> Processing failed"},{"location":"architecture/overview/#projectstatus-project-level-stages","title":"ProjectStatus (Project-Level Stages)","text":"Status Description <code>POPULATING</code> Videos being added/processed <code>FILTERING</code> Filter workers active <code>DEDUP_READY</code> All videos filtered, ready for cross-dedup <code>DEDUPING</code> Cross-dedup in progress <code>DETECT_READY</code> Cross-dedup done, ready for detection <code>DETECTING</code> Detection in progress <code>COMPLETE</code> Pipeline finished <code>FAILED</code> Pipeline failed"},{"location":"architecture/overview/#key-database-operations","title":"Key Database Operations","text":""},{"location":"architecture/overview/#claimrelease-pattern","title":"Claim/Release Pattern","text":"<p>All workers use atomic <code>FOR UPDATE SKIP LOCKED</code> for concurrent safety:</p> <pre><code># claim_next_video() in operations.py\nstmt = (\n    select(Video)\n    .where(\n        and_(\n            Video.status == status,\n            or_(\n                Video.locked_by.is_(None),\n                Video.heartbeat_at &lt; threshold  # Stale lock recovery\n            )\n        )\n    )\n    .with_for_update(skip_locked=True)\n    .limit(1)\n)\n</code></pre>"},{"location":"architecture/overview/#heartbeat-system","title":"Heartbeat System","text":"<p>Workers update heartbeats every 30 seconds to prove liveness:</p> <pre><code>def update_video_heartbeat(session: Session, video_id: str, worker_id: str) -&gt; bool:\n    \"\"\"Returns False if lock was lost (another worker completed this).\"\"\"\n    video = session.get(Video, video_id)\n    if video.locked_by != worker_id:\n        return False  # Lost lock!\n    video.heartbeat_at = datetime.utcnow()\n    session.commit()\n    return True\n</code></pre>"},{"location":"architecture/overview/#worker-system","title":"Worker System","text":""},{"location":"architecture/overview/#worker-hierarchy","title":"Worker Hierarchy","text":"<pre><code>classDiagram\n    class _BaseWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +stage_name: StageName\n        +poll_interval: float\n        +heartbeat_interval: float\n        +_init_project()\n        +_start_heartbeat(item_id)\n        +_stop_heartbeat()\n        +_heartbeat_loop()*\n        +run()*\n    }\n\n    class BaseVideoWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +input_status()*\n        +in_progress_status()*\n        +output_status()*\n        +process(video: Video)*\n        +run()\n    }\n\n    class BaseProjectVideosWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +input_status()*\n        +in_progress_status()*\n        +output_status()*\n        +process(pv: ProjectVideo, video: Video)*\n        +run()\n    }\n\n    class BaseProjectStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +worker_name: str\n        +claim_project(session)*\n        +process(project: Project)*\n        +complete_project(session, project_id, result)*\n        +fail_project(session, project_id, error)*\n        +run()\n    }\n\n    _BaseWorker &lt;|-- BaseVideoWorker\n    _BaseWorker &lt;|-- BaseProjectVideosWorker\n    _BaseWorker &lt;|-- BaseProjectStageWorker\n\n    BaseVideoWorker &lt;|-- DownloadWorker\n    BaseVideoWorker &lt;|-- ExtractWorker\n    BaseProjectVideosWorker &lt;|-- FilterWorker\n    BaseProjectStageWorker &lt;|-- CrossDedupWorker\n    BaseProjectStageWorker &lt;|-- ProjectDetectWorker</code></pre>"},{"location":"architecture/overview/#worker-types","title":"Worker Types","text":"Worker Base Class Works On Responsibility <code>DownloadWorker</code> <code>BaseVideoWorker</code> Video table Download YouTube videos <code>ExtractWorker</code> <code>BaseVideoWorker</code> Video table Extract frames from videos <code>FilterWorker</code> <code>BaseProjectVideosWorker</code> ProjectVideo table Filter frames with SigLIP2 <code>CrossDedupWorker</code> <code>BaseProjectStageWorker</code> Project level Cross-video deduplication <code>ProjectDetectWorker</code> <code>BaseProjectStageWorker</code> Project level Object detection <code>ProjectMonitorWorker</code> Custom N/A Stage transitions, stale lock recovery <code>BackupWorker</code> Custom Video table rsync backup to remote"},{"location":"architecture/overview/#worker-lifecycle","title":"Worker Lifecycle","text":"<pre><code>sequenceDiagram\n    participant W as Worker\n    participant DB as PostgreSQL\n    participant M as Module\n\n    loop Main Loop\n        W-&gt;&gt;DB: claim_next_video(status, worker_id)\n        alt No work available\n            W-&gt;&gt;W: sleep(poll_interval)\n        else Work claimed\n            W-&gt;&gt;W: _start_heartbeat(video_id)\n            W-&gt;&gt;M: process(video)\n            alt Success\n                W-&gt;&gt;DB: release_video(new_status, **updates)\n            else Failure\n                W-&gt;&gt;DB: mark_video_failed(error)\n            end\n            W-&gt;&gt;W: _stop_heartbeat()\n        end\n    end</code></pre>"},{"location":"architecture/overview/#supervisor-integration","title":"Supervisor Integration","text":"<p>Workers are managed by supervisord:</p> <pre><code>[program:download]\ncommand=/path/to/.venv/bin/python -m data_miner.workers.download --config %(ENV_CONFIG)s\nnumprocs=3\nprocess_name=%(program_name)s_%(process_num)02d\nautorestart=true\nstartsecs=5\nstopwaitsecs=30\n</code></pre> <p>Generated via <code>data-miner workers setup --config path/to/config.yaml</code></p>"},{"location":"architecture/overview/#processing-modules","title":"Processing Modules","text":""},{"location":"architecture/overview/#1-downloader-downloaderpy","title":"1. Downloader (<code>downloader.py</code>)","text":"<p>Downloads YouTube videos using yt-dlp with configurable rate limiting.</p> <p>Key Features:</p> <ul> <li>Format selection (max 1080p by default)</li> <li>Rate limiting (sleep intervals between downloads)</li> <li>Hashtag blocklist filtering</li> <li>Timeout handling</li> </ul> <pre><code>class YouTubeDownloader:\n    def download_single(self, url: str) -&gt; DownloadResult:\n        \"\"\"Download a single video, returns path and metadata.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#2-frame-extractor-frame_extractorpy","title":"2. Frame Extractor (<code>frame_extractor.py</code>)","text":"<p>Extracts frames from videos using PyAV.</p> <p>Sampling Strategies: | Strategy | Description | |----------|-------------| | <code>interval</code> | Every N frames (default: 30) | | <code>time</code> | Every N seconds | | <code>keyframe</code> | Scene change detection |</p>"},{"location":"architecture/overview/#3-frame-filter-frame_filterpy","title":"3. Frame Filter (<code>frame_filter.py</code>)","text":"<p>Filters frames based on SigLIP2 image-text similarity.</p> <p>Two Modes:</p> <ol> <li>Positive-only: Frame passes if <code>max(positive_scores) &gt; threshold</code></li> <li>Positive + Negative: Also requires <code>max(positive) - max(negative) &gt; margin</code></li> </ol> <pre><code>class FrameFilter:\n    def filter_frames(\n        self,\n        frame_paths: list[Path],\n        video_id: str = \"unknown\",\n    ) -&gt; FilterResult:\n        \"\"\"\n        Filter frames based on similarity to text prompts.\n        Returns FilterResult with passing frames.\n        \"\"\"\n</code></pre>"},{"location":"architecture/overview/#4-deduplicator-deduplicatorpy","title":"4. Deduplicator (<code>deduplicator.py</code>)","text":"<p>Removes duplicate frames using embedding-based similarity with FAISS.</p> <p>Two-Phase Algorithm:</p> <ol> <li>Phase 1 - Per-Video: Remove temporal duplicates within each video using greedy selection</li> <li>Phase 2 - Cross-Video: Use FAISS ANN search to find and remove duplicates across all videos</li> </ol> <pre><code>flowchart LR\n    subgraph Phase1[\"Phase 1: Per-Video\"]\n        A[Embeddings] --&gt; B[Cosine Similarity]\n        B --&gt; C[Greedy Selection]\n    end\n\n    subgraph Phase2[\"Phase 2: Cross-Video\"]\n        C --&gt; D[FAISS Index]\n        D --&gt; E[KNN Search]\n        E --&gt; F[Union-Find Merge]\n    end\n\n    F --&gt; G[Unique Frames]</code></pre> <p>Supported Models:</p> <ul> <li>DINOv3 (default): Best quality embeddings</li> <li>SigLIP2: Memory-efficient, reuses filter model</li> </ul>"},{"location":"architecture/overview/#5-detector-detectorpy","title":"5. Detector (<code>detector.py</code>)","text":"<p>Runs open-set object detection on frames.</p> <p>Supported Detectors: | Detector | Model | Notes | |----------|-------|-------| | GroundingDINO | <code>IDEA-Research/grounding-dino-base</code> | Text-guided detection | | OWLv2 | <code>google/owlv2-base-patch16-ensemble</code> | Open-vocabulary |</p>"},{"location":"architecture/overview/#ml-model-wrappers","title":"ML Model Wrappers","text":""},{"location":"architecture/overview/#base-model-pattern","title":"Base Model Pattern","text":"<p>All ML models follow a consistent pattern:</p> <pre><code>class BaseModel(ABC):\n    def __init__(self):\n        self.model = None\n        self.processor = None\n        self._loaded = False\n\n    @abstractmethod\n    def load(self) -&gt; None:\n        \"\"\"Load model to device.\"\"\"\n\n    def unload(self) -&gt; None:\n        \"\"\"Free GPU memory.\"\"\"\n        del self.model, self.processor\n        torch.cuda.empty_cache()\n\n    def __enter__(self): self.load(); return self\n    def __exit__(self, *args): self.unload()\n</code></pre>"},{"location":"architecture/overview/#siglipmodel-siglip_modelpy","title":"SigLIPModel (<code>siglip_model.py</code>)","text":"<p>Wrapper for Google's SigLIP2 for image-text similarity:</p> <pre><code>class SigLIPModel(BaseModel):\n    def compute_similarity(\n        self, \n        images: list, \n        texts: list[str], \n        batch_size: int = 16\n    ) -&gt; np.ndarray:\n        \"\"\"Returns (N_images, N_texts) similarity matrix.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#dinov3model-dinov3_modelpy","title":"DINOv3Model (<code>dinov3_model.py</code>)","text":"<p>Wrapper for Meta's DINOv3/DINOv2 for image embeddings:</p> <pre><code>class DINOv3Model(BaseModel):\n    def get_embeddings(\n        self, \n        images: list, \n        batch_size: int = 32, \n        normalize: bool = True\n    ) -&gt; np.ndarray:\n        \"\"\"Returns (N_images, embedding_dim) array.\"\"\"\n</code></pre>"},{"location":"architecture/overview/#configuration-system","title":"Configuration System","text":""},{"location":"architecture/overview/#architecture","title":"Architecture","text":"<pre><code>flowchart LR\n    A[default.yaml] --&gt; C[OmegaConf Merge]\n    B[user.yaml] --&gt; C\n    C --&gt; D[lru_cache]\n    D --&gt; E[\"get_*_config()\"]\n    E --&gt; F[Pydantic Model]</code></pre>"},{"location":"architecture/overview/#pydantic-config-models","title":"Pydantic Config Models","text":"Config Key Fields <code>DownloadConfig</code> <code>output_dir</code>, <code>format</code>, <code>max_resolution</code>, <code>sleep_interval</code>, <code>blocked_hashtag_patterns</code> <code>ExtractionConfig</code> <code>output_dir</code>, <code>strategy</code>, <code>interval_frames</code>, <code>max_frames_per_video</code> <code>FilterConfig</code> <code>output_dir</code>, <code>model_id</code>, <code>positive_prompts</code>, <code>negative_prompts</code>, <code>threshold</code>, <code>margin_threshold</code> <code>DeduplicationConfig</code> <code>output_dir</code>, <code>model_type</code>, <code>dino_model_id</code>, <code>threshold</code>, <code>k_neighbors</code> <code>DetectionConfig</code> <code>output_dir</code>, <code>detector</code>, <code>confidence_threshold</code>, <code>save_visualizations</code> <code>DatabaseConfig</code> <code>url</code> <code>SupervisorConfig</code> <code>download_workers</code>, <code>extract_workers</code>, <code>filter_workers</code>, <code>dedup_workers</code>, <code>detect_workers</code> <code>MonitorConfig</code> <code>poll_interval</code>, <code>stale_threshold_minutes</code>, <code>cleanup_extracted_videos</code> <code>BackupConfig</code> <code>enabled</code>, <code>remote_dest</code>, <code>delete_after_backup</code>"},{"location":"architecture/overview/#config-loading","title":"Config Loading","text":"<pre><code>from data_miner.config import get_filter_config, get_download_config\n\n# Automatically loads from DATA_MINER_CONFIG env var or default.yaml\nconfig = get_filter_config()\nprint(config.positive_prompts)  # Type-safe access\n</code></pre>"},{"location":"architecture/overview/#cli-interface","title":"CLI Interface","text":"<p>Built with Click, the CLI provides commands for:</p>"},{"location":"architecture/overview/#core-commands","title":"Core Commands","text":"Command Description <code>init-db</code> Initialize database tables <code>populate</code> Add videos from config sources (search, URLs, files) <code>status</code> Show pipeline status <code>add-video</code> Add a single video URL"},{"location":"architecture/overview/#worker-management","title":"Worker Management","text":"Command Description <code>workers setup</code> Generate supervisor config <code>workers start</code> Start all workers <code>workers stop</code> Stop all workers <code>workers restart</code> Restart all workers <code>workers status</code> Show worker status"},{"location":"architecture/overview/#maintenance","title":"Maintenance","text":"Command Description <code>delete-project</code> Delete project and optionally files <code>delete-videos</code> Delete videos with filters <code>cleanup-orphans</code> Remove orphaned videos <code>force-dedup</code> Re-run cross-dedup for project <code>force-detect</code> Re-run detection for project"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>flowchart TB\n    subgraph Input[\"Input Sources\"]\n        YAML[Config YAML] --&gt; POP[populate command]\n        SEARCH[YouTube Search] --&gt; POP\n        URLS[URL Files] --&gt; POP\n    end\n\n    subgraph Central[\"Central Processing\"]\n        POP --&gt; VID[(Video Table)]\n        VID --&gt; DL[Download Worker]\n        DL --&gt; EX[Extract Worker]\n        EX --&gt; VID2[(Video: EXTRACTED)]\n    end\n\n    subgraph Project[\"Per-Project Processing\"]\n        VID2 --&gt; PV[(ProjectVideo Table)]\n        PV --&gt; FIL[Filter Worker]\n        FIL --&gt; PV2[(ProjectVideo: FILTERED)]\n        PV2 --&gt; MON[Monitor: DEDUP_READY]\n        MON --&gt; DEDUP[Cross-Dedup Worker]\n        DEDUP --&gt; DET[Detect Worker]\n    end\n\n    subgraph Output[\"Outputs\"]\n        DL --&gt; VIDS[videos/]\n        EX --&gt; RAW[frames_raw/]\n        FIL --&gt; FILT[frames_filtered/]\n        DEDUP --&gt; UNIQ[frames_dedup/]\n        DET --&gt; ANN[detections/annotations.json]\n    end</code></pre>"},{"location":"architecture/overview/#output-directory-structure","title":"Output Directory Structure","text":"<pre><code>output/\n\u251c\u2500\u2500 videos/                    # Downloaded videos (optional deletion)\n\u2502   \u2514\u2500\u2500 {video_id}.mp4\n\u251c\u2500\u2500 frames_raw/{video_id}/     # All extracted frames\n\u2502   \u2514\u2500\u2500 frame_{N:05d}.jpg\n\u251c\u2500\u2500 frames_filtered/{video_id}/ # Frames passing filter\n\u2502   \u2514\u2500\u2500 frame_{N:05d}.jpg\n\u251c\u2500\u2500 frames_dedup/              # Unique frames (flat)\n\u2502   \u2514\u2500\u2500 {video_id}_frame_{N:05d}.jpg\n\u2514\u2500\u2500 detections/\n    \u251c\u2500\u2500 annotations.json       # COCO-format annotations\n    \u2514\u2500\u2500 visualizations/        # Bounding box images\n</code></pre>"},{"location":"architecture/overview/#comparison-with-earlier-versions","title":"Comparison with Earlier Versions","text":""},{"location":"architecture/overview/#key-differences-current-vs-v3-earlier","title":"Key Differences: Current vs V3 (Earlier)","text":"Aspect Current Version V3 (Earlier) State Storage PostgreSQL database YAML file (<code>video_registry.yaml</code>) Worker Model Supervisor-managed long-running processes Single CLI command with sequential stages Concurrency Row-level locking with heartbeats Thread locks in-memory Multi-Project Native support (ProjectVideo table) Single registry per run Scalability Horizontal (multiple workers) Vertical (single machine) Fault Tolerance Worker restart, stale lock recovery Manual restart required Config OmegaConf with caching OmegaConf without caching Status Tracking Database queries YAML file reads"},{"location":"architecture/overview/#architecture-evolution","title":"Architecture Evolution","text":"<pre><code>timeline\n    title Data Miner Evolution\n    V3 : File-based registry\n       : Sequential pipeline\n       : Single threaded\n       : CLI-driven execution\n    Current : PostgreSQL backend\n            : Supervisor-managed workers\n            : Concurrent processing\n            : Heartbeat-based locking\n            : Project-level isolation</code></pre>"},{"location":"architecture/overview/#migration-benefits","title":"Migration Benefits","text":"<ol> <li>Reliability: Automatic worker restart on failure</li> <li>Scalability: Multiple workers for each stage</li> <li>Visibility: Database queries for status monitoring</li> <li>Isolation: Per-project filtering without re-downloading</li> <li>Recovery: Stale lock detection and reset</li> </ol>"},{"location":"architecture/overview/#appendix-a-earlier-versions","title":"Appendix A: Earlier Versions","text":""},{"location":"architecture/overview/#v3-architecture-file-based","title":"V3 Architecture (File-Based)","text":"<p>The earlier V3 version used a different architecture:</p>"},{"location":"architecture/overview/#key-components","title":"Key Components","text":"<ol> <li>Video Registry (<code>registry.py</code>): Pydantic-based YAML registry tracking video processing status</li> <li>Pipeline Orchestrator (<code>pipeline.py</code>): Sequential stage execution with lazy model loading</li> <li>CLI Commands: <code>run-config</code>, <code>validate-config</code>, registry management</li> </ol>"},{"location":"architecture/overview/#registry-structure","title":"Registry Structure","text":"<pre><code>metadata:\n  created: \"2024-01-01T00:00:00\"\n  version: \"3.0\"\n\nvideos:\n  dQw4w9WgXcQ:\n    video_id: dQw4w9WgXcQ\n    url: https://youtube.com/watch?v=dQw4w9WgXcQ\n    status: filtered\n    stages:\n      download:\n        completed: true\n        path: output/videos/dQw4w9WgXcQ.mp4\n      extraction:\n        completed: true\n        frame_count: 450\n</code></pre>"},{"location":"architecture/overview/#proposed-async-enhancement","title":"Proposed Async Enhancement","text":"<p>The original async pipeline implementation plan proposed an async evolution:</p> <ul> <li><code>asyncio</code> event loop for orchestration</li> <li><code>ThreadPoolExecutor</code> for blocking operations</li> <li><code>asyncio.Queue</code> for stage communication</li> <li><code>BaseStageWorker</code> abstract class</li> </ul> <p>This design influenced the current worker architecture but was adapted for database-backed state management instead of in-memory queues.</p>"},{"location":"architecture/overview/#parallel-pipeline-options","title":"Parallel Pipeline Options","text":"<p>Two approaches were considered in the parallel pipeline design:</p> <ol> <li>Per-Video Streaming: Each video flows through all stages concurrently</li> <li>Stage-Level Async Queues: Separate workers per stage with folder-based message passing</li> </ol> <p>The current implementation adopted Option 2 (stage-level workers) with database-backed coordination instead of async queues.</p>"},{"location":"architecture/overview/#summary","title":"Summary","text":"<p>Data Miner is a production-grade video mining pipeline featuring:</p> <ul> <li>PostgreSQL-backed state management with SQLModel for type safety</li> <li>Supervisor-managed workers for reliability and scalability</li> <li>Heartbeat-based locking for concurrent worker safety</li> <li>Project-level isolation enabling reuse of downloads across projects</li> <li>Two-phase deduplication with FAISS for O(N log N) scalability</li> <li>Flexible configuration with OmegaConf + Pydantic validation</li> <li>Multiple ML backends for filtering (SigLIP2) and detection (GroundingDINO, OWLv2)</li> </ul>"},{"location":"architecture/workers/","title":"Worker System","text":"<p>Data Miner uses supervisor-managed long-running worker processes.</p>"},{"location":"architecture/workers/#worker-hierarchy","title":"Worker Hierarchy","text":"<pre><code>classDiagram\n    class _BaseWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +stage_name: StageName\n        +poll_interval: float\n        +heartbeat_interval: float\n        +run()*\n    }\n\n    class BaseVideoWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +process(video: Video)*\n    }\n\n    class BaseProjectVideosWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +process(pv: ProjectVideo, video: Video)*\n    }\n\n    class BaseProjectStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +claim_project(session)*\n        +process(project)*\n        +complete_project()*\n    }\n\n    _BaseWorker &lt;|-- BaseVideoWorker\n    _BaseWorker &lt;|-- BaseProjectVideosWorker\n    _BaseWorker &lt;|-- BaseProjectStageWorker\n\n    BaseVideoWorker &lt;|-- DownloadWorker\n    BaseVideoWorker &lt;|-- ExtractWorker\n    BaseProjectVideosWorker &lt;|-- FilterWorker\n    BaseProjectStageWorker &lt;|-- CrossDedupWorker\n    BaseProjectStageWorker &lt;|-- DetectWorker</code></pre>"},{"location":"architecture/workers/#worker-types","title":"Worker Types","text":"Worker Base Class Table Responsibility <code>DownloadWorker</code> <code>BaseVideoWorker</code> Video Download YouTube videos <code>ExtractWorker</code> <code>BaseVideoWorker</code> Video Extract frames <code>FilterWorker</code> <code>BaseProjectVideosWorker</code> ProjectVideo Filter with SigLIP2 <code>CrossDedupWorker</code> <code>BaseProjectStageWorker</code> Project Cross-video dedup <code>DetectWorker</code> <code>BaseProjectStageWorker</code> Project Object detection <code>MonitorWorker</code> Custom \u2014 Stage transitions <code>BackupWorker</code> Custom Video Remote backup"},{"location":"architecture/workers/#worker-lifecycle","title":"Worker Lifecycle","text":"<pre><code>sequenceDiagram\n    participant W as Worker\n    participant DB as PostgreSQL\n    participant M as Module\n\n    loop Main Loop\n        W-&gt;&gt;DB: claim_next_item()\n        alt No work\n            W-&gt;&gt;W: sleep(poll_interval)\n        else Work claimed\n            W-&gt;&gt;W: start_heartbeat()\n            W-&gt;&gt;M: process()\n            W-&gt;&gt;DB: release_item()\n            W-&gt;&gt;W: stop_heartbeat()\n        end\n    end</code></pre>"},{"location":"architecture/workers/#supervisor-configuration","title":"Supervisor Configuration","text":"<p>Workers are managed by supervisord. Generated via:</p> <pre><code>data-miner workers setup --config config.yaml\n</code></pre> <p>Creates <code>/etc/supervisor/conf.d/data_miner.conf</code>:</p> <pre><code>[program:download]\ncommand=/path/.venv/bin/python -m data_miner.workers.download\nnumprocs=3\nprocess_name=%(program_name)s_%(process_num)02d\nautorestart=true\nstartsecs=5\nstopwaitsecs=30\n</code></pre>"},{"location":"architecture/workers/#heartbeat-system","title":"Heartbeat System","text":"<p>Workers update heartbeat timestamps every 30 seconds to prove liveness:</p> <pre><code>def _heartbeat_loop(self):\n    while not self._stop_event.wait(30):\n        with get_session() as session:\n            still_owner = update_heartbeat(session, item_id, worker_id)\n            if not still_owner:\n                os._exit(1)  # Supervisor restarts\n</code></pre> <p>Stale Lock Recovery: The monitor worker resets locks older than <code>stale_threshold_minutes</code>.</p>"},{"location":"architecture/workers/#implementing-custom-workers","title":"Implementing Custom Workers","text":""},{"location":"architecture/workers/#per-video-worker","title":"Per-Video Worker","text":"<pre><code>from data_miner.workers.base import BaseVideoWorker\nfrom data_miner.config import StageName\n\nclass MyWorker(BaseVideoWorker):\n    stage_name = StageName.DOWNLOAD  # Define stage\n\n    def process(self, video: Video) -&gt; dict:\n        # Do work...\n        return {\"video_path\": \"/path/to/video.mp4\"}\n</code></pre>"},{"location":"architecture/workers/#project-level-worker","title":"Project-Level Worker","text":"<pre><code>from data_miner.workers.base import BaseProjectStageWorker\n\nclass MyProjectWorker(BaseProjectStageWorker):\n    worker_name = \"my-stage\"\n\n    def claim_project(self, session):\n        # Claim project with specific status\n        pass\n\n    def process(self, project):\n        # Process entire project\n        return {\"unique_frames\": 500}\n\n    def complete_project(self, session, project_id, result):\n        # Update project status\n        pass\n</code></pre>"},{"location":"architecture/workers/#related-docs","title":"Related Docs","text":"<ul> <li>Database Models - Table schemas</li> <li>Architecture Overview - Full system design</li> </ul>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Guidelines for contributing to Data Miner.</p>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone and install in dev mode\ngit clone https://github.com/tycoai/data_miner.git\ncd data_miner\npip install -e \".[dev]\"\n\n# Start PostgreSQL\ndocker compose up -d\n\n# Initialize database\ndata-miner init-db\n</code></pre>"},{"location":"development/contributing/#project-structure","title":"Project Structure","text":"<pre><code>data_miner/\n\u251c\u2500\u2500 cli.py              # Click CLI commands\n\u251c\u2500\u2500 config/             # Pydantic configs + OmegaConf\n\u251c\u2500\u2500 db/                 # SQLModel + PostgreSQL\n\u251c\u2500\u2500 workers/            # Long-running workers\n\u251c\u2500\u2500 modules/            # Core processing logic\n\u251c\u2500\u2500 models/             # ML model wrappers\n\u2514\u2500\u2500 utils/              # Utilities\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<ul> <li>Python 3.12+ features allowed</li> <li>Type hints required for public functions</li> <li>Docstrings for classes and public methods</li> <li>Black for formatting (line length 100)</li> <li>isort for imports</li> </ul>"},{"location":"development/contributing/#adding-a-new-worker","title":"Adding a New Worker","text":"<ol> <li>Create <code>workers/my_worker.py</code></li> <li>Extend appropriate base class:</li> <li><code>BaseVideoWorker</code> for per-video processing</li> <li><code>BaseProjectVideosWorker</code> for per-project-video processing</li> <li> <p><code>BaseProjectStageWorker</code> for project-level operations</p> </li> <li> <p>Implement <code>process()</code> method</p> </li> <li>Add to supervisor config in <code>cli.py</code></li> </ol>"},{"location":"development/contributing/#testing","title":"Testing","text":"<pre><code># Run tests\npytest\n\n# With coverage\npytest --cov=data_miner\n</code></pre>"},{"location":"development/contributing/#database-migrations","title":"Database Migrations","text":"<p>Currently using SQLModel's <code>create_all()</code>. For schema changes:</p> <ol> <li>Update models in <code>db/models.py</code></li> <li>Run <code>data-miner init-db --force</code> (destroys data!)</li> </ol>"},{"location":"development/contributing/#submitting-changes","title":"Submitting Changes","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make changes with tests</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>Include: - Python version - PostgreSQL version - Config file (anonymized) - Error logs - Steps to reproduce</p>"},{"location":"k3s/01-concepts/","title":"K3s Complete Tutorial","text":""},{"location":"k3s/01-concepts/#from-zero-to-production-ready-cluster","title":"From Zero to Production-Ready Cluster","text":"<p>This tutorial will take you from zero Kubernetes knowledge to running your SeaweedFS distributed filesystem cluster. We'll learn by doing.</p>"},{"location":"k3s/01-concepts/#part-1-understanding-kubernetes-concepts","title":"PART 1: UNDERSTANDING KUBERNETES CONCEPTS","text":"<p>Before touching the keyboard, let's understand what we're building.</p>"},{"location":"k3s/01-concepts/#11-what-is-kubernetes","title":"1.1 What is Kubernetes?","text":"<p>Kubernetes is a container orchestrator. It answers: \"I have containers, how do I run them across multiple machines reliably?\"</p> <pre><code>Without Kubernetes:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 You manually:                                           \u2502\n\u2502 - SSH into each server                                  \u2502\n\u2502 - Run docker commands                                   \u2502\n\u2502 - Hope containers stay running                          \u2502\n\u2502 - Manually restart crashed containers                   \u2502\n\u2502 - Manually balance load                                 \u2502\n\u2502 - Manually update containers one by one                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nWith Kubernetes:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 You declare: \"I want 4 copies of this container\"        \u2502\n\u2502 Kubernetes:                                             \u2502\n\u2502 - Schedules them across nodes                           \u2502\n\u2502 - Restarts crashed ones                                 \u2502\n\u2502 - Load balances traffic                                 \u2502\n\u2502 - Performs rolling updates                              \u2502\n\u2502 - Scales up/down on demand                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/01-concepts/#12-k3s-vs-k8s","title":"1.2 K3s vs K8s","text":"<p>K3s IS Kubernetes, just packaged differently:</p> <pre><code>Full K8s:                          K3s:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Multiple binaries   \u2502            \u2502 Single 50MB binary  \u2502\n\u2502 Requires etcd       \u2502            \u2502 SQLite by default   \u2502\n\u2502 2GB+ RAM minimum    \u2502            \u2502 512MB RAM minimum   \u2502\n\u2502 Complex install     \u2502            \u2502 One-liner install   \u2502\n\u2502 Same API            \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 Same API            \u2502\n\u2502 Same kubectl        \u2502            \u2502 Same kubectl        \u2502\n\u2502 Same YAML           \u2502            \u2502 Same YAML           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Everything you learn about K3s applies to full Kubernetes.</p>"},{"location":"k3s/01-concepts/#13-core-concepts-the-big-picture","title":"1.3 Core Concepts (The Big Picture)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              CLUSTER                                     \u2502\n\u2502                                                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                     CONTROL PLANE (Master)                       \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502 API Server\u2502 \u2502 Scheduler \u2502 \u2502Controller \u2502 \u2502    etcd/      \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502           \u2502 \u2502           \u2502 \u2502  Manager  \u2502 \u2502   SQLite      \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                    \u2502                                     \u2502\n\u2502                                    \u2502 kubectl / API                       \u2502\n\u2502                                    \u25bc                                     \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502   \u2502   WORKER NODE   \u2502  \u2502   WORKER NODE   \u2502  \u2502   WORKER NODE   \u2502        \u2502\n\u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502        \u2502\n\u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502        \u2502\n\u2502   \u2502 \u2502   kubelet   \u2502 \u2502  \u2502 \u2502   kubelet   \u2502 \u2502  \u2502 \u2502   kubelet   \u2502 \u2502        \u2502\n\u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502        \u2502\n\u2502   \u2502                 \u2502  \u2502                 \u2502  \u2502                 \u2502        \u2502\n\u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2510        \u2502        \u2502\n\u2502   \u2502 \u2502 Pod \u2502 \u2502 Pod \u2502 \u2502  \u2502 \u2502 Pod \u2502 \u2502 Pod \u2502 \u2502  \u2502 \u2502 Pod \u2502        \u2502        \u2502\n\u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2518        \u2502        \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/01-concepts/#key-components","title":"Key Components:","text":"Component What it does Analogy Cluster The whole system The factory Node A machine (physical/virtual) A workstation in the factory Control Plane Brain of the cluster Factory management office kubelet Agent on each node Foreman at each workstation Pod Smallest deployable unit (1+ containers) A work order"},{"location":"k3s/01-concepts/#14-kubernetes-objects-things-you-create","title":"1.4 Kubernetes Objects (Things You Create)","text":""},{"location":"k3s/01-concepts/#pod","title":"Pod","text":"<p>The smallest unit. Usually 1 container, sometimes multiple tightly-coupled containers.</p> <pre><code># You rarely create Pods directly, but understand them:\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n</code></pre>"},{"location":"k3s/01-concepts/#deployment","title":"Deployment","text":"<p>\"I want N copies of this Pod, keep them running.\"</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 3  # Run 3 copies\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: nginx\n        image: nginx\n</code></pre> <pre><code>Deployment creates:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Deployment: my-app                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  ReplicaSet (manages pod count)               \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502  \u2502\n\u2502  \u2502  \u2502  Pod 1  \u2502  \u2502  Pod 2  \u2502  \u2502  Pod 3  \u2502       \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/01-concepts/#daemonset","title":"DaemonSet","text":"<p>\"Run exactly ONE Pod on EVERY node.\" Perfect for your SeaweedFS volume/mount.</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: seaweed-volume\nspec:\n  selector:\n    matchLabels:\n      app: seaweed-volume\n  template:\n    # ... pod template\n</code></pre> <pre><code>DaemonSet:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Node 1     \u2502  \u2502   Node 2     \u2502  \u2502   Node 3     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Pod   \u2502  \u2502  \u2502  \u2502  Pod   \u2502  \u2502  \u2502  \u2502  Pod   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u25b2                 \u25b2                 \u25b2\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 Exactly 1 per node\n</code></pre>"},{"location":"k3s/01-concepts/#service","title":"Service","text":"<p>\"How do Pods find each other?\" Services provide stable DNS names and load balancing.</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: my-app  # Find pods with this label\n  ports:\n  - port: 80\n</code></pre> <pre><code>Without Service:                    With Service:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pod IPs change!     \u2502            \u2502 my-service:80       \u2502\n\u2502 10.42.0.5 \u2192 died    \u2502            \u2502        \u2502            \u2502\n\u2502 10.42.0.9 \u2192 new one \u2502            \u2502   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502 How to connect???   \u2502            \u2502   \u25bc    \u25bc   \u25bc       \u2502\n\u2502                     \u2502            \u2502  Pod  Pod  Pod      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   Stable DNS, load balanced\n</code></pre> <p>Service Types: | Type | Use Case | |------|----------| | <code>ClusterIP</code> | Internal only (default) | | <code>NodePort</code> | Expose on each node's IP:port | | <code>LoadBalancer</code> | Cloud provider load balancer |</p>"},{"location":"k3s/01-concepts/#configmap-secret","title":"ConfigMap &amp; Secret","text":"<p>Configuration data for your pods.</p> <pre><code># ConfigMap - non-sensitive config\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-config\ndata:\n  DATABASE_HOST: \"db.example.com\"\n  LOG_LEVEL: \"debug\"\n\n---\n# Secret - sensitive data (base64 encoded)\napiVersion: v1\nkind: Secret\nmetadata:\n  name: my-secret\ntype: Opaque\ndata:\n  password: cGFzc3dvcmQxMjM=  # base64 of \"password123\"\n</code></pre>"},{"location":"k3s/01-concepts/#volumes-persistentvolumes","title":"Volumes &amp; PersistentVolumes","text":"<p>How containers access storage.</p> <pre><code>Volume Types:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 emptyDir      - Temporary, dies with Pod            \u2502\n\u2502 hostPath      - Mount host directory into Pod       \u2502\n\u2502 configMap     - Mount ConfigMap as files            \u2502\n\u2502 secret        - Mount Secret as files               \u2502\n\u2502 persistentVolumeClaim - Request persistent storage  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>For your SeaweedFS mount, we'll use <code>hostPath</code> with <code>mountPropagation: Bidirectional</code>.</p>"},{"location":"k3s/01-concepts/#15-labels-and-selectors","title":"1.5 Labels and Selectors","text":"<p>How Kubernetes objects find each other:</p> <pre><code># Pod with labels\nmetadata:\n  labels:\n    app: nginx\n    environment: production\n    tier: frontend\n\n# Service selects pods by labels\nspec:\n  selector:\n    app: nginx\n    tier: frontend\n</code></pre>"},{"location":"k3s/01-concepts/#16-namespaces","title":"1.6 Namespaces","text":"<p>Logical separation within a cluster (like folders):</p> <pre><code>Cluster\n\u251c\u2500\u2500 namespace: default        \u2190 Your stuff goes here by default\n\u251c\u2500\u2500 namespace: kube-system    \u2190 K8s internal components\n\u251c\u2500\u2500 namespace: production     \u2190 You can create your own\n\u2514\u2500\u2500 namespace: staging\n</code></pre>"},{"location":"k3s/01-concepts/#17-the-declarative-model","title":"1.7 The Declarative Model","text":"<p>Kubernetes is declarative, not imperative:</p> <pre><code>Imperative (what you're used to):\n\"Start 3 nginx containers\"\n\"Stop container #2\"\n\"Start a new container\"\n\nDeclarative (Kubernetes way):\n\"I want 3 nginx containers running\"\n(Kubernetes figures out how to make it happen)\n</code></pre> <p>You write YAML describing DESIRED STATE, Kubernetes makes CURRENT STATE match it.</p>"},{"location":"k3s/01-concepts/#summary-of-part-1","title":"Summary of Part 1","text":"Concept What it is Your Use Case Cluster Collection of nodes Your 3 lab machines Node A machine Each physical server Pod Container wrapper Each SeaweedFS component Deployment Manages replicated Pods yt-dlp workers (scale up/down) DaemonSet One Pod per node SeaweedFS volume + mount Service Stable DNS + load balancing <code>seaweed-filer:8888</code> ConfigMap Configuration SeaweedFS settings hostPath Mount host directory <code>/data/seaweed</code>, <code>/mnt/swdshared</code> <p>Ready for Part 2? Let's install K3s on your machines!</p>"},{"location":"k3s/01b-questions-answered/","title":"K3s Tutorial: Your Questions Answered","text":""},{"location":"k3s/01b-questions-answered/#question-1-yaml-config-structure","title":"Question 1: YAML Config Structure","text":"<p>Yes! Every Kubernetes YAML has a standard structure with 4 required top-level fields:</p> <pre><code>apiVersion: &lt;api_group/version&gt;  # Which API to use\nkind: &lt;ResourceType&gt;              # What type of object\nmetadata:                         # Identity &amp; organization\n  name: &lt;unique-name&gt;\n  namespace: &lt;optional&gt;\n  labels: &lt;optional&gt;\n  annotations: &lt;optional&gt;\nspec:                             # Your desired state (varies by kind)\n  # ... specific to each resource type\n</code></pre>"},{"location":"k3s/01b-questions-answered/#complete-structure-reference","title":"Complete Structure Reference:","text":"<pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FIELD 1: apiVersion\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Format: &lt;group&gt;/&lt;version&gt; or just &lt;version&gt; for core resources\n#\n# Common values:\n#   v1                  \u2192 Core resources (Pod, Service, ConfigMap, Secret, Namespace)\n#   apps/v1             \u2192 Deployments, DaemonSets, StatefulSets, ReplicaSets\n#   batch/v1            \u2192 Jobs, CronJobs\n#   networking.k8s.io/v1 \u2192 Ingress, NetworkPolicy\n#   storage.k8s.io/v1   \u2192 StorageClass, VolumeAttachment\n#   rbac.authorization.k8s.io/v1 \u2192 Roles, ClusterRoles, Bindings\n\napiVersion: apps/v1\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FIELD 2: kind\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# The type of resource (case-sensitive, PascalCase)\n\nkind: Deployment\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FIELD 3: metadata\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Identity and organizational info\n\nmetadata:\n  # REQUIRED: unique name within namespace\n  name: my-application\n\n  # OPTIONAL: which namespace (default: \"default\")\n  namespace: production\n\n  # OPTIONAL: key-value pairs for selection/organization\n  labels:\n    app: my-app\n    environment: production\n    team: backend\n    version: v1.2.3\n\n  # OPTIONAL: non-identifying metadata (for tools, humans)\n  annotations:\n    description: \"Main application server\"\n    maintainer: \"team@example.com\"\n    prometheus.io/scrape: \"true\"\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FIELD 4: spec\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Desired state - structure depends entirely on 'kind'\n\nspec:\n  # ... varies by resource type\n</code></pre>"},{"location":"k3s/01b-questions-answered/#example-complete-deployment-with-all-common-fields","title":"Example: Complete Deployment with All Common Fields","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-server\n  namespace: default\n  labels:\n    app: web-server\n    tier: frontend\nspec:\n  # \u2500\u2500 Deployment-specific fields \u2500\u2500\n  replicas: 3\n\n  # How to find pods this deployment manages\n  selector:\n    matchLabels:\n      app: web-server\n\n  # Strategy for updates\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n\n  # \u2500\u2500 Pod Template (nested Pod spec) \u2500\u2500\n  template:\n    metadata:\n      labels:\n        app: web-server  # Must match selector above\n    spec:\n      # \u2500\u2500 Container(s) \u2500\u2500\n      containers:\n      - name: nginx\n        image: nginx:1.25\n\n        # Resource limits\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n\n        # Ports\n        ports:\n        - containerPort: 80\n          name: http\n\n        # Health checks\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 80\n          initialDelaySeconds: 10\n          periodSeconds: 5\n\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 3\n\n        # Environment variables\n        env:\n        - name: LOG_LEVEL\n          value: \"info\"\n        - name: DB_HOST\n          valueFrom:\n            configMapKeyRef:\n              name: app-config\n              key: database_host\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: app-secrets\n              key: db_password\n\n        # Volume mounts\n        volumeMounts:\n        - name: config-volume\n          mountPath: /etc/config\n        - name: data-volume\n          mountPath: /data\n\n      # \u2500\u2500 Volumes \u2500\u2500\n      volumes:\n      - name: config-volume\n        configMap:\n          name: app-config\n      - name: data-volume\n        hostPath:\n          path: /mnt/data\n          type: DirectoryOrCreate\n\n      # \u2500\u2500 Pod-level settings \u2500\u2500\n      restartPolicy: Always  # Always, OnFailure, Never\n\n      # Node selection\n      nodeSelector:\n        disk: ssd\n\n      # Tolerations (allow scheduling on tainted nodes)\n      tolerations:\n      - key: \"node-role.kubernetes.io/master\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n\n      # Security context\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n</code></pre>"},{"location":"k3s/01b-questions-answered/#quick-reference-spec-structure-by-kind","title":"Quick Reference: spec Structure by Kind","text":"<pre><code>Pod.spec:\n\u251c\u2500\u2500 containers[]\n\u251c\u2500\u2500 volumes[]\n\u251c\u2500\u2500 restartPolicy\n\u251c\u2500\u2500 nodeSelector\n\u251c\u2500\u2500 tolerations\n\u251c\u2500\u2500 securityContext\n\u2514\u2500\u2500 ...\n\nDeployment.spec:\n\u251c\u2500\u2500 replicas\n\u251c\u2500\u2500 selector\n\u251c\u2500\u2500 strategy\n\u2514\u2500\u2500 template (contains Pod.spec)\n\nDaemonSet.spec:\n\u251c\u2500\u2500 selector\n\u251c\u2500\u2500 updateStrategy\n\u2514\u2500\u2500 template (contains Pod.spec)\n\nService.spec:\n\u251c\u2500\u2500 selector\n\u251c\u2500\u2500 ports[]\n\u251c\u2500\u2500 type (ClusterIP/NodePort/LoadBalancer)\n\u2514\u2500\u2500 ...\n\nConfigMap:\n\u251c\u2500\u2500 data (key-value strings)\n\u2514\u2500\u2500 binaryData (key-value binary)\n\nSecret:\n\u251c\u2500\u2500 type\n\u251c\u2500\u2500 data (base64 encoded)\n\u2514\u2500\u2500 stringData (plain text, converted to base64)\n</code></pre>"},{"location":"k3s/01b-questions-answered/#question-2-toolssdks-for-managing-configs","title":"Question 2: Tools/SDKs for Managing Configs","text":"<p>Yes! There are several approaches, from simple to complex:</p>"},{"location":"k3s/01b-questions-answered/#tier-1-built-in-simple","title":"Tier 1: Built-in / Simple","text":"Tool What it does Complexity Use when kubectl Direct YAML apply \u2b50 Learning, simple deployments Kustomize Patch/overlay YAML (built into kubectl) \u2b50\u2b50 Multiple environments"},{"location":"k3s/01b-questions-answered/#tier-2-package-managers","title":"Tier 2: Package Managers","text":"Tool What it does Complexity Use when Helm Package manager with templates \u2b50\u2b50\u2b50 Using community charts, team standardization"},{"location":"k3s/01b-questions-answered/#tier-3-programming-languages-iac","title":"Tier 3: Programming Languages (IaC)","text":"Tool Language Complexity Use when Pulumi Python/Go/TS/etc \u2b50\u2b50\u2b50\u2b50 Complex infra, existing code CDK8s Python/TS/Go \u2b50\u2b50\u2b50\u2b50 Type-safe K8s configs cdk8s+ Python/TS \u2b50\u2b50\u2b50\u2b50 Higher-level abstractions"},{"location":"k3s/01b-questions-answered/#detailed-comparison","title":"Detailed Comparison:","text":""},{"location":"k3s/01b-questions-answered/#1-kubectl-raw-yaml","title":"1. kubectl (Raw YAML)","text":"<p><pre><code># Just apply YAML files directly\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n\n# Or a whole directory\nkubectl apply -f ./manifests/\n\n# Or from URL\nkubectl apply -f https://example.com/manifest.yaml\n</code></pre> Pros: No extra tools, direct control Cons: Repetition, no templating, manual env management</p>"},{"location":"k3s/01b-questions-answered/#2-kustomize-built-into-kubectl","title":"2. Kustomize (Built into kubectl)","text":"<p>Lets you have a \"base\" and \"overlays\" for different environments:</p> <pre><code>k8s/\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2514\u2500\u2500 service.yaml\n\u251c\u2500\u2500 overlays/\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml    # patches for dev\n\u2502   \u2514\u2500\u2500 prod/\n\u2502       \u2514\u2500\u2500 kustomization.yaml    # patches for prod\n</code></pre> <pre><code># base/kustomization.yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n  - deployment.yaml\n  - service.yaml\n\n# overlays/prod/kustomization.yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n  - ../../base\npatchesStrategicMerge:\n  - increase-replicas.yaml\nnamePrefix: prod-\n</code></pre> <pre><code># Apply dev\nkubectl apply -k overlays/dev/\n\n# Apply prod\nkubectl apply -k overlays/prod/\n</code></pre> <p>Pros: Built-in, no templating language, composition over inheritance Cons: Can get complex, limited logic</p>"},{"location":"k3s/01b-questions-answered/#3-helm-package-manager","title":"3. Helm (Package Manager)","text":"<p>Think \"apt/npm for Kubernetes\":</p> <pre><code># Install community charts\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm install my-redis bitnami/redis\n\n# Install with custom values\nhelm install my-app ./my-chart -f values-prod.yaml\n</code></pre> <p>Create your own chart: <pre><code>my-chart/\n\u251c\u2500\u2500 Chart.yaml           # Metadata\n\u251c\u2500\u2500 values.yaml          # Default values\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 deployment.yaml  # Go templates\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 _helpers.tpl     # Template helpers\n</code></pre></p> <pre><code># templates/deployment.yaml (Go templating)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ .Release.Name }}-{{ .Chart.Name }}\nspec:\n  replicas: {{ .Values.replicas }}\n  template:\n    spec:\n      containers:\n      - name: app\n        image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"\n        {{- if .Values.resources }}\n        resources:\n          {{- toYaml .Values.resources | nindent 10 }}\n        {{- end }}\n</code></pre> <pre><code># values.yaml\nreplicas: 3\nimage:\n  repository: nginx\n  tag: latest\nresources:\n  limits:\n    memory: 128Mi\n</code></pre> <p>Pros: Huge ecosystem, versioned releases, rollback support Cons: Go templating is ugly, steep learning curve</p>"},{"location":"k3s/01b-questions-answered/#4-pulumi-python-example","title":"4. Pulumi (Python Example)","text":"<pre><code>import pulumi\nimport pulumi_kubernetes as k8s\n\n# Create a deployment using Python!\napp_labels = {\"app\": \"nginx\"}\n\ndeployment = k8s.apps.v1.Deployment(\n    \"nginx\",\n    spec=k8s.apps.v1.DeploymentSpecArgs(\n        replicas=3,\n        selector=k8s.meta.v1.LabelSelectorArgs(match_labels=app_labels),\n        template=k8s.core.v1.PodTemplateSpecArgs(\n            metadata=k8s.meta.v1.ObjectMetaArgs(labels=app_labels),\n            spec=k8s.core.v1.PodSpecArgs(\n                containers=[k8s.core.v1.ContainerArgs(\n                    name=\"nginx\",\n                    image=\"nginx:1.25\",\n                    ports=[k8s.core.v1.ContainerPortArgs(container_port=80)],\n                )],\n            ),\n        ),\n    ),\n)\n\n# Export the deployment name\npulumi.export(\"deployment_name\", deployment.metadata.name)\n</code></pre> <pre><code>pulumi up  # Deploy\npulumi destroy  # Tear down\n</code></pre> <p>Pros: Real programming language, loops, conditionals, IDE support, type checking Cons: More complex, state management, learning curve</p>"},{"location":"k3s/01b-questions-answered/#5-cdk8s-python-example","title":"5. CDK8s (Python Example)","text":"<pre><code>from constructs import Construct\nfrom cdk8s import App, Chart\nfrom cdk8s_plus_25 import Deployment, Service, ContainerProps\n\nclass MyChart(Chart):\n    def __init__(self, scope: Construct, id: str):\n        super().__init__(scope, id)\n\n        # Much simpler API than raw K8s\n        deployment = Deployment(\n            self, \"nginx\",\n            replicas=3,\n            containers=[ContainerProps(\n                name=\"nginx\",\n                image=\"nginx:1.25\",\n                port=80,\n            )]\n        )\n\n        # Automatically creates service pointing to deployment\n        deployment.expose_via_service(port=80)\n\napp = App()\nMyChart(app, \"my-app\")\napp.synth()  # Generates YAML files\n</code></pre> <pre><code>cdk8s synth  # Generate YAML\nkubectl apply -f dist/\n</code></pre> <p>Pros: Type-safe, IDE autocomplete, generates standard YAML Cons: Extra build step, another tool to learn</p>"},{"location":"k3s/01b-questions-answered/#my-recommendation-for-you","title":"My Recommendation for You:","text":"<pre><code>Learning (now):     Raw YAML + kubectl\n                    \u2193\nSmall projects:     Kustomize (built-in, no extra tools)\n                    \u2193\nTeam/Production:    Helm (if using community charts)\n                    or Pulumi/CDK8s (if you prefer Python)\n</code></pre> <p>For your SeaweedFS project: Start with raw YAML, then maybe Kustomize if you want dev/prod variants.</p>"},{"location":"k3s/01b-questions-answered/#question-3-daemonset-and-all-workload-types","title":"Question 3: DaemonSet and ALL Workload Types","text":"<p>A DaemonSet ensures exactly ONE pod runs on EVERY node (or a subset). When a new node joins, it automatically gets a pod. When a node leaves, the pod is garbage collected.</p>"},{"location":"k3s/01b-questions-answered/#complete-list-of-kubernetes-workload-resources","title":"Complete List of Kubernetes Workload Resources:","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        KUBERNETES WORKLOAD TYPES                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                         PODS (Base Unit)                            \u2502   \u2502\n\u2502  \u2502  \u2022 Smallest deployable unit                                         \u2502   \u2502\n\u2502  \u2502  \u2022 Usually created by controllers, not directly                     \u2502   \u2502\n\u2502  \u2502  \u2022 Contains 1+ containers sharing network/storage                   \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                    \u2502                                        \u2502\n\u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502          \u2502                         \u2502                         \u2502             \u2502\n\u2502          \u25bc                         \u25bc                         \u25bc             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502  Deployment   \u2502      \u2502  DaemonSet    \u2502      \u2502  StatefulSet  \u2502          \u2502\n\u2502  \u2502               \u2502      \u2502               \u2502      \u2502               \u2502          \u2502\n\u2502  \u2502 \u2022 N replicas  \u2502      \u2502 \u2022 1 per node  \u2502      \u2502 \u2022 Stateful    \u2502          \u2502\n\u2502  \u2502 \u2022 Stateless   \u2502      \u2502 \u2022 System-wide \u2502      \u2502 \u2022 Ordered     \u2502          \u2502\n\u2502  \u2502 \u2022 Scale up/   \u2502      \u2502 \u2022 Logs/agents \u2502      \u2502 \u2022 Stable IDs  \u2502          \u2502\n\u2502  \u2502   down freely \u2502      \u2502 \u2022 Storage     \u2502      \u2502 \u2022 Databases   \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502          \u2502                                                                  \u2502\n\u2502          \u25bc                                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                         \u2502\n\u2502  \u2502  ReplicaSet   \u2502  (Usually managed by Deployment, not used directly)    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                         \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                         BATCH WORKLOADS                              \u2502   \u2502\n\u2502  \u2502                                                                      \u2502   \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502   \u2502\n\u2502  \u2502  \u2502     Job       \u2502                \u2502   CronJob     \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2502               \u2502                \u2502               \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2502 \u2022 Run to      \u2502                \u2502 \u2022 Scheduled   \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2502   completion  \u2502                \u2502 \u2022 Like cron   \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2502 \u2022 Retries     \u2502                \u2502 \u2022 Creates     \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2502 \u2022 Parallelism \u2502                \u2502   Jobs        \u2502                 \u2502   \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/01b-questions-answered/#detailed-breakdown","title":"Detailed Breakdown:","text":""},{"location":"k3s/01b-questions-answered/#1-pod","title":"1. Pod","text":"<p><pre><code>apiVersion: v1\nkind: Pod\n</code></pre> - What: 1+ containers that share network namespace and storage - Use: Almost never directly; use controllers instead - Example: Testing a single container quickly</p>"},{"location":"k3s/01b-questions-answered/#2-replicaset","title":"2. ReplicaSet","text":"<p><pre><code>apiVersion: apps/v1\nkind: ReplicaSet\n</code></pre> - What: Ensures N identical pods are running - Use: Almost never directly; Deployment manages these - Example: (Managed by Deployment)</p>"},{"location":"k3s/01b-questions-answered/#3-deployment-most-common","title":"3. Deployment \u2b50 (Most Common)","text":"<p><pre><code>apiVersion: apps/v1\nkind: Deployment\n</code></pre> - What: Declarative updates for ReplicaSets and Pods - Use: Stateless applications, web servers, APIs, workers - Features:   - Scale replicas up/down   - Rolling updates (zero downtime)   - Rollback to previous versions   - Self-healing (restarts failed pods)</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: yt-dlp-worker\nspec:\n  replicas: 10  # Run 10 workers\n  selector:\n    matchLabels:\n      app: yt-dlp-worker\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 2        # Can have 2 extra during update\n      maxUnavailable: 1  # Can have 1 less during update\n  template:\n    metadata:\n      labels:\n        app: yt-dlp-worker\n    spec:\n      containers:\n      - name: worker\n        image: your-yt-dlp-image:v1\n</code></pre> <p>Your use case: yt-dlp download workers</p>"},{"location":"k3s/01b-questions-answered/#4-daemonset-for-your-seaweedfs","title":"4. DaemonSet \u2b50 (For Your SeaweedFS)","text":"<p><pre><code>apiVersion: apps/v1\nkind: DaemonSet\n</code></pre> - What: Ensures exactly 1 pod runs on every node (or selected nodes) - Use: Node-level services, storage, monitoring agents, log collectors - Features:   - Auto-deploys to new nodes   - Auto-removes from deleted nodes   - Can target specific nodes with selectors</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: seaweed-volume\nspec:\n  selector:\n    matchLabels:\n      app: seaweed-volume\n  template:\n    metadata:\n      labels:\n        app: seaweed-volume\n    spec:\n      containers:\n      - name: volume\n        image: chrislusf/seaweedfs\n        args: [\"volume\", \"-mserver=seaweed-master:9333\", \"-dir=/data\"]\n        volumeMounts:\n        - name: data\n          mountPath: /data\n      volumes:\n      - name: data\n        hostPath:\n          path: /data/seaweed\n</code></pre> <p>Visual: <pre><code>Node 1          Node 2          Node 3          (New) Node 4\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pod auto \u2502    \u2502 Pod auto \u2502    \u2502 Pod auto \u2502    \u2502 Pod auto \u2502\n\u2502 created  \u2502    \u2502 created  \u2502    \u2502 created  \u2502    \u2502 created  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u25b2               \u25b2               \u25b2               \u25b2\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    DaemonSet ensures this\n</code></pre></p> <p>Your use case: SeaweedFS volume servers and FUSE mounts (one per node)</p>"},{"location":"k3s/01b-questions-answered/#5-statefulset","title":"5. StatefulSet","text":"<p><pre><code>apiVersion: apps/v1\nkind: StatefulSet\n</code></pre> - What: Like Deployment but for stateful apps needing stable identity - Use: Databases, distributed systems needing stable network IDs - Features:   - Stable, persistent hostname: <code>pod-0</code>, <code>pod-1</code>, <code>pod-2</code>   - Ordered deployment/scaling (0 before 1 before 2)   - Ordered rolling updates   - Stable persistent storage per pod</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\nspec:\n  serviceName: postgres  # Required: headless service name\n  replicas: 3\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:15\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/postgresql/data\n  volumeClaimTemplates:  # Each pod gets its own PVC\n  - metadata:\n      name: data\n    spec:\n      accessModes: [\"ReadWriteOnce\"]\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre> <p>Visual: <pre><code>StatefulSet: postgres\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  postgres-0    \u2502  \u2502  postgres-1    \u2502  \u2502  postgres-2    \u2502\n\u2502  (created 1st) \u2502  \u2502  (created 2nd) \u2502  \u2502  (created 3rd) \u2502\n\u2502                \u2502  \u2502                \u2502  \u2502                \u2502\n\u2502  PVC: data-0   \u2502  \u2502  PVC: data-1   \u2502  \u2502  PVC: data-2   \u2502\n\u2502  (persistent)  \u2502  \u2502  (persistent)  \u2502  \u2502  (persistent)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Your use case: Could use for SeaweedFS master if you want HA (but single master is fine for lab)</p>"},{"location":"k3s/01b-questions-answered/#6-job","title":"6. Job","text":"<p><pre><code>apiVersion: batch/v1\nkind: Job\n</code></pre> - What: Run pod(s) to completion, then stop - Use: Batch processing, migrations, one-time tasks - Features:   - Runs until success (or max retries)   - Can run multiple pods in parallel   - Tracks completions</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: process-videos\nspec:\n  completions: 100      # Need 100 successful completions\n  parallelism: 10       # Run 10 pods at a time\n  backoffLimit: 3       # Retry failed pods 3 times\n  template:\n    spec:\n      restartPolicy: Never  # Required for Jobs\n      containers:\n      - name: processor\n        image: video-processor\n</code></pre> <p>Your use case: Batch download jobs (alternative to long-running workers)</p>"},{"location":"k3s/01b-questions-answered/#7-cronjob","title":"7. CronJob","text":"<p><pre><code>apiVersion: batch/v1\nkind: CronJob\n</code></pre> - What: Scheduled Jobs (like cron) - Use: Periodic tasks, backups, cleanups, reports - Features:   - Standard cron syntax   - Creates Jobs on schedule   - Concurrency policies</p> <pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: nightly-backup\nspec:\n  schedule: \"0 2 * * *\"  # 2 AM daily\n  concurrencyPolicy: Forbid  # Don't run if previous still running\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: backup\n            image: backup-tool\n</code></pre> <p>Your use case: Scheduled cleanup of old downloads, periodic stats collection</p>"},{"location":"k3s/01b-questions-answered/#summary-table-when-to-use-what","title":"Summary Table: When to Use What","text":"Workload Replicas Identity Storage Lifetime Your Use Case Deployment N (scalable) Random names Shared/None Long-running yt-dlp workers DaemonSet 1 per node Per-node Per-node Long-running SeaweedFS volume + mount StatefulSet N (ordered) Stable (pod-0, pod-1) Per-pod persistent Long-running Databases Job N (to completion) Random Temporary Until done Batch processing CronJob Creates Jobs Random Temporary Scheduled Nightly backups"},{"location":"k3s/01b-questions-answered/#your-seaweedfs-architecture-mapped-to-k8s","title":"Your SeaweedFS Architecture Mapped to K8s:","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Your K3s Cluster                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502  Deployment (replicas: 1)           Deployment (replicas: 1)        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502  seaweed-master     \u2502            \u2502  seaweed-filer      \u2502         \u2502\n\u2502  \u2502  (single instance)  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  (single instance)  \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502            \u25b2                                   \u25b2                     \u2502\n\u2502            \u2502                                   \u2502                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502  \u2502                                                        \u2502          \u2502\n\u2502  \u2502  DaemonSet: seaweed-volume (1 per node)               \u2502          \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502          \u2502\n\u2502  \u2502  \u2502 volume-1 \u2502  \u2502 volume-2 \u2502  \u2502 volume-3 \u2502            \u2502          \u2502\n\u2502  \u2502  \u2502 Node 1   \u2502  \u2502 Node 2   \u2502  \u2502 Node 3   \u2502            \u2502          \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502          \u2502\n\u2502  \u2502                                                        \u2502          \u2502\n\u2502  \u2502  DaemonSet: seaweed-mount (1 per node)                \u2502          \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502          \u2502\n\u2502  \u2502  \u2502 mount-1  \u2502  \u2502 mount-2  \u2502  \u2502 mount-3  \u2502            \u2502          \u2502\n\u2502  \u2502  \u2502 /mnt/swd \u2502  \u2502 /mnt/swd \u2502  \u2502 /mnt/swd \u2502            \u2502          \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                                                      \u2502\n\u2502  Deployment: yt-dlp-workers (replicas: 10, scalable)                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510...               \u2502\n\u2502  \u2502 w-1  \u2502\u2502 w-2  \u2502\u2502 w-3  \u2502\u2502 w-4  \u2502\u2502 w-5  \u2502\u2502 w-6  \u2502                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502  (spread across nodes, can scale to 50+)                            \u2502\n\u2502                                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Ready for Part 2 (Installation) now?</p>"},{"location":"k3s/02-installation/","title":"K3s Tutorial - Part 2: Installation","text":"<p>Let's get K3s running on your machines. This is the fun part!</p>"},{"location":"k3s/02-installation/#21-prerequisites","title":"2.1 Prerequisites","text":""},{"location":"k3s/02-installation/#your-machines-need","title":"Your Machines Need:","text":"Requirement Minimum Your Lab (probably fine) OS Ubuntu 20.04+, Debian 10+ \u2713 RAM 512 MB (server), 256 MB (agent) \u2713 CPU 1 core \u2713 Disk 1 GB free \u2713"},{"location":"k3s/02-installation/#network-requirements","title":"Network Requirements:","text":"Port Purpose Used By 6443 Kubernetes API kubectl, agents 8472 Flannel VXLAN (pod networking) All nodes 10250 Kubelet metrics Master 2379-2380 etcd (if HA setup) Masters only"},{"location":"k3s/02-installation/#before-you-start","title":"Before You Start:","text":"<pre><code># On ALL nodes, run these checks:\n\n# 1. Check hostname is unique per machine\nhostname\n\n# 2. Ensure hostnames are set properly (not \"localhost\")\nsudo hostnamectl set-hostname master-1   # On master\nsudo hostnamectl set-hostname worker-1   # On worker 1\nsudo hostnamectl set-hostname worker-2   # On worker 2\n\n# 3. Check connectivity between nodes\nping &lt;other-node-ip&gt;\n\n# 4. Ensure no firewall blocks (or open ports)\nsudo ufw status\n# If active, either disable or allow ports:\nsudo ufw allow 6443/tcp\nsudo ufw allow 8472/udp\nsudo ufw allow 10250/tcp\n\n# 5. Disable swap (Kubernetes doesn't like swap)\nsudo swapoff -a\n# Make permanent: comment out swap line in /etc/fstab\nsudo sed -i '/ swap / s/^/#/' /etc/fstab\n</code></pre>"},{"location":"k3s/02-installation/#22-cluster-architecture","title":"2.2 Cluster Architecture","text":"<p>For your lab, we'll do:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Your K3s Cluster                          \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                    MASTER NODE                           \u2502   \u2502\n\u2502   \u2502                 (also runs workloads)                    \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502   IP: 192.168.1.10 (replace with your actual IP)        \u2502   \u2502\n\u2502   \u2502   Hostname: master-1                                     \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502   Runs: K3s server (API, scheduler, controller)         \u2502   \u2502\n\u2502   \u2502         + Can also run pods                              \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                              \u2502                                   \u2502\n\u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502               \u2502              \u2502              \u2502                   \u2502\n\u2502               \u25bc              \u25bc              \u25bc                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502  WORKER NODE  \u2502  \u2502  WORKER NODE  \u2502  \u2502  WORKER NODE  \u2502      \u2502\n\u2502   \u2502   worker-1    \u2502  \u2502   worker-2    \u2502  \u2502   worker-3    \u2502      \u2502\n\u2502   \u2502 192.168.1.11  \u2502  \u2502 192.168.1.12  \u2502  \u2502 192.168.1.13  \u2502      \u2502\n\u2502   \u2502               \u2502  \u2502               \u2502  \u2502               \u2502      \u2502\n\u2502   \u2502 Runs: K3s     \u2502  \u2502 Runs: K3s     \u2502  \u2502 Runs: K3s     \u2502      \u2502\n\u2502   \u2502       agent   \u2502  \u2502       agent   \u2502  \u2502       agent   \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Note: In K3s, the master can also run workloads (unlike some K8s setups). Good for small clusters!</p>"},{"location":"k3s/02-installation/#23-install-k3s-server-master-node","title":"2.3 Install K3s Server (Master Node)","text":"<p>SSH into your master node and run:</p> <pre><code># One-liner installation!\ncurl -sfL https://get.k3s.io | sh -\n\n# That's it. Seriously.\n</code></pre>"},{"location":"k3s/02-installation/#what-just-happened","title":"What Just Happened?","text":"<pre><code>Downloaded:   /usr/local/bin/k3s (single binary, ~60MB)\nCreated:      /etc/rancher/k3s/k3s.yaml (kubeconfig)\nStarted:      k3s.service (systemd)\nInstalled:    kubectl, crictl, ctr (bundled)\n</code></pre>"},{"location":"k3s/02-installation/#verify-its-running","title":"Verify It's Running:","text":"<pre><code># Check service status\nsudo systemctl status k3s\n\n# You should see:\n#   Active: active (running)\n\n# Check K3s version\nk3s --version\n\n# Check nodes (just master for now)\nsudo kubectl get nodes\n\n# Output:\n# NAME       STATUS   ROLES                  AGE   VERSION\n# master-1   Ready    control-plane,master   30s   v1.28.x+k3s1\n</code></pre>"},{"location":"k3s/02-installation/#get-the-token-needed-for-workers","title":"Get the Token (Needed for Workers)","text":"<pre><code># This token lets workers join the cluster\nsudo cat /var/lib/rancher/k3s/server/node-token\n\n# Output looks like:\n# K10abc123...very-long-string...xyz789::server:abc123...\n</code></pre> <p>Save this token! You'll need it for each worker node.</p>"},{"location":"k3s/02-installation/#get-master-ip","title":"Get Master IP","text":"<pre><code># Get the IP address workers will connect to\nhostname -I | awk '{print $1}'\n\n# Or check manually\nip addr show\n</code></pre>"},{"location":"k3s/02-installation/#24-install-k3s-agent-worker-nodes","title":"2.4 Install K3s Agent (Worker Nodes)","text":"<p>SSH into each worker node and run:</p> <pre><code># Replace with YOUR values:\n#   K3S_URL    = https://&lt;master-ip&gt;:6443\n#   K3S_TOKEN  = &lt;token from master&gt;\n\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.10:6443 K3S_TOKEN=&lt;your-token&gt; sh -\n\n# Example with real values:\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.10:6443 K3S_TOKEN=K10abc123xyz... sh -\n</code></pre>"},{"location":"k3s/02-installation/#verify-on-worker","title":"Verify on Worker:","text":"<pre><code># Check agent is running\nsudo systemctl status k3s-agent\n\n# Should show: Active: active (running)\n</code></pre>"},{"location":"k3s/02-installation/#verify-on-master","title":"Verify on Master:","text":"<pre><code># Back on master, check all nodes\nsudo kubectl get nodes\n\n# Output:\n# NAME       STATUS   ROLES                  AGE   VERSION\n# master-1   Ready    control-plane,master   5m    v1.28.x+k3s1\n# worker-1   Ready    &lt;none&gt;                 30s   v1.28.x+k3s1\n# worker-2   Ready    &lt;none&gt;                 25s   v1.28.x+k3s1\n</code></pre>"},{"location":"k3s/02-installation/#repeat-for-each-worker","title":"Repeat for Each Worker","text":"<pre><code># Worker 2\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.10:6443 K3S_TOKEN=&lt;token&gt; sh -\n\n# Worker 3\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.1.10:6443 K3S_TOKEN=&lt;token&gt; sh -\n</code></pre>"},{"location":"k3s/02-installation/#25-configure-kubectl-access","title":"2.5 Configure kubectl Access","text":"<p>By default, you need <code>sudo</code> to run kubectl on the master. Let's fix that:</p>"},{"location":"k3s/02-installation/#option-a-copy-kubeconfig-to-your-user-recommended","title":"Option A: Copy kubeconfig to your user (Recommended)","text":"<pre><code># On master node:\nmkdir -p ~/.kube\nsudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config\nsudo chown $(id -u):$(id -g) ~/.kube/config\n\n# Now kubectl works without sudo!\nkubectl get nodes\n</code></pre>"},{"location":"k3s/02-installation/#option-b-set-kubeconfig-environment-variable","title":"Option B: Set KUBECONFIG environment variable","text":"<pre><code># Add to ~/.bashrc\necho 'export KUBECONFIG=/etc/rancher/k3s/k3s.yaml' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n\n# Still needs sudo for this file, or fix permissions:\nsudo chmod 644 /etc/rancher/k3s/k3s.yaml  # Less secure\n</code></pre>"},{"location":"k3s/02-installation/#option-c-access-from-your-local-machine","title":"Option C: Access from Your Local Machine","text":"<pre><code># On master, copy the kubeconfig\nsudo cat /etc/rancher/k3s/k3s.yaml\n\n# On your local machine:\nmkdir -p ~/.kube\n\n# Paste the content, BUT change this line:\n#   server: https://127.0.0.1:6443\n# To:\n#   server: https://&lt;master-ip&gt;:6443\n\n# Save as ~/.kube/config\n# Now you can run kubectl from your laptop!\n</code></pre>"},{"location":"k3s/02-installation/#26-verify-your-cluster","title":"2.6 Verify Your Cluster","text":""},{"location":"k3s/02-installation/#check-nodes","title":"Check Nodes","text":"<pre><code>kubectl get nodes -o wide\n\n# Output:\n# NAME       STATUS   ROLES                  AGE   VERSION        INTERNAL-IP     OS-IMAGE             KERNEL-VERSION\n# master-1   Ready    control-plane,master   10m   v1.28.x+k3s1   192.168.1.10    Ubuntu 22.04.3 LTS   5.15.0-xx\n# worker-1   Ready    &lt;none&gt;                 5m    v1.28.x+k3s1   192.168.1.11    Ubuntu 22.04.3 LTS   5.15.0-xx\n# worker-2   Ready    &lt;none&gt;                 5m    v1.28.x+k3s1   192.168.1.12    Ubuntu 22.04.3 LTS   5.15.0-xx\n</code></pre>"},{"location":"k3s/02-installation/#check-system-pods","title":"Check System Pods","text":"<pre><code>kubectl get pods -A\n\n# Output (K3s comes with these pre-installed):\n# NAMESPACE     NAME                                      READY   STATUS    RESTARTS   AGE\n# kube-system   coredns-597584b69b-xxxxx                  1/1     Running   0          10m\n# kube-system   local-path-provisioner-79f67d76f8-xxxxx  1/1     Running   0          10m\n# kube-system   metrics-server-5c8978b444-xxxxx          1/1     Running   0          10m\n# kube-system   traefik-7d5f6474df-xxxxx                 1/1     Running   0          10m\n</code></pre> <p>What are these?</p> Pod Purpose <code>coredns</code> DNS for service discovery <code>local-path-provisioner</code> Dynamic storage provisioning <code>metrics-server</code> Resource metrics (CPU, memory) <code>traefik</code> Ingress controller (HTTP routing)"},{"location":"k3s/02-installation/#check-cluster-info","title":"Check Cluster Info","text":"<pre><code>kubectl cluster-info\n\n# Output:\n# Kubernetes control plane is running at https://192.168.1.10:6443\n# CoreDNS is running at https://192.168.1.10:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n# Metrics-server is running at https://192.168.1.10:6443/api/v1/namespaces/kube-system/services/https:metrics-server:https/proxy\n</code></pre>"},{"location":"k3s/02-installation/#27-your-first-deployment-test","title":"2.7 Your First Deployment (Test!)","text":"<p>Let's deploy something to verify everything works:</p> <pre><code># Create a simple nginx deployment\nkubectl create deployment nginx --image=nginx\n\n# Check it's running\nkubectl get pods\n\n# Output:\n# NAME                     READY   STATUS    RESTARTS   AGE\n# nginx-77b4fdf86c-xxxxx   1/1     Running   0          30s\n\n# Expose it as a service\nkubectl expose deployment nginx --port=80 --type=NodePort\n\n# Get the NodePort\nkubectl get svc nginx\n\n# Output:\n# NAME    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\n# nginx   NodePort   10.43.xxx.xx   &lt;none&gt;        80:31234/TCP   5s\n#                                                    \u2191\n#                                            This port (31234)\n\n# Access it from any node's IP!\ncurl http://192.168.1.10:31234\ncurl http://192.168.1.11:31234\ncurl http://192.168.1.12:31234\n\n# All should return nginx welcome page HTML!\n</code></pre>"},{"location":"k3s/02-installation/#check-where-the-pod-is-running","title":"Check Where the Pod is Running","text":"<pre><code>kubectl get pods -o wide\n\n# Output:\n# NAME                     READY   STATUS    NODE       \n# nginx-77b4fdf86c-xxxxx   1/1     Running   worker-1   \n\n# It landed on worker-1, but accessible from ANY node IP!\n</code></pre>"},{"location":"k3s/02-installation/#clean-up-test-deployment","title":"Clean Up Test Deployment","text":"<pre><code>kubectl delete deployment nginx\nkubectl delete service nginx\n</code></pre>"},{"location":"k3s/02-installation/#28-essential-kubectl-commands","title":"2.8 Essential kubectl Commands","text":""},{"location":"k3s/02-installation/#the-ones-youll-use-daily","title":"The Ones You'll Use Daily","text":"<pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# VIEWING RESOURCES\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nkubectl get &lt;resource&gt;              # List resources\nkubectl get pods                    # List pods\nkubectl get pods -o wide            # More details (node, IP)\nkubectl get pods -A                 # All namespaces\nkubectl get deploy,svc,pods         # Multiple types\n\nkubectl describe &lt;resource&gt; &lt;name&gt;  # Detailed info\nkubectl describe pod nginx-xxxxx    # Pod details, events, errors\n\nkubectl logs &lt;pod&gt;                  # Container logs\nkubectl logs -f &lt;pod&gt;               # Follow logs (tail -f)\nkubectl logs &lt;pod&gt; -c &lt;container&gt;   # Specific container in pod\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# CREATING RESOURCES\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nkubectl apply -f file.yaml          # Create/update from file\nkubectl apply -f ./manifests/       # Apply whole directory\nkubectl apply -f https://url/x.yaml # Apply from URL\n\nkubectl create deployment x --image=y  # Quick create (imperative)\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# MODIFYING RESOURCES\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nkubectl edit deployment nginx       # Edit live (opens vim)\nkubectl scale deployment nginx --replicas=5  # Scale up/down\nkubectl set image deployment/nginx nginx=nginx:1.25  # Update image\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# DELETING RESOURCES\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nkubectl delete -f file.yaml         # Delete what's in file\nkubectl delete pod nginx-xxxxx      # Delete specific pod\nkubectl delete deployment nginx     # Delete deployment (and pods)\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# DEBUGGING\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nkubectl exec -it &lt;pod&gt; -- bash      # Shell into pod\nkubectl exec -it &lt;pod&gt; -- sh        # If bash not available\nkubectl exec &lt;pod&gt; -- ls /app       # Run command in pod\n\nkubectl port-forward pod/nginx 8080:80    # Access pod locally\nkubectl port-forward svc/nginx 8080:80    # Access service locally\n\nkubectl top nodes                   # Node CPU/memory usage\nkubectl top pods                    # Pod CPU/memory usage\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# USEFUL FLAGS\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n-n &lt;namespace&gt;                      # Specific namespace\n-A                                  # All namespaces\n-o wide                             # More columns\n-o yaml                             # Output as YAML\n-o json                             # Output as JSON\n--watch                             # Watch for changes\n-l app=nginx                        # Filter by label\n</code></pre>"},{"location":"k3s/02-installation/#shortcuts-aliases","title":"Shortcuts (Aliases)","text":"<pre><code># Add to ~/.bashrc for convenience\nalias k='kubectl'\nalias kgp='kubectl get pods'\nalias kgs='kubectl get svc'\nalias kgd='kubectl get deployments'\nalias kga='kubectl get all'\nalias kaf='kubectl apply -f'\nalias kdel='kubectl delete'\nalias klog='kubectl logs -f'\nalias kexec='kubectl exec -it'\n\n# Now you can type:\nk get pods\nkgp -A\nkaf myapp.yaml\n</code></pre>"},{"location":"k3s/02-installation/#29-useful-k3s-specific-commands","title":"2.9 Useful K3s-Specific Commands","text":"<pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# K3S SERVICE MANAGEMENT\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n# On master:\nsudo systemctl status k3s\nsudo systemctl restart k3s\nsudo systemctl stop k3s\nsudo journalctl -u k3s -f           # View K3s logs\n\n# On workers:\nsudo systemctl status k3s-agent\nsudo systemctl restart k3s-agent\nsudo journalctl -u k3s-agent -f     # View agent logs\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# K3S UTILITIES\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n# K3s bundles these tools:\nk3s kubectl get nodes               # Same as kubectl\nk3s crictl ps                       # List containers (low-level)\nk3s crictl images                   # List images\nk3s ctr containers list             # containerd CLI\n\n# Check K3s configuration\ncat /etc/rancher/k3s/k3s.yaml       # Kubeconfig\ncat /var/lib/rancher/k3s/server/node-token  # Join token\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# UNINSTALL (if needed)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n# On master:\n/usr/local/bin/k3s-uninstall.sh\n\n# On workers:\n/usr/local/bin/k3s-agent-uninstall.sh\n</code></pre>"},{"location":"k3s/02-installation/#210-summary-what-you-have-now","title":"2.10 Summary: What You Have Now","text":"<pre><code>\u2705 K3s master running on master-1\n\u2705 K3s agents running on worker-1, worker-2, ...\n\u2705 All nodes can see each other\n\u2705 kubectl configured and working\n\u2705 Cluster ready for deployments!\n\nYour cluster:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  master-1 (control-plane)                                   \u2502\n\u2502  \u251c\u2500\u2500 API Server (port 6443)                                 \u2502\n\u2502  \u251c\u2500\u2500 Scheduler                                              \u2502\n\u2502  \u251c\u2500\u2500 Controller Manager                                     \u2502\n\u2502  \u251c\u2500\u2500 CoreDNS (service discovery)                           \u2502\n\u2502  \u251c\u2500\u2500 Traefik (ingress)                                     \u2502\n\u2502  \u2514\u2500\u2500 Metrics Server                                        \u2502\n\u2502                                                             \u2502\n\u2502  worker-1 (agent)                                          \u2502\n\u2502  \u251c\u2500\u2500 kubelet                                               \u2502\n\u2502  \u2514\u2500\u2500 Ready to run pods                                     \u2502\n\u2502                                                             \u2502\n\u2502  worker-2 (agent)                                          \u2502\n\u2502  \u251c\u2500\u2500 kubelet                                               \u2502\n\u2502  \u2514\u2500\u2500 Ready to run pods                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/02-installation/#next-steps","title":"Next Steps","text":"<p>Part 3: We'll deploy your SeaweedFS cluster on this K3s setup! - Create the YAML manifests - Deploy master, filer, volume servers - Set up FUSE mounts with privileged containers - Test distributed storage</p> <p>Ready to proceed?</p>"},{"location":"k3s/k8s-core-concepts/","title":"Kubernetes Core Concepts","text":""},{"location":"k3s/k8s-core-concepts/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          CONTROL PLANE                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 API Server  \u2502  \u2502  Scheduler  \u2502  \u2502 Controller  \u2502  \u2502    etcd     \u2502 \u2502\n\u2502  \u2502             \u2502  \u2502             \u2502  \u2502   Manager   \u2502  \u2502  (storage)  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u2502 manages\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       CLUSTER ADD-ONS                                \u2502\n\u2502         (run as pods, but provide cluster-wide services)             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502  \u2502   CoreDNS   \u2502  \u2502 kube-proxy  \u2502  \u2502   Metrics   \u2502                  \u2502\n\u2502  \u2502   (DNS)     \u2502  \u2502 (networking)\u2502  \u2502   Server    \u2502                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u2502 runs on\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            NODES                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 Node                                                            \u2502\u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502  \u2502  \u2502                      kubelet                              \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  (talks to API server, manages pods on this node)         \u2502   \u2502\u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502  \u2502                            \u2502                                    \u2502\u2502\n\u2502  \u2502                            \u2502 uses                               \u2502\u2502\n\u2502  \u2502                            \u25bc                                    \u2502\u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502  \u2502  \u2502              Container Runtime (containerd)               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  (actually pulls images, starts/stops containers)         \u2502   \u2502\u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502  \u2502                            \u2502                                    \u2502\u2502\n\u2502  \u2502                            \u2502 runs                               \u2502\u2502\n\u2502  \u2502                            \u25bc                                    \u2502\u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\u2502\n\u2502  \u2502  \u2502                        Pods                               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u2502   pod-1   \u2502 \u2502   pod-2   \u2502 \u2502   pod-3   \u2502               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u2502\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 \u2502\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u2502\u2502container\u2502\u2502 \u2502\u2502container\u2502\u2502 \u2502\u2502container\u2502\u2502               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502 \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502               \u2502   \u2502\u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502   \u2502\u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#component-responsibilities","title":"Component Responsibilities","text":"Layer Component What it does Control Plane API Server Single entry point, all components talk through it Scheduler Decides which node runs each pod Controller Manager Runs controllers (Deployment, StatefulSet, DaemonSet, etc.) etcd Key-value store, holds all cluster state Add-ons CoreDNS Translates service names \u2192 IPs (<code>master.seaweedfs</code> \u2192 <code>10.43.x.x</code>) kube-proxy Network rules, routes service IPs to pod IPs Metrics Server Optional, provides CPU/memory metrics for <code>kubectl top</code> Node kubelet Agent on each node, manages pod lifecycle containerd Container runtime, does the actual container work Pods Your workloads"},{"location":"k3s/k8s-core-concepts/#yaml-fields-k8s-components","title":"YAML Fields \u2192 K8s Components","text":"<pre><code>apiVersion: apps/v1              # \u2192 API Server: which API group handles this\nkind: StatefulSet                # \u2192 Controller Manager: which controller manages this\nmetadata:\n  name: master                   # \u2192 etcd: stored as unique key\n  namespace: seaweedfs           # \u2192 etcd: partition/folder for storage\n  labels:                        # \u2192 etcd: stored metadata for filtering\n    app: seaweedfs\nspec:\n  serviceName: master            # \u2192 CoreDNS: creates DNS records\n  replicas: 1                    # \u2192 Controller Manager: desired state to maintain\n  selector:\n    matchLabels:                 # \u2192 Controller Manager: how to find owned pods\n      component: master\n  template:                      # \u2192 kubelet: blueprint for creating pods\n    metadata:\n      labels:                    # \u2192 etcd + Controller: pod identification\n        component: master\n    spec:\n      nodeSelector:              # \u2192 Scheduler: constraint for node selection\n        kubernetes.io/hostname: pavanjci\n      containers:                # \u2192 kubelet + containerd\n      - name: master             # \u2192 containerd: container identifier\n        image: seaweedfs:latest  # \u2192 containerd: what to pull/run\n        args: [...]              # \u2192 containerd: process arguments\n        ports:                   # \u2192 kube-proxy: network exposure info\n        - containerPort: 9333\n        volumeMounts:            # \u2192 kubelet: mount setup inside container\n        - name: data\n          mountPath: /data\n      volumes:                   # \u2192 kubelet: volume provisioning\n      - name: data\n        hostPath:\n          path: /data/seaweed/master\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#service-yaml","title":"Service YAML","text":"<pre><code>apiVersion: v1\nkind: Service                    # \u2192 kube-proxy + CoreDNS\nmetadata:\n  name: master                   # \u2192 CoreDNS: DNS name (master.seaweedfs.svc)\n  namespace: seaweedfs\nspec:\n  clusterIP: None                # \u2192 kube-proxy: headless, no load balancer IP\n  selector:                      # \u2192 kube-proxy: which pods to route to\n    component: master\n  ports:                         # \u2192 kube-proxy: port mapping rules\n  - port: 9333\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#field-to-component-mapping","title":"Field to Component Mapping","text":"YAML Field K8s Component Purpose <code>apiVersion</code> API Server Routes to correct API handler <code>kind</code> Controller Manager Picks which controller manages it <code>metadata.name</code> etcd Unique identifier, stored as key <code>metadata.namespace</code> etcd Logical partition <code>metadata.labels</code> etcd Stored for filtering/selection <code>spec.replicas</code> Controller Manager Desired state to reconcile <code>spec.selector</code> Controller Manager Links controller to pods <code>spec.serviceName</code> CoreDNS Stable DNS for StatefulSet pods <code>spec.template</code> kubelet Pod creation blueprint <code>nodeSelector</code> Scheduler Node placement constraint <code>containers</code> kubelet + containerd Actual workload definition <code>image</code> containerd Container image to run <code>ports</code> kube-proxy Network exposure <code>volumeMounts</code> kubelet In-container mount points <code>volumes</code> kubelet Volume source definitions Service <code>selector</code> kube-proxy Pod discovery for routing Service <code>clusterIP</code> kube-proxy Virtual IP assignment"},{"location":"k3s/k8s-core-concepts/#the-flow-what-happens-when-you-apply","title":"The Flow: What Happens When You Apply","text":"<pre><code>1. kubectl apply -f deployment.yaml\n                \u2502\n                \u25bc\n2. API Server: validates, stores in etcd\n                \u2502\n                \u25bc\n3. Controller Manager: sees new resource\n   \"I need 1 replica, currently 0, create pod\"\n                \u2502\n                \u25bc\n4. Scheduler: sees unscheduled pod\n   \"nodeSelector says node-1, assign there\"\n                \u2502\n                \u25bc\n5. kubelet (on node-1): sees pod assigned to it\n   \"Create container, mount volumes, start process\"\n                \u2502\n                \u25bc\n6. kube-proxy: sees Service + pod labels match\n   \"Route traffic for service:port to this pod\"\n                \u2502\n                \u25bc\n7. CoreDNS: sees Service\n   \"service.namespace.svc.cluster.local \u2192 pod IP\"\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#labels-and-names","title":"Labels and Names","text":""},{"location":"k3s/k8s-core-concepts/#whats-required-vs-optional","title":"What's Required vs Optional","text":"Field Required? Purpose <code>metadata.name</code> Yes K8s resource identifier <code>metadata.namespace</code> No (defaults to <code>default</code>) Isolation <code>spec.selector.matchLabels</code> Yes Links controller \u2192 pods <code>template.metadata.labels</code> Yes Must match selector <code>spec.serviceName</code> StatefulSet only Stable pod DNS <code>app</code>, <code>component</code>, etc. No Human organization + filtering"},{"location":"k3s/k8s-core-concepts/#label-rules","title":"Label Rules","text":"<ul> <li><code>selector.matchLabels</code> must be a subset of <code>template.metadata.labels</code></li> <li>Label keys can be anything (<code>app</code>, <code>component</code>, <code>banana</code>, etc.)</li> <li>Labels are just key-value pairs for filtering</li> </ul> <pre><code># Valid - template has more labels than selector\nselector:\n  matchLabels:\n    component: master\ntemplate:\n  metadata:\n    labels:\n      component: master    # matches selector\n      app: seaweedfs       # extra, ignored by selector\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#namespace-vs-app-label","title":"Namespace vs App Label","text":"Aspect Namespace <code>app</code> label What it is K8s built-in isolation Just a text label Enforced by Kubernetes itself Nothing (convention) Scope Resources isolated No effect on visibility Network Services need full DNS to cross No effect Deletion <code>kubectl delete ns X</code> removes all Just a filter"},{"location":"k3s/k8s-core-concepts/#k3s-vs-full-kubernetes","title":"K3s vs Full Kubernetes","text":"Full K8s K3s etcd SQLite (or etcd optional) Separate binaries Single <code>k3s</code> binary containerd separate containerd bundled kube-proxy separate Built into k3s"},{"location":"k3s/k8s-core-concepts/#useful-commands","title":"Useful Commands","text":"<pre><code># View control plane components\nkubectl get pods -n kube-system\n\n# View CoreDNS\nkubectl get pods -n kube-system -l k8s-app=kube-dns\n\n# Filter by labels\nkubectl get pods -l app=seaweedfs\nkubectl get pods -l component=master\nkubectl logs -l component=mount\n\n# Multiple labels (AND)\nkubectl get pods -l app=seaweedfs,component=master\n\n# All namespaces\nkubectl get pods -A -l app=seaweedfs\n</code></pre>"},{"location":"k3s/k8s-core-concepts/#tags","title":"Tags","text":""},{"location":"k3s/k8s-core-concepts/#kubernetes-k8s-infrastructure-containers-devops","title":"kubernetes #k8s #infrastructure #containers #devops","text":""},{"location":"k3s/kubectl-commands/","title":"kubectl Commands Reference","text":""},{"location":"k3s/kubectl-commands/#basic-syntax","title":"Basic Syntax","text":"<pre><code>kubectl [command] [TYPE] [NAME] [flags]\n</code></pre>"},{"location":"k3s/kubectl-commands/#cluster-info","title":"Cluster Info","text":"<pre><code># Cluster info\nkubectl cluster-info\n\n# List all nodes\nkubectl get nodes\nkubectl get nodes -o wide\n\n# Node details\nkubectl describe node &lt;node-name&gt;\n\n# Check component status\nkubectl get componentstatuses\n</code></pre>"},{"location":"k3s/kubectl-commands/#namespaces","title":"Namespaces","text":"<pre><code># List namespaces\nkubectl get namespaces\nkubectl get ns\n\n# Create namespace\nkubectl create namespace &lt;name&gt;\n\n# Delete namespace (deletes everything inside)\nkubectl delete namespace &lt;name&gt;\n\n# Set default namespace for session\nkubectl config set-context --current --namespace=&lt;name&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#pods","title":"Pods","text":"<pre><code># List pods\nkubectl get pods\nkubectl get pods -n &lt;namespace&gt;\nkubectl get pods -A                      # All namespaces\nkubectl get pods -o wide                 # Show node, IP\nkubectl get pods -w                      # Watch mode\nkubectl get pods -l app=seaweedfs        # Filter by label\n\n# Pod details\nkubectl describe pod &lt;pod-name&gt; -n &lt;namespace&gt;\n\n# Pod logs\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --tail=50\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; -f              # Follow\nkubectl logs -l component=mount -n &lt;namespace&gt;         # By label\n\n# Execute command in pod\nkubectl exec -it &lt;pod-name&gt; -n &lt;namespace&gt; -- sh\nkubectl exec -it &lt;pod-name&gt; -n &lt;namespace&gt; -- bash\nkubectl exec &lt;pod-name&gt; -n &lt;namespace&gt; -- ls -la /data\n\n# Delete pod (will recreate if managed by controller)\nkubectl delete pod &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl delete pods -l component=mount -n &lt;namespace&gt;  # By label\n\n# Run debug pod\nkubectl run debug --rm -it --image=busybox -n &lt;namespace&gt; -- sh\n</code></pre>"},{"location":"k3s/kubectl-commands/#deployments","title":"Deployments","text":"<pre><code># List deployments\nkubectl get deployments -n &lt;namespace&gt;\nkubectl get deploy -n &lt;namespace&gt;\n\n# Create deployment\nkubectl create deployment &lt;name&gt; --image=&lt;image&gt;\n\n# Scale deployment\nkubectl scale deployment &lt;name&gt; --replicas=3 -n &lt;namespace&gt;\n\n# Update image\nkubectl set image deployment/&lt;name&gt; &lt;container&gt;=&lt;new-image&gt; -n &lt;namespace&gt;\n\n# Rollout status\nkubectl rollout status deployment/&lt;name&gt; -n &lt;namespace&gt;\n\n# Rollout history\nkubectl rollout history deployment/&lt;name&gt; -n &lt;namespace&gt;\n\n# Rollback\nkubectl rollout undo deployment/&lt;name&gt; -n &lt;namespace&gt;\n\n# Restart deployment\nkubectl rollout restart deployment/&lt;name&gt; -n &lt;namespace&gt;\n\n# Delete deployment\nkubectl delete deployment &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#statefulsets","title":"StatefulSets","text":"<pre><code># List statefulsets\nkubectl get statefulsets -n &lt;namespace&gt;\nkubectl get sts -n &lt;namespace&gt;\n\n# Scale\nkubectl scale statefulset &lt;name&gt; --replicas=3 -n &lt;namespace&gt;\n\n# Restart\nkubectl rollout restart statefulset &lt;name&gt; -n &lt;namespace&gt;\n\n# Delete\nkubectl delete statefulset &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#daemonsets","title":"DaemonSets","text":"<pre><code># List daemonsets\nkubectl get daemonsets -n &lt;namespace&gt;\nkubectl get ds -n &lt;namespace&gt;\n\n# Restart all pods in daemonset\nkubectl rollout restart daemonset &lt;name&gt; -n &lt;namespace&gt;\n\n# Delete\nkubectl delete daemonset &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#services","title":"Services","text":"<pre><code># List services\nkubectl get services -n &lt;namespace&gt;\nkubectl get svc -n &lt;namespace&gt;\n\n# Service details\nkubectl describe svc &lt;name&gt; -n &lt;namespace&gt;\n\n# Expose deployment as service\nkubectl expose deployment &lt;name&gt; --port=80 --target-port=8080 -n &lt;namespace&gt;\n\n# Port forward (access locally)\nkubectl port-forward svc/&lt;name&gt; &lt;local-port&gt;:&lt;service-port&gt; -n &lt;namespace&gt;\nkubectl port-forward pod/&lt;pod-name&gt; &lt;local-port&gt;:&lt;pod-port&gt; -n &lt;namespace&gt;\n\n# Delete service\nkubectl delete svc &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#configmaps-secrets","title":"ConfigMaps &amp; Secrets","text":"<pre><code># List\nkubectl get configmaps -n &lt;namespace&gt;\nkubectl get secrets -n &lt;namespace&gt;\n\n# Create configmap\nkubectl create configmap &lt;name&gt; --from-file=&lt;path&gt; -n &lt;namespace&gt;\nkubectl create configmap &lt;name&gt; --from-literal=key=value -n &lt;namespace&gt;\n\n# Create secret\nkubectl create secret generic &lt;name&gt; --from-literal=password=secret -n &lt;namespace&gt;\n\n# View secret (base64 decoded)\nkubectl get secret &lt;name&gt; -n &lt;namespace&gt; -o jsonpath='{.data.password}' | base64 -d\n\n# Delete\nkubectl delete configmap &lt;name&gt; -n &lt;namespace&gt;\nkubectl delete secret &lt;name&gt; -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#apply-delete-resources","title":"Apply &amp; Delete Resources","text":"<pre><code># Apply YAML\nkubectl apply -f &lt;file.yaml&gt;\nkubectl apply -f &lt;directory&gt;/\nkubectl apply -f https://raw.githubusercontent.com/...\n\n# Delete from YAML\nkubectl delete -f &lt;file.yaml&gt;\n\n# Create (fails if exists)\nkubectl create -f &lt;file.yaml&gt;\n\n# Replace (must exist)\nkubectl replace -f &lt;file.yaml&gt;\n\n# Dry run (preview changes)\nkubectl apply -f &lt;file.yaml&gt; --dry-run=client\nkubectl apply -f &lt;file.yaml&gt; --dry-run=server\n</code></pre>"},{"location":"k3s/kubectl-commands/#resource-inspection","title":"Resource Inspection","text":"<pre><code># Get YAML of existing resource\nkubectl get &lt;type&gt; &lt;name&gt; -n &lt;namespace&gt; -o yaml\nkubectl get pod &lt;name&gt; -n &lt;namespace&gt; -o yaml\n\n# Get JSON\nkubectl get &lt;type&gt; &lt;name&gt; -n &lt;namespace&gt; -o json\n\n# Get specific field\nkubectl get pod &lt;name&gt; -n &lt;namespace&gt; -o jsonpath='{.status.podIP}'\nkubectl get pods -n &lt;namespace&gt; -o jsonpath='{.items[*].metadata.name}'\n\n# Get all resources\nkubectl get all -n &lt;namespace&gt;\n\n# Get events\nkubectl get events -n &lt;namespace&gt;\nkubectl get events -n &lt;namespace&gt; --sort-by='.lastTimestamp'\n</code></pre>"},{"location":"k3s/kubectl-commands/#labels-selectors","title":"Labels &amp; Selectors","text":"<pre><code># Add label\nkubectl label pod &lt;name&gt; env=prod -n &lt;namespace&gt;\n\n# Remove label\nkubectl label pod &lt;name&gt; env- -n &lt;namespace&gt;\n\n# Filter by label\nkubectl get pods -l app=seaweedfs -n &lt;namespace&gt;\nkubectl get pods -l 'app in (nginx, redis)' -n &lt;namespace&gt;\nkubectl get pods -l app!=nginx -n &lt;namespace&gt;\n\n# Show labels\nkubectl get pods --show-labels -n &lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#resource-management","title":"Resource Management","text":"<pre><code># Top (requires metrics-server)\nkubectl top nodes\nkubectl top pods -n &lt;namespace&gt;\n\n# Resource usage\nkubectl describe node &lt;name&gt; | grep -A5 \"Allocated resources\"\n\n# Edit resource directly\nkubectl edit deployment &lt;name&gt; -n &lt;namespace&gt;\nkubectl edit svc &lt;name&gt; -n &lt;namespace&gt;\n\n# Patch resource\nkubectl patch svc &lt;name&gt; -n &lt;namespace&gt; -p '{\"spec\": {\"type\": \"NodePort\"}}'\n</code></pre>"},{"location":"k3s/kubectl-commands/#troubleshooting","title":"Troubleshooting","text":"<pre><code># Pod not starting - check events\nkubectl describe pod &lt;name&gt; -n &lt;namespace&gt;\nkubectl get events -n &lt;namespace&gt; --field-selector involvedObject.name=&lt;pod-name&gt;\n\n# Check logs\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt;\nkubectl logs &lt;pod-name&gt; -n &lt;namespace&gt; --previous    # Previous container\n\n# Debug with ephemeral container\nkubectl debug &lt;pod-name&gt; -it --image=busybox -n &lt;namespace&gt;\n\n# Check DNS resolution\nkubectl run dns-test --rm -it --image=busybox -- nslookup &lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local\n\n# Check connectivity\nkubectl run curl-test --rm -it --image=curlimages/curl -- curl http://&lt;service&gt;:&lt;port&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#context-config","title":"Context &amp; Config","text":"<pre><code># View config\nkubectl config view\n\n# List contexts\nkubectl config get-contexts\n\n# Current context\nkubectl config current-context\n\n# Switch context\nkubectl config use-context &lt;context-name&gt;\n\n# Set default namespace\nkubectl config set-context --current --namespace=&lt;namespace&gt;\n</code></pre>"},{"location":"k3s/kubectl-commands/#common-shortcuts","title":"Common Shortcuts","text":"Short Full <code>po</code> pods <code>svc</code> services <code>deploy</code> deployments <code>ds</code> daemonsets <code>sts</code> statefulsets <code>ns</code> namespaces <code>cm</code> configmaps <code>pv</code> persistentvolumes <code>pvc</code> persistentvolumeclaims"},{"location":"k3s/kubectl-commands/#seaweedfs-specific-commands","title":"SeaweedFS Specific Commands","text":"<pre><code># Check all SeaweedFS pods\nkubectl get pods -n seaweedfs -o wide\n\n# Check logs\nkubectl logs -l component=master -n seaweedfs\nkubectl logs -l component=filer -n seaweedfs\nkubectl logs -l component=volume -n seaweedfs\nkubectl logs -l component=mount -n seaweedfs\n\n# Restart components\nkubectl delete pods -l component=mount -n seaweedfs\nkubectl rollout restart statefulset master -n seaweedfs\nkubectl rollout restart statefulset filer -n seaweedfs\nkubectl rollout restart daemonset volume -n seaweedfs\nkubectl rollout restart daemonset mount -n seaweedfs\n\n# Port forward for UI\nkubectl port-forward svc/master -n seaweedfs 9333:9333\nkubectl port-forward svc/filer -n seaweedfs 8888:8888\n\n# Exec into pods\nkubectl exec -it master-0 -n seaweedfs -- sh\nkubectl exec -it filer-0 -n seaweedfs -- sh\n\n# Check services\nkubectl get svc -n seaweedfs\n\n# Full cleanup\nkubectl delete namespace seaweedfs\n</code></pre>"},{"location":"k3s/kubectl-commands/#useful-aliases-add-to-bashrc-or-zshrc","title":"Useful Aliases (add to ~/.bashrc or ~/.zshrc)","text":"<pre><code>alias k='kubectl'\nalias kgp='kubectl get pods'\nalias kgpa='kubectl get pods -A'\nalias kgs='kubectl get svc'\nalias kgn='kubectl get nodes'\nalias kd='kubectl describe'\nalias kl='kubectl logs'\nalias klf='kubectl logs -f'\nalias kex='kubectl exec -it'\nalias kaf='kubectl apply -f'\nalias kdf='kubectl delete -f'\nalias kns='kubectl config set-context --current --namespace'\n</code></pre>"},{"location":"k3s/kubectl-commands/#tags","title":"Tags","text":""},{"location":"k3s/kubectl-commands/#kubernetes-kubectl-k8s-devops-commands","title":"kubernetes #kubectl #k8s #devops #commands","text":""},{"location":"reference/legacy/","title":"Legacy Documentation","text":"<p>Archived documentation from earlier versions of Data Miner.</p>"},{"location":"reference/legacy/#documents","title":"Documents","text":"<ul> <li>Async Pipeline Implementation Plan - Original async/queue-based design proposal</li> <li>Video Miner V3 Async - V3 async implementation notes</li> <li>Video Miner V3 Code Walkthrough - V3 file-based registry walkthrough</li> </ul> <p>Note: These documents describe earlier versions of the pipeline. The current architecture uses PostgreSQL-backed state management and supervisor-managed workers. See Architecture Overview for current documentation.</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/","title":"Async Pipeline Implementation Design","text":"<p>Goal: Process 1000s of videos efficiently with stage-level parallelism</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#1-concurrency-model-analysis","title":"1. Concurrency Model Analysis","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#comparison-matrix","title":"Comparison Matrix","text":"Aspect <code>asyncio</code> <code>threading</code> <code>multiprocessing</code> GIL Impact N/A (single thread) Blocked for CPU No GIL (separate process) I/O Bound \u2705 Excellent \u2705 Good \u26a0\ufe0f Overkill CPU Bound \u274c Poor \u274c Poor (GIL) \u2705 Excellent GPU Sharing \u2705 Easy (same process) \u2705 Works \u274c Complex (IPC) Memory Low Moderate High (per-process) Queue Overhead Minimal Minimal Serialization cost"},{"location":"reference/legacy/async_pipeline_implementation_plan/#workload-analysis","title":"Workload Analysis","text":"Stage I/O vs CPU Best Fit Download Network I/O <code>asyncio</code> + <code>aiohttp</code> or ThreadPool Extract Disk I/O + CPU decode ThreadPool (PyAV releases GIL) Filter GPU compute ThreadPool (PyTorch releases GIL) Dedup GPU compute ThreadPool Detect GPU compute ThreadPool"},{"location":"reference/legacy/async_pipeline_implementation_plan/#recommendation","title":"Recommendation","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  asyncio Event Loop (Main Orchestrator)                     \u2502\n\u2502  \u251c\u2500\u2500 manages queues and flow control                        \u2502\n\u2502  \u2514\u2500\u2500 spawns ThreadPoolExecutor for blocking operations      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Hybrid approach: <code>asyncio</code> for orchestration + <code>ThreadPoolExecutor</code> for blocking calls.</p> <ul> <li>PyTorch and PyAV release the GIL during heavy computation</li> <li>Keeps GPU in single process (avoids CUDA context issues)</li> <li>Simple queue semantics with <code>asyncio.Queue</code></li> </ul>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#2-queue-communication-analysis","title":"2. Queue Communication Analysis","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#options","title":"Options","text":"Queue Type Pros Cons Best For <code>asyncio.Queue</code> Simple, in-memory Single process only Our use case <code>queue.Queue</code> Thread-safe Blocks event loop Mixed threading <code>multiprocessing.Queue</code> Cross-process Serialization overhead Not needed Redis/RabbitMQ Distributed, persistent External dependency Multi-machine"},{"location":"reference/legacy/async_pipeline_implementation_plan/#message-protocol","title":"Message Protocol","text":"<p>Principle: Pass folder paths (lightweight), not data (heavy).</p> <pre><code>@dataclass\nclass StageMessage:\n    video_id: str\n    input_path: Path      # Folder/file from previous stage\n    metadata: dict        # Optional stage-specific data\n    timestamp: float      # For monitoring latency\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#queue-sizing","title":"Queue Sizing","text":"<pre><code>max_queue_size = 2 \u00d7 num_workers_next_stage\n</code></pre> <p>This provides backpressure without blocking upstream workers.</p>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#3-architecture-design","title":"3. Architecture Design","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#class-hierarchy-reusable-components","title":"Class Hierarchy (Reusable Components)","text":"<pre><code>classDiagram\n    class BaseStageWorker {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +input_queue: Queue\n        +output_queue: Queue\n        +executor: ThreadPoolExecutor\n        +shutdown: Event\n        +process(msg: StageMessage)* StageMessage\n        +run_loop()\n        +_run_blocking(func, *args)\n    }\n\n    class DownloadWorker {\n        +downloader: YouTubeDownloader\n        +process(msg) StageMessage\n    }\n\n    class ExtractWorker {\n        +extractor: FrameExtractor\n        +process(msg) StageMessage\n    }\n\n    class FilterWorker {\n        +filter: FrameFilter\n        +process(msg) StageMessage\n    }\n\n    class DedupCollector {\n        +collected: dict\n        +process(msg) StageMessage\n    }\n\n    BaseStageWorker &lt;|-- DownloadWorker\n    BaseStageWorker &lt;|-- ExtractWorker\n    BaseStageWorker &lt;|-- FilterWorker\n    BaseStageWorker &lt;|-- DedupCollector</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#base-worker-pattern","title":"Base Worker Pattern","text":"<pre><code>class BaseStageWorker(ABC):\n    \"\"\"Abstract base for all pipeline stage workers.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        input_queue: asyncio.Queue,\n        output_queue: asyncio.Queue,\n        executor: ThreadPoolExecutor,\n    ):\n        self.name = name\n        self.input_queue = input_queue\n        self.output_queue = output_queue\n        self.executor = executor\n        self.shutdown = asyncio.Event()\n        self.processed_count = 0\n\n    @abstractmethod\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        \"\"\"Process one message. Return None to drop.\"\"\"\n        pass\n\n    async def run_loop(self):\n        \"\"\"Main worker loop - DO NOT OVERRIDE.\"\"\"\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.input_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            try:\n                # Run blocking process() in thread pool\n                result = await self._run_blocking(self.process, msg)\n                if result:\n                    await self.output_queue.put(result)\n                self.processed_count += 1\n            except Exception as e:\n                logger.error(f\"{self.name} failed on {msg.video_id}: {e}\")\n            finally:\n                self.input_queue.task_done()\n\n    async def _run_blocking(self, func, *args):\n        \"\"\"Execute blocking function in thread pool.\"\"\"\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(self.executor, func, *args)\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#pipeline-orchestrator","title":"Pipeline Orchestrator","text":"<pre><code>flowchart TB\n    subgraph Queues\n        Q0[(URL Queue)]\n        Q1[(Download Queue)]\n        Q2[(Extract Queue)]\n        Q3[(Filter Queue)]\n        Q4[(Dedup Collector)]\n    end\n\n    subgraph Workers\n        DW1[Download 1]\n        DW2[Download 2]\n        EW1[Extract 1]\n        EW2[Extract 2]\n        FW[Filter - GPU]\n    end\n\n    Q0 --&gt; DW1 &amp; DW2\n    DW1 &amp; DW2 --&gt; Q1\n    Q1 --&gt; EW1 &amp; EW2\n    EW1 &amp; EW2 --&gt; Q2\n    Q2 --&gt; FW\n    FW --&gt; Q3\n    Q3 --&gt; Q4\n    Q4 --&gt; Dedup[Final Dedup]</code></pre> <pre><code>class AsyncPipelineOrchestrator:\n    \"\"\"Manages all stages and workers.\"\"\"\n\n    def __init__(self, config: PipelineConfig):\n        self.config = config\n\n        # Shared thread pool for blocking ops\n        self.executor = ThreadPoolExecutor(max_workers=8)\n\n        # Queues (sized for backpressure)\n        self.url_queue = asyncio.Queue()\n        self.download_queue = asyncio.Queue(maxsize=4)\n        self.extract_queue = asyncio.Queue(maxsize=4)\n        self.filter_queue = asyncio.Queue(maxsize=2)\n        self.dedup_queue = asyncio.Queue()\n\n        # Workers\n        self.workers = []\n\n    def _create_workers(self):\n        # Download workers (I/O bound, 2-3 concurrent)\n        for i in range(2):\n            self.workers.append(DownloadWorker(\n                name=f\"download-{i}\",\n                input_queue=self.url_queue,\n                output_queue=self.download_queue,\n                executor=self.executor,\n                config=self.config.download,\n            ))\n\n        # Extract workers (CPU bound, 2 concurrent)\n        for i in range(2):\n            self.workers.append(ExtractWorker(\n                name=f\"extract-{i}\",\n                input_queue=self.download_queue,\n                output_queue=self.extract_queue,\n                executor=self.executor,\n                config=self.config.extraction,\n            ))\n\n        # Filter worker (GPU, single to avoid contention)\n        self.workers.append(FilterWorker(\n            name=\"filter-gpu\",\n            input_queue=self.extract_queue,\n            output_queue=self.filter_queue,\n            executor=self.executor,\n            config=self.config.filter,\n        ))\n\n        # Dedup collector (accumulates results)\n        self.dedup_collector = DedupCollector(\n            input_queue=self.filter_queue,\n            output_queue=self.dedup_queue,\n        )\n        self.workers.append(self.dedup_collector)\n\n    async def run(self, urls: list[str]):\n        # Seed URL queue\n        for url in urls:\n            await self.url_queue.put(StageMessage(\n                video_id=get_video_id(url),\n                input_path=url,\n                metadata={},\n                timestamp=time.time(),\n            ))\n\n        # Start all workers\n        self._create_workers()\n        tasks = [asyncio.create_task(w.run_loop()) for w in self.workers]\n\n        # Wait for pipeline to drain\n        await self.url_queue.join()\n        await self.download_queue.join()\n        await self.extract_queue.join()\n        await self.filter_queue.join()\n\n        # Shutdown workers\n        for w in self.workers:\n            w.shutdown.set()\n        await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Final cross-video dedup\n        return await self._run_final_dedup()\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#4-worker-implementations-reusing-base","title":"4. Worker Implementations (Reusing Base)","text":"<p>Each worker only implements <code>process()</code>:</p> <pre><code>class DownloadWorker(BaseStageWorker):\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self.downloader = YouTubeDownloader(config)\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        result = self.downloader.download_single(msg.input_path)\n        if not result.success:\n            return None\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=result.output_path,\n            metadata={\"title\": result.title, \"duration\": result.duration},\n            timestamp=time.time(),\n        )\n\nclass ExtractWorker(BaseStageWorker):\n    def __init__(self, config, **kwargs):\n        super().__init__(**kwargs)\n        self.extractor = FrameExtractor(config)\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        result = self.extractor.extract_video(msg.input_path, msg.video_id)\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=result.output_dir,  # Folder of frames\n            metadata={\"frame_count\": result.frame_count},\n            timestamp=time.time(),\n        )\n\nclass FilterWorker(BaseStageWorker):\n    def __init__(self, config, classes, **kwargs):\n        super().__init__(**kwargs)\n        self.filter = FrameFilter(config)\n        self.classes = classes\n\n    def process(self, msg: StageMessage) -&gt; Optional[StageMessage]:\n        frames = sorted(Path(msg.input_path).glob(\"*.jpg\"))\n        result = self.filter.filter_frames(frames, self.classes, msg.video_id)\n\n        if result.passed_frames == 0:\n            return None\n\n        return StageMessage(\n            video_id=msg.video_id,\n            input_path=self.filter.config.output_dir / msg.video_id,\n            metadata={\"passed\": result.passed_frames, \"total\": result.total_frames},\n            timestamp=time.time(),\n        )\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#5-scaling-considerations","title":"5. Scaling Considerations","text":""},{"location":"reference/legacy/async_pipeline_implementation_plan/#worker-count-guidelines","title":"Worker Count Guidelines","text":"Stage Workers Rationale Download 2-3 Network limited, yt-dlp is heavy Extract 2 CPU decode, disk I/O Filter 1 GPU bound, avoid VRAM contention Dedup Collector 1 Just accumulates"},{"location":"reference/legacy/async_pipeline_implementation_plan/#memory-management","title":"Memory Management","text":"<pre><code># Cleanup raw frames after filtering\nif config.cleanup_intermediate:\n    shutil.rmtree(msg.input_path)  # Delete frames_raw/video_id\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#monitoring","title":"Monitoring","text":"<pre><code>@dataclass\nclass PipelineMetrics:\n    stage_counts: dict[str, int]      # processed per stage\n    stage_latencies: dict[str, float] # avg time per stage\n    queue_depths: dict[str, int]      # current queue sizes\n    errors: list[tuple[str, str]]     # (video_id, error)\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#6-file-structure","title":"6. File Structure","text":"<pre><code>video_miner_v3/\n\u251c\u2500\u2500 async_pipeline/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 base_worker.py      # BaseStageWorker\n\u2502   \u251c\u2500\u2500 messages.py         # StageMessage dataclass\n\u2502   \u251c\u2500\u2500 workers/\n\u2502   \u2502   \u251c\u2500\u2500 download.py     # DownloadWorker\n\u2502   \u2502   \u251c\u2500\u2500 extract.py      # ExtractWorker\n\u2502   \u2502   \u251c\u2500\u2500 filter.py       # FilterWorker\n\u2502   \u2502   \u2514\u2500\u2500 dedup.py        # DedupCollector\n\u2502   \u251c\u2500\u2500 orchestrator.py     # AsyncPipelineOrchestrator\n\u2502   \u2514\u2500\u2500 metrics.py          # PipelineMetrics\n</code></pre>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#7-migration-path","title":"7. Migration Path","text":"<ol> <li>Phase 1: Create <code>async_pipeline/</code> module alongside existing <code>pipeline.py</code></li> <li>Phase 2: Add CLI flag <code>--async-mode</code> to select new pipeline</li> <li>Phase 3: Validate with 100 videos, compare results</li> <li>Phase 4: Deprecate old sequential pipeline</li> </ol>"},{"location":"reference/legacy/async_pipeline_implementation_plan/#summary","title":"Summary","text":"Decision Choice Reasoning Concurrency asyncio + ThreadPool GPU in single process, GIL released by PyTorch Queue Type <code>asyncio.Queue</code> Simple, backpressure built-in Message Format Folder paths Lightweight, no serialization GPU Workers Single Avoid VRAM contention Base Class <code>BaseStageWorker</code> DRY principle, common <code>run_loop()</code>"},{"location":"reference/legacy/video_miner_v3_async/","title":"Parallel Pipeline Design Options","text":"<p>Two architectural approaches for parallelizing download \u2192 extract \u2192 filter stages.</p>"},{"location":"reference/legacy/video_miner_v3_async/#option-1-per-video-streaming-pipeline","title":"Option 1: Per-Video Streaming Pipeline","text":"<p>Concept: Each video flows through download\u2192extract\u2192filter as a unit, multiple videos processed concurrently.</p> <pre><code>flowchart LR\n    subgraph Parallel Workers\n        A1[Video 1] --&gt; B1[Download] --&gt; C1[Extract] --&gt; D1[Filter]\n        A2[Video 2] --&gt; B2[Download] --&gt; C2[Extract] --&gt; D2[Filter]\n        A3[Video 3] --&gt; B3[Download] --&gt; C3[Extract] --&gt; D3[Filter]\n    end\n\n    D1 --&gt; E[Collect Filtered]\n    D2 --&gt; E\n    D3 --&gt; E\n    E --&gt; F[Cross-Video Dedup]\n    F --&gt; G[Detection]</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#implementation-sketch","title":"Implementation Sketch","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor, as_completed\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass VideoProcessResult:\n    video_id: str\n    filtered_dir: Path\n    frame_count: int\n\nclass StreamingPipeline:\n    def __init__(self, config, registry):\n        self.config = config\n        self.registry = registry\n        self.downloader = YouTubeDownloader(config.download)\n        self.extractor = FrameExtractor(config.extraction)\n        # Shared filter model (thread-safe for inference)\n        self.filter = FrameFilter(config.filter)\n\n    def process_single_video(self, url: str) -&gt; VideoProcessResult:\n        \"\"\"Process one video through download \u2192 extract \u2192 filter.\"\"\"\n        video_id = get_video_id(url)\n\n        # Stage 1: Download\n        download_result = self.downloader.download_single(url)\n        if not download_result.success:\n            return None\n\n        # Stage 2: Extract frames\n        extraction_result = self.extractor.extract_video(\n            download_result.output_path, video_id\n        )\n\n        # Stage 3: Filter frames\n        filter_result = self.filter.filter_frames(\n            frame_paths=extraction_result.output_paths,\n            classes=self.config.classes,\n            video_id=video_id,\n        )\n\n        # Optional: Delete raw frames to save disk\n        if self.config.cleanup_raw_frames:\n            shutil.rmtree(extraction_result.output_dir)\n\n        return VideoProcessResult(\n            video_id=video_id,\n            filtered_dir=self.config.filter.output_dir / video_id,\n            frame_count=filter_result.passed_frames,\n        )\n\n    def run(self, urls: list[str], max_workers: int = 3):\n        \"\"\"Run parallel video processing.\"\"\"\n        results = []\n\n        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n            futures = {\n                executor.submit(self.process_single_video, url): url\n                for url in urls\n            }\n\n            for future in as_completed(futures):\n                result = future.result()\n                if result:\n                    results.append(result)\n                    # Update registry per-video\n                    self.registry.update_video(result.video_id, status=\"filtered\")\n\n        # Cross-video deduplication (after all videos filtered)\n        all_filtered_frames = self._collect_filtered_frames(results)\n        dedup_result = self.deduplicator.deduplicate_cross_video(all_filtered_frames)\n\n        return dedup_result\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#proscons","title":"Pros/Cons","text":"Pros Cons Simple mental model Limited by slowest stage Easy error handling per-video Filter model loaded N times if not shared Good for small batches Thread contention on GPU"},{"location":"reference/legacy/video_miner_v3_async/#option-2-stage-level-async-queues-folder-based","title":"Option 2: Stage-Level Async Queues (Folder-Based)","text":"<p>Concept: Separate workers for each stage, communicate via folder paths in queues. Each stage runs independently.</p> <pre><code>flowchart TB\n    subgraph Download Workers\n        DW1[Worker 1]\n        DW2[Worker 2]\n    end\n\n    subgraph Extract Workers\n        EW1[Worker 1]\n        EW2[Worker 2]\n    end\n\n    subgraph Filter Workers\n        FW1[Worker 1 - GPU]\n    end\n\n    Q1[(Download Queue)]\n    Q2[(Extract Queue)]\n    Q3[(Filter Queue)]\n    Q4[(Dedup Queue)]\n\n    URLs --&gt; Q1\n    Q1 --&gt; DW1 &amp; DW2\n    DW1 &amp; DW2 --&gt; Q2\n    Q2 --&gt; EW1 &amp; EW2\n    EW1 &amp; EW2 --&gt; Q3\n    Q3 --&gt; FW1\n    FW1 --&gt; Q4\n    Q4 --&gt; Dedup[Cross-Video Dedup]</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#implementation-sketch_1","title":"Implementation Sketch","text":"<pre><code>import asyncio\nfrom asyncio import Queue\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\n@dataclass\nclass StageMessage:\n    video_id: str\n    folder_path: Path  # Pass folder, not frames\n    stage: str\n\nclass AsyncQueuePipeline:\n    def __init__(self, config):\n        self.config = config\n        # Async queues between stages\n        self.download_queue = Queue()   # Input: URLs\n        self.extract_queue = Queue()    # Input: video paths\n        self.filter_queue = Queue()     # Input: frame folders\n        self.dedup_queue = Queue()      # Input: filtered folders\n\n        self.shutdown = asyncio.Event()\n\n    # =========== DOWNLOAD WORKER ===========\n    async def download_worker(self, worker_id: int):\n        \"\"\"Download videos, output video file path to extract queue.\"\"\"\n        downloader = YouTubeDownloader(self.config.download)\n\n        while not self.shutdown.is_set():\n            try:\n                url = await asyncio.wait_for(\n                    self.download_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            # Run blocking download in thread pool\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None, downloader.download_single, url\n            )\n\n            if result.success:\n                # Pass VIDEO FOLDER to next stage\n                await self.extract_queue.put(StageMessage(\n                    video_id=result.video_id,\n                    folder_path=result.output_path,\n                    stage=\"downloaded\",\n                ))\n\n            self.download_queue.task_done()\n\n    # =========== EXTRACT WORKER ===========\n    async def extract_worker(self, worker_id: int):\n        \"\"\"Extract frames, output frames folder to filter queue.\"\"\"\n        extractor = FrameExtractor(self.config.extraction)\n\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.extract_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                extractor.extract_video,\n                msg.folder_path,\n                msg.video_id,\n            )\n\n            # Pass FRAMES FOLDER to next stage\n            await self.filter_queue.put(StageMessage(\n                video_id=msg.video_id,\n                folder_path=result.output_dir,  # Folder of frames\n                stage=\"extracted\",\n            ))\n\n            self.extract_queue.task_done()\n\n    # =========== FILTER WORKER (GPU) ===========\n    async def filter_worker(self):\n        \"\"\"Filter frames using GPU. Single worker to avoid GPU contention.\"\"\"\n        filter_model = FrameFilter(self.config.filter)\n\n        while not self.shutdown.is_set():\n            try:\n                msg = await asyncio.wait_for(\n                    self.filter_queue.get(), timeout=1.0\n                )\n            except asyncio.TimeoutError:\n                continue\n\n            # Get all frame paths from folder\n            frame_paths = sorted(msg.folder_path.glob(\"*.jpg\"))\n\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                filter_model.filter_frames,\n                frame_paths,\n                self.config.classes,\n                msg.video_id,\n            )\n\n            # Pass FILTERED FOLDER to dedup\n            await self.dedup_queue.put(StageMessage(\n                video_id=msg.video_id,\n                folder_path=self.config.filter.output_dir / msg.video_id,\n                stage=\"filtered\",\n            ))\n\n            # Optional: cleanup raw frames\n            if self.config.cleanup_raw_frames:\n                shutil.rmtree(msg.folder_path)\n\n            self.filter_queue.task_done()\n\n    # =========== MAIN RUNNER ===========\n    async def run(self, urls: list[str]):\n        \"\"\"Run the full async pipeline.\"\"\"\n        # Seed the download queue\n        for url in urls:\n            await self.download_queue.put(url)\n\n        # Start workers\n        workers = [\n            asyncio.create_task(self.download_worker(1)),\n            asyncio.create_task(self.download_worker(2)),\n            asyncio.create_task(self.extract_worker(1)),\n            asyncio.create_task(self.extract_worker(2)),\n            asyncio.create_task(self.filter_worker()),  # Single GPU worker\n        ]\n\n        # Wait for all queues to drain\n        await self.download_queue.join()\n        await self.extract_queue.join()\n        await self.filter_queue.join()\n\n        # Signal shutdown\n        self.shutdown.set()\n        await asyncio.gather(*workers, return_exceptions=True)\n\n        # Collect all filtered folders for dedup\n        filtered_folders = {}\n        while not self.dedup_queue.empty():\n            msg = self.dedup_queue.get_nowait()\n            filtered_folders[msg.video_id] = list(msg.folder_path.glob(\"*.jpg\"))\n\n        # Final cross-video dedup\n        deduplicator = Deduplicator(self.config.deduplication)\n        return deduplicator.deduplicate_cross_video(filtered_folders)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_async/#proscons_1","title":"Pros/Cons","text":"Pros Cons Maximum parallelism More complex error handling Each stage scales independently Debugging harder Natural backpressure via queues Need careful queue sizing GPU worker isolation asyncio learning curve"},{"location":"reference/legacy/video_miner_v3_async/#comparison-summary","title":"Comparison Summary","text":"Aspect Option 1 (Per-Video) Option 2 (Async Queues) Complexity Low High Parallelism Per-video Per-stage GPU Utilization Moderate High (dedicated worker) Memory Higher (multiple videos in flight) Controlled via queue size Error Recovery Easy (per-video retry) Complex (stage isolation) Best For &lt; 50 videos 100+ videos"},{"location":"reference/legacy/video_miner_v3_async/#recommendation","title":"Recommendation","text":"<ul> <li>Start with Option 1 for simplicity</li> <li>Migrate to Option 2 if you need to process 100+ videos or want better GPU utilization</li> <li>Key insight: Pass folder paths between stages, not frame data, to minimize memory usage</li> </ul>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/","title":"Video Miner V3 - Detailed Code Walkthrough","text":"<p>A comprehensive guide to the architecture and code flow of Video Miner V3, a high-performance video mining pipeline for generating large-scale computer vision datasets from YouTube videos.</p> <p></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Project Overview</li> <li>Directory Structure</li> <li>Architecture Diagram</li> <li>Entry Points</li> <li>Configuration System</li> <li>Pipeline Orchestration</li> <li>Processing Modules</li> <li>ML Model Wrappers</li> <li>Video Registry System</li> <li>Utility Functions</li> <li>Data Flow</li> </ol>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#project-overview","title":"Project Overview","text":"<p>Video Miner V3 is designed to: - Search YouTube for videos by keyword - Download highest quality videos - Extract frames with configurable sampling - Filter frames using SigLIP2 semantic similarity - Deduplicate frames using DINOv2/v3 or SigLIP2 embeddings - Detect objects using open-set detection models</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#directory-structure","title":"Directory Structure","text":"<pre><code>video_miner_v3/\n\u251c\u2500\u2500 cli.py                 # Click CLI interface (509 lines)\n\u251c\u2500\u2500 config.py              # Pydantic configuration models (203 lines)\n\u251c\u2500\u2500 config_loader.py       # OmegaConf YAML loading (232 lines)\n\u251c\u2500\u2500 constants.py           # Centralized model IDs &amp; defaults (91 lines)\n\u251c\u2500\u2500 pipeline.py            # Main pipeline orchestrator (688 lines)\n\u251c\u2500\u2500 registry.py            # Video tracking registry (420 lines)\n\u251c\u2500\u2500 search.py              # YouTube search via yt-dlp (281 lines)\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 base.py            # BaseModel class, shared utilities\n\u2502   \u251c\u2500\u2500 siglip_model.py    # SigLIP2 wrapper for filtering\n\u2502   \u251c\u2500\u2500 dinov3_model.py    # DINOv2/v3 wrapper for dedup\n\u2502   \u2514\u2500\u2500 detector_models.py # Florence2, GroundingDINO, Moondream\n\u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 downloader.py      # YouTube video download\n\u2502   \u251c\u2500\u2500 frame_extractor.py # Frame extraction with PyAV\n\u2502   \u251c\u2500\u2500 frame_filter.py    # SigLIP-based filtering\n\u2502   \u251c\u2500\u2500 deduplicator.py    # Embedding-based dedup with FAISS\n\u2502   \u2514\u2500\u2500 detector.py        # Object detection orchestrator\n\u2514\u2500\u2500 utils/\n    \u251c\u2500\u2500 device.py          # CUDA/CPU device management\n    \u251c\u2500\u2500 io.py              # File I/O, video ID extraction\n    \u251c\u2500\u2500 validators.py      # Input validation\n    \u2514\u2500\u2500 query_generator.py # Query generation utilities\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#entry-points","title":"Entry Points","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#cli-clipy","title":"CLI (<code>cli.py</code>)","text":"<p>The main entry point is the <code>video-miner</code> CLI built with Click:</p> <pre><code>@click.group()\n@click.option('--verbose', '-v', is_flag=True)\n@click.pass_context\ndef main(ctx: click.Context, verbose: bool):\n    \"\"\"Video Miner v3 - High-performance video mining pipeline.\"\"\"\n    setup_logging(verbose)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#key-commands","title":"Key Commands","text":"Command Function Description <code>run-config</code> <code>run_config()</code> Run pipeline from YAML config file(s) <code>validate-config</code> <code>validate_config_cmd()</code> Validate YAML config without running <code>registry status</code> <code>registry_status()</code> Show registry statistics <code>registry list</code> <code>registry_list()</code> List videos in registry <code>registry export</code> <code>registry_export()</code> Export URLs to file"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pipeline-execution-flow","title":"Pipeline Execution Flow","text":"<pre><code>flowchart TD\n    A[run-config command] --&gt; B[Load YAML with OmegaConf]\n    B --&gt; C[validate_config]\n    C --&gt; D{Valid?}\n    D --&gt;|No| E[Print errors &amp; exit]\n    D --&gt;|Yes| F[_execute_pipeline]\n    F --&gt; G[gather_input_urls]\n    G --&gt; H[Create PipelineConfig]\n    H --&gt; I[VideoPipeline.run]</code></pre> <p>The <code>_execute_pipeline()</code> function: 1. Loads/creates the video registry 2. Executes optional search stage 3. Gathers URLs from config, files, or registry 4. Builds <code>PipelineConfig</code> with all stage configurations 5. Instantiates <code>VideoPipeline</code> and calls <code>run()</code></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#configuration-system","title":"Configuration System","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pydantic-models-configpy","title":"Pydantic Models (<code>config.py</code>)","text":"<p>All configuration uses Pydantic for validation:</p> <pre><code>classDiagram\n    PipelineConfig *-- DownloadConfig\n    PipelineConfig *-- ExtractionConfig\n    PipelineConfig *-- FilterConfig\n    PipelineConfig *-- DeduplicationConfig\n    PipelineConfig *-- DetectionConfig\n\n    class PipelineConfig {\n        +urls: list~str~\n        +classes: list~str~\n        +stages: list~str~\n        +device: str\n        +use_fp16: bool\n        +output_dir: Path\n        +get_urls() list~str~\n    }\n\n    class DownloadConfig {\n        +force: bool\n        +output_dir: Path\n        +max_concurrent: int\n        +timeout: int\n    }\n\n    class ExtractionConfig {\n        +force: bool\n        +output_dir: Path\n        +strategy: SamplingStrategy\n        +interval: int\n        +max_frames: int\n        +image_format: str\n        +quality: int\n    }\n\n    class FilterConfig {\n        +force: bool\n        +threshold: float\n        +model: FilterModel\n        +batch_size: int\n        +output_dir: Path\n        +model_id() str\n    }\n\n    class DeduplicationConfig {\n        +force: bool\n        +threshold: float\n        +use_siglip: bool\n        +batch_size: int\n        +output_dir: Path\n        +dino_model_id: str\n        +model_type() str\n    }\n\n    class DetectionConfig {\n        +force: bool\n        +detector: DetectorType\n        +confidence_threshold: float\n        +save_visualizations: bool\n        +output_dir: Path\n        +batch_size: int\n    }</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#enums","title":"Enums","text":"Enum Values Location <code>DetectorType</code> dino-x, moondream3, florence2, grounding-dino <code>config.py:35-40</code> <code>SamplingStrategy</code> interval, time, keyframe <code>config.py:43-47</code> <code>FilterModel</code> siglip2-so400m, siglip2-giant <code>config.py:50-53</code>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#omegaconf-loader-config_loaderpy","title":"OmegaConf Loader (<code>config_loader.py</code>)","text":"<p>Supports layered configuration merging:</p> <pre><code>def load_config(user_config, overrides, resolve=True):\n    \"\"\"\n    Merge order (later overrides earlier):\n    1. config/default.yaml (base defaults)\n    2. user_config (user overrides)\n    3. overrides dict (CLI/programmatic overrides)\n    \"\"\"\n</code></pre> <p>Key functions: - <code>load_config()</code> - Load and merge YAML configs - <code>validate_config()</code> - Validate required fields - <code>print_config()</code> - Pretty print configuration</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#constants-constantspy","title":"Constants (<code>constants.py</code>)","text":"<p>Centralized source of truth for all model IDs and defaults:</p> Category Models Default SigLIP2 siglip2-so400m, siglip2-giant siglip2-so400m DINO dinov3-small/base/large/huge/giant, dinov2-base/large dinov2-base Detectors dino-x, moondream3, florence2, grounding-dino moondream3 <p>Default thresholds: - Filter: 0.25 - Dedup: 0.90 - Detection: 0.3</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#pipeline-orchestration","title":"Pipeline Orchestration","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#videopipeline-pipelinepy","title":"VideoPipeline (<code>pipeline.py</code>)","text":"<p>The main orchestrator coordinates all processing stages:</p> <pre><code>flowchart LR\n    subgraph Stage 1\n        A[Download] --&gt; B[DownloadResult]\n    end\n    subgraph Stage 2\n        B --&gt; C[Extract Frames]\n        C --&gt; D[ExtractionResult]\n    end\n    subgraph Stage 3\n        D --&gt; E[Filter Frames]\n        E --&gt; F[FilterResult]\n    end\n    subgraph Stage 4\n        F --&gt; G[Deduplicate]\n        G --&gt; H[DeduplicationResult]\n    end\n    subgraph Stage 5\n        H --&gt; I[Detection]\n        I --&gt; J[DetectionBatchResult]\n    end\n    J --&gt; K[PipelineResult]</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#constructor","title":"Constructor","text":"<pre><code>class VideoPipeline:\n    def __init__(self, config: PipelineConfig, registry: Optional[\"VideoRegistry\"] = None):\n        self.config = config\n        self.registry = registry\n        # Lazy-loaded modules\n        self._downloader = None\n        self._extractor = None\n        self._frame_filter = None\n        self._deduplicator = None\n        self._detector = None\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#main-run-method","title":"Main Run Method","text":"<p><code>VideoPipeline.run()</code>:</p> <pre><code>def run(self, show_progress: bool = True) -&gt; PipelineResult:\n    stages = self.config.stages  # e.g., [\"download\", \"extract\", \"filter\", \"dedup\", \"detect\"]\n\n    if \"download\" in stages:\n        download_results = self._run_download(show_progress)\n        self._update_registry_downloads(download_results)\n\n    if \"extract\" in stages:\n        extraction_results = self._run_extraction(download_results, show_progress)\n        self._update_registry_extractions(extraction_results)\n\n    if \"filter\" in stages:\n        filter_results = self._run_filter(extraction_results, show_progress)\n        self._update_registry_filters(filter_results)\n\n    if \"dedup\" in stages:\n        dedup_result = self._run_deduplication(filter_results, show_progress)\n        self._update_registry_deduplication(dedup_result)\n\n    if \"detect\" in stages:\n        detection_result = self._run_detection(dedup_result, show_progress)\n        self._update_registry_detections(detection_result)\n\n    return PipelineResult(...)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#registry-aware-filtering","title":"Registry-Aware Filtering","text":"<p>The pipeline uses <code>_filter_by_registry()</code> to skip already-processed videos:</p> <pre><code>def _filter_by_registry(self, items, get_video_id, stage_name, force=False):\n    \"\"\"Skip items that have already completed the stage in registry.\"\"\"\n    if force or self.registry is None:\n        return items\n\n    filtered = []\n    for item in items:\n        video_id = get_video_id(item)\n        if not self.registry.is_stage_complete(video_id, stage_name):\n            filtered.append(item)\n    return filtered\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#processing-modules","title":"Processing Modules","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#1-downloader-downloaderpy","title":"1. Downloader (<code>downloader.py</code>)","text":"<p>Downloads YouTube videos using yt-dlp with concurrent processing.</p> <pre><code>flowchart TD\n    A[URL List] --&gt; B[ThreadPoolExecutor]\n    B --&gt; C1[download_single]\n    B --&gt; C2[download_single]\n    B --&gt; C3[download_single]\n    C1 --&gt; D[yt-dlp]\n    C2 --&gt; D\n    C3 --&gt; D\n    D --&gt; E[DownloadResult]</code></pre> <p>Key Classes: - <code>DownloadResult</code> - Dataclass with url, video_id, success, output_path, title, duration - <code>YouTubeDownloader</code> - Main downloader class</p> <p>Key Methods: - <code>download_single()</code> - Download one video - <code>download_batch()</code> - Concurrent batch download - <code>gather_input_urls()</code> - Collect URLs from config sources</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#2-frame-extractor-frame_extractorpy","title":"2. Frame Extractor (<code>frame_extractor.py</code>)","text":"<p>Extracts frames from videos using PyAV with configurable sampling strategies.</p> <p>Sampling Strategies:</p> Strategy Description <code>interval</code> Every N frames (default: 30) <code>time</code> Every N seconds <code>keyframe</code> Scene change detection <p>Key Classes: - <code>FrameInfo</code> - Dataclass with video_path, video_id, frame_number, timestamp, image - <code>ExtractionResult</code> - Dataclass with frame_count, output_paths, output_dir - <code>FrameExtractor</code> - Main extractor class</p> <p>Key Methods: - <code>iterate_frames()</code> - Generator yielding FrameInfo - <code>extract_video()</code> - Extract and save frames - <code>extract_batch()</code> - Concurrent batch extraction</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#3-frame-filter-frame_filterpy","title":"3. Frame Filter (<code>frame_filter.py</code>)","text":"<p>Filters frames using SigLIP2 text-image similarity.</p> <pre><code>flowchart LR\n    A[Frame Images] --&gt; B[SigLIPModel]\n    C[Text Classes] --&gt; B\n    B --&gt; D{Score &gt; Threshold?}\n    D --&gt;|Yes| E[Keep Frame]\n    D --&gt;|No| F[Discard]</code></pre> <p>Key Classes: - <code>FilteredFrame</code> - Dataclass with source_path, best_class, score, all_scores - <code>FilterResult</code> - Dataclass with total_frames, passed_frames, filtered_frames - <code>FrameFilter</code> - Main filter class</p> <p>Key Methods: - <code>filter_frames()</code> - Filter single video frames - <code>filter_batch()</code> - Filter multiple videos</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#4-deduplicator-deduplicatorpy","title":"4. Deduplicator (<code>deduplicator.py</code>)","text":"<p>Removes duplicate frames using embedding-based similarity with FAISS.</p> <p>Two-Phase Deduplication:</p> <pre><code>flowchart TD\n    subgraph Phase1[\"Phase 1: Per-Video\"]\n        A[All Frames] --&gt; B[Compute Embeddings]\n        B --&gt; C[Cosine Similarity]\n        C --&gt; D[Greedy Selection]\n    end\n\n    subgraph Phase2[\"Phase 2: Cross-Video\"]\n        D --&gt; E[FAISS Index]\n        E --&gt; F[KNN Search]\n        F --&gt; G[Merge Duplicates]\n    end\n\n    G --&gt; H[Unique Frames]</code></pre> <p>Algorithm Flow: 1. Phase 1 - Per-Video: Remove temporal duplicates within each video using greedy selection 2. Phase 2 - Cross-Video: Use FAISS ANN search to find and remove duplicates across all videos</p> <p>Supported Models: - DINOv2/v3 (default) - Best quality embeddings - SigLIP2 - Memory-efficient, reuses filter model</p> <p>Key Methods: - <code>deduplicate()</code> - Single batch deduplication - <code>deduplicate_cross_video()</code> - Two-phase cross-video dedup - <code>_faiss_dedup()</code> - FAISS-based O(N log N) dedup</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#5-object-detector-detectorpy","title":"5. Object Detector (<code>detector.py</code>)","text":"<p>Runs open-set object detection on frames.</p> <p>Supported Detectors:</p> Detector Model ID Notes Moondream3 <code>vikhyatk/moondream2</code> VQA + detection Florence-2 <code>microsoft/Florence-2-large</code> Multi-task Grounding DINO <code>IDEA-Research/grounding-dino-base</code> Stable <p>Key Methods: - <code>detect_single()</code> - Detect in one image - <code>detect_batch()</code> - Batch detection with progress</p> <p>Output: - <code>annotations.json</code> - COCO-format annotations - <code>visualizations/</code> - Images with bounding boxes</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#ml-model-wrappers","title":"ML Model Wrappers","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#base-model-basepy","title":"Base Model (<code>base.py</code>)","text":"<p>Abstract base class providing common functionality:</p> <pre><code>class BaseModel(ABC):\n    def __init__(self):\n        self.model = None\n        self.processor = None\n        self._loaded = False\n\n    @abstractmethod\n    def load(self) -&gt; None: pass\n\n    def unload(self) -&gt; None:\n        del self.model, self.processor\n        clear_gpu_cache()\n\n    def __enter__(self): self.load(); return self\n    def __exit__(self, *args): self.unload()\n</code></pre> <p>Utilities: - <code>load_image()</code> - Convert Path/np.array/PIL to RGB Image - <code>create_batch_iterator()</code> - Batch iterator with tqdm - <code>load_model_with_fallback()</code> - Try multiple model IDs</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#siglip-model-siglip_modelpy","title":"SigLIP Model (<code>siglip_model.py</code>)","text":"<p>Wrapper for Google's SigLIP2 for image-text similarity:</p> <pre><code>class SigLIPModel(BaseModel):\n    def compute_similarity(self, images, texts, batch_size=16):\n        \"\"\"Returns (N_images, N_texts) similarity matrix.\"\"\"\n        # Precompute text features\n        text_features = self.model.get_text_features(...)\n\n        # Process images in batches\n        for batch in create_batch_iterator(images, batch_size):\n            image_features = self.model.get_image_features(...)\n            logits = (image_features @ text_features.T) * self.model.logit_scale.exp()\n            scores = torch.sigmoid(logits)  # SigLIP uses sigmoid\n\n        return np.vstack(all_scores)\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#dinov3-model-dinov3_modelpy","title":"DINOv3 Model (<code>dinov3_model.py</code>)","text":"<p>Wrapper for Meta's DINOv2/v3 for image embeddings:</p> <pre><code>class DINOv3Model(BaseModel):\n    def get_embeddings(self, images, batch_size=32, normalize=True):\n        \"\"\"Returns (N_images, embedding_dim) array.\"\"\"\n        for batch in create_batch_iterator(images, batch_size):\n            outputs = self.model(**inputs)\n            embeddings = outputs.pooler_output  # or last_hidden_state[:, 0]\n\n        if normalize:\n            embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n        return embeddings\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#detector-models-detector_modelspy","title":"Detector Models (<code>detector_models.py</code>)","text":"<p>Unified interface for multiple detection backends:</p> <pre><code>classDiagram\n    BaseDetector &lt;|-- Florence2Detector\n    BaseDetector &lt;|-- GroundingDINODetector\n    BaseDetector &lt;|-- MoondreamDetector\n\n    class BaseDetector {\n        &lt;&lt;abstract&gt;&gt;\n        +device_map: str\n        +model: Any\n        +processor: Any\n        +load()*\n        +unload()*\n        +detect(image, prompt, threshold)* DetectionResult\n        -_load_image(image) Image\n    }\n\n    class Florence2Detector {\n        +model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }\n\n    class GroundingDINODetector {\n        +model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }\n\n    class MoondreamDetector {\n        +model_id: str\n        +_actual_model_id: str\n        +load()\n        +detect(image, prompt, threshold) DetectionResult\n    }</code></pre> <p>Factory function: <pre><code>def get_detector(detector_type: DetectorType, model_id: str, device_map: str):\n    if detector_type == DetectorType.FLORENCE2:\n        return Florence2Detector(model_id, device_map)\n    elif detector_type == DetectorType.GROUNDING_DINO:\n        return GroundingDINODetector(model_id, device_map)\n    elif detector_type == DetectorType.MOONDREAM3:\n        return MoondreamDetector(model_id, device_map)\n</code></pre></p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#video-registry-system","title":"Video Registry System","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#videoregistry-registrypy","title":"VideoRegistry (<code>registry.py</code>)","text":"<p>Pydantic-based YAML registry for tracking video processing status:</p> <pre><code>classDiagram\n    VideoRegistry *-- RegistryMetadata\n    VideoRegistry \"1\" *-- \"*\" VideoEntry : videos\n    VideoEntry *-- PipelineStages\n    PipelineStages *-- DownloadStage\n    PipelineStages *-- ExtractionStage\n    PipelineStages *-- FilterStage\n    PipelineStages *-- DeduplicationStage\n    PipelineStages *-- DetectionStage\n\n    class VideoRegistry {\n        +metadata: RegistryMetadata\n        +videos: dict~str VideoEntry~\n        +_lock: threading.Lock\n        +add_video(video_id, url, title) bool\n        +get_pending() list~VideoEntry~\n        +get_by_status(status) list~VideoEntry~\n        +update_stage(video_id, stage, data)\n        +is_stage_complete(video_id, stage) bool\n        +save(file_path)\n        +load(file_path)$ VideoRegistry\n        +load_or_create(file_path)$ VideoRegistry\n    }\n\n    class RegistryMetadata {\n        +created: str\n        +updated: str\n        +total_videos: int\n        +keywords_searched: list~str~\n        +version: str\n    }\n\n    class VideoEntry {\n        +video_id: str\n        +url: str\n        +title: str\n        +channel: str\n        +duration_seconds: int\n        +source_keyword: str\n        +status: VideoStatus\n        +added: str\n        +stages: PipelineStages\n        +notes: str\n        +is_processed() bool\n        +get_summary() dict\n    }\n\n    class PipelineStages {\n        +download: DownloadStage\n        +extraction: ExtractionStage\n        +filter: FilterStage\n        +deduplication: DeduplicationStage\n        +detection: DetectionStage\n    }\n\n    class DownloadStage {\n        +completed: bool\n        +path: str\n        +size_mb: float\n        +duration_seconds: float\n        +error: str\n    }\n\n    class FilterStage {\n        +completed: bool\n        +input_frames: int\n        +passed_frames: int\n        +output_dir: str\n        +pass_rate() float\n    }</code></pre> <p>VideoStatus Enum: <pre><code>class VideoStatus(str, Enum):\n    PENDING = \"pending\"\n    DOWNLOADING = \"downloading\"\n    DOWNLOADED = \"downloaded\"\n    EXTRACTING = \"extracting\"\n    EXTRACTED = \"extracted\"\n    FILTERING = \"filtering\"\n    FILTERED = \"filtered\"\n    DEDUPLICATING = \"deduplicating\"\n    DEDUPLICATED = \"deduplicated\"\n    DETECTING = \"detecting\"\n    DETECTED = \"detected\"\n    COMPLETE = \"complete\"\n    FAILED = \"failed\"\n    SKIPPED = \"skipped\"\n</code></pre></p> <p>Key Methods: - <code>add_video()</code> - Add video to registry - <code>update_stage()</code> - Update stage completion - <code>get_pending()</code> - Get unprocessed videos - <code>save()</code> - Thread-safe YAML save</p>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#utility-functions","title":"Utility Functions","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#device-management-devicepy","title":"Device Management (<code>device.py</code>)","text":"<pre><code>def resolve_device(device_map: str = \"auto\") -&gt; str:\n    \"\"\"Resolve device_map for HuggingFace model loading.\"\"\"\n    num_gpus = torch.cuda.device_count()\n    if device_map == \"auto\":\n        if num_gpus &gt; 1: return \"auto\"  # Multi-GPU\n        elif num_gpus == 1: return \"cuda\"\n        else: return \"cpu\"\n\ndef clear_gpu_cache():\n    \"\"\"Clear GPU cache to free memory.\"\"\"\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#io-utilities-iopy","title":"I/O Utilities (<code>io.py</code>)","text":"Function Description <code>ensure_dir()</code> Create directory if not exists <code>save_json()</code> / <code>load_json()</code> JSON file operations <code>get_video_id()</code> Extract YouTube video ID from URL <code>get_safe_filename()</code> Sanitize string for filesystem"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#data-flow","title":"Data Flow","text":""},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#complete-pipeline-flow","title":"Complete Pipeline Flow","text":"<pre><code>flowchart TB\n    subgraph Input\n        A[YAML Config] --&gt; B[load_config]\n        C[URL File/List] --&gt; D[gather_input_urls]\n        E[Registry] --&gt; D\n    end\n\n    subgraph Pipeline\n        D --&gt; F[YouTubeDownloader.download_batch]\n        F --&gt; G[FrameExtractor.extract_batch]\n        G --&gt; H[FrameFilter.filter_batch]\n        H --&gt; I[Deduplicator.deduplicate_cross_video]\n        I --&gt; J[ObjectDetector.detect_batch]\n    end\n\n    subgraph Models\n        K[SigLIPModel] --&gt; H\n        L[DINOv3Model] --&gt; I\n        M[Detector Models] --&gt; J\n    end\n\n    subgraph Output\n        F --&gt; N[videos/]\n        G --&gt; O[frames_raw/]\n        H --&gt; P[frames_filtered/]\n        I --&gt; Q[frames_deduplicated/]\n        J --&gt; R[detections/annotations.json]\n        J --&gt; S[detections/visualizations/]\n    end\n\n    subgraph Registry\n        F --&gt; T[Update download stage]\n        G --&gt; T\n        H --&gt; T\n        I --&gt; T\n        J --&gt; T\n        T --&gt; U[video_registry.yaml]\n    end</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#output-directory-structure","title":"Output Directory Structure","text":"<pre><code>output/\n\u251c\u2500\u2500 video_registry.yaml        # Video tracking\n\u251c\u2500\u2500 videos/                    # Downloaded videos\n\u2502   \u2514\u2500\u2500 {video_id}.mp4\n\u251c\u2500\u2500 frames_raw/{video_id}/     # All extracted frames\n\u2502   \u2514\u2500\u2500 frame_00001.jpg\n\u251c\u2500\u2500 frames_filtered/{video_id}/ # Frames passing filter\n\u2502   \u2514\u2500\u2500 frame_00042.jpg\n\u251c\u2500\u2500 frames_deduplicated/       # Unique frames\n\u2502   \u2514\u2500\u2500 frame_00042.jpg\n\u251c\u2500\u2500 detections/\n\u2502   \u251c\u2500\u2500 annotations.json       # COCO-format\n\u2502   \u2514\u2500\u2500 visualizations/        # Bounding box images\n\u2514\u2500\u2500 pipeline_result.json       # Summary statistics\n</code></pre>"},{"location":"reference/legacy/video_miner_v3_code_walkthrough/#summary","title":"Summary","text":"<p>Video Miner V3 is a well-architected pipeline with:</p> <ul> <li>Clean separation of concerns - Each module handles one stage</li> <li>Pydantic configuration - Type-safe, validated configs</li> <li>Registry tracking - Resume capability, no reprocessing</li> <li>Lazy model loading - Models loaded only when needed</li> <li>FAISS deduplication - O(N log N) scalable dedup</li> <li>Multiple detector backends - Florence2, GroundingDINO, Moondream</li> <li>Multi-GPU support - HuggingFace device_map=\"auto\"</li> </ul>"},{"location":"user-guide/cli-reference/","title":"CLI Reference","text":"<p>All commands are available via the <code>data-miner</code> CLI.</p> <pre><code>data-miner --help\n</code></pre>"},{"location":"user-guide/cli-reference/#core-commands","title":"Core Commands","text":""},{"location":"user-guide/cli-reference/#init-db","title":"<code>init-db</code>","text":"<p>Initialize database tables.</p> <pre><code>data-miner init-db\ndata-miner init-db --force  # Drop and recreate tables\n</code></pre>"},{"location":"user-guide/cli-reference/#populate","title":"<code>populate</code>","text":"<p>Add videos to the database from config sources (search queries, URLs, files).</p> <pre><code># Use config file\ndata-miner populate --config config.yaml\n\n# Dry run (show what would be added)\ndata-miner populate --config config.yaml --dry-run\n</code></pre>"},{"location":"user-guide/cli-reference/#add-video","title":"<code>add-video</code>","text":"<p>Add a single video URL.</p> <pre><code>data-miner add-video \"https://youtube.com/watch?v=...\" \\\n    --project my_project \\\n    --source-type url\n</code></pre> <p>Options: - <code>--project</code> - Project name (default: from config) - <code>--source-type</code> - <code>url</code>, <code>search</code>, or <code>file</code> - <code>--source-info</code> - Additional metadata</p>"},{"location":"user-guide/cli-reference/#status","title":"<code>status</code>","text":"<p>Show pipeline status.</p> <pre><code># All projects\ndata-miner status\n\n# Specific project\ndata-miner status --project my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#worker-management","title":"Worker Management","text":""},{"location":"user-guide/cli-reference/#workers-setup","title":"<code>workers setup</code>","text":"<p>Generate supervisor configuration.</p> <pre><code>data-miner workers setup --config config.yaml\n</code></pre> <p>This creates <code>/etc/supervisor/conf.d/data_miner.conf</code> with worker definitions.</p>"},{"location":"user-guide/cli-reference/#workers-start","title":"<code>workers start</code>","text":"<p>Start all workers.</p> <pre><code>data-miner workers start\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-stop","title":"<code>workers stop</code>","text":"<p>Stop all workers.</p> <pre><code>data-miner workers stop\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-restart","title":"<code>workers restart</code>","text":"<p>Restart all workers.</p> <pre><code>data-miner workers restart\n</code></pre>"},{"location":"user-guide/cli-reference/#workers-status","title":"<code>workers status</code>","text":"<p>Show supervisor worker status.</p> <pre><code>data-miner workers status\n</code></pre>"},{"location":"user-guide/cli-reference/#maintenance-commands","title":"Maintenance Commands","text":""},{"location":"user-guide/cli-reference/#delete-project","title":"<code>delete-project</code>","text":"<p>Delete a project and optionally its files.</p> <pre><code># Delete project (keep files)\ndata-miner delete-project my_project\n\n# Delete project and files\ndata-miner delete-project my_project --files\n\n# Also delete orphaned videos\ndata-miner delete-project my_project --files --orphans\n\n# Skip confirmation\ndata-miner delete-project my_project --yes\n</code></pre>"},{"location":"user-guide/cli-reference/#delete-videos","title":"<code>delete-videos</code>","text":"<p>Delete project-videos with optional filters.</p> <pre><code># Delete all FAILED videos\ndata-miner delete-videos --project my_project --pv-status FAILED\n\n# Delete videos and files\ndata-miner delete-videos --project my_project --pv-status FAILED --files\n</code></pre>"},{"location":"user-guide/cli-reference/#cleanup-orphans","title":"<code>cleanup-orphans</code>","text":"<p>Remove orphaned videos not linked to any project.</p> <pre><code>data-miner cleanup-orphans\ndata-miner cleanup-orphans --files  # Also delete files\n</code></pre>"},{"location":"user-guide/cli-reference/#force-dedup","title":"<code>force-dedup</code>","text":"<p>Force project back to DEDUP_READY stage (re-run cross-dedup).</p> <pre><code>data-miner force-dedup my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#force-detect","title":"<code>force-detect</code>","text":"<p>Force project back to DETECT_READY stage (re-run detection).</p> <pre><code>data-miner force-detect my_project\n</code></pre>"},{"location":"user-guide/cli-reference/#environment-variables","title":"Environment Variables","text":"Variable Description <code>DATA_MINER_CONFIG</code> Path to config file <code>DATABASE_URL</code> PostgreSQL connection string <code>HF_TOKEN</code> HuggingFace token for private models <code>DATA_MINER_DEBUG</code> Set to <code>1</code> to disable heartbeat (dev only)"},{"location":"user-guide/cli-reference/#next-steps","title":"Next Steps","text":"<ul> <li>Quickstart - End-to-end tutorial</li> <li>Configuration - Config options</li> </ul>"},{"location":"user-guide/configuration/","title":"Configuration","text":"<p>Data Miner uses YAML configuration files with OmegaConf for variable interpolation and Pydantic for validation.</p>"},{"location":"user-guide/configuration/#configuration-loading","title":"Configuration Loading","text":"<p>The config system supports three modes:</p> <ol> <li>Default config - Built-in defaults from <code>data_miner/config/default.yaml</code></li> <li>User config - Override with <code>--config path/to/config.yaml</code></li> <li>Environment variable - Set <code>DATA_MINER_CONFIG=/path/to/config.yaml</code></li> </ol> <p>User configs are merged with defaults, so you only need to specify overrides.</p>"},{"location":"user-guide/configuration/#minimal-config-example","title":"Minimal Config Example","text":"<pre><code># config.yaml\nproject_name: \"glass_doors\"\noutput_dir: \"./output\"\n\ninput:\n  search_queries:\n    - \"glass door installation\"\n    - \"sliding glass door\"\n  max_results_per_query: 50\n\nfilter:\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding door\"\n</code></pre>"},{"location":"user-guide/configuration/#full-configuration-reference","title":"Full Configuration Reference","text":""},{"location":"user-guide/configuration/#project-settings","title":"Project Settings","text":"<pre><code>project_name: \"my_project\"\noutput_dir: \"./output\"\nproject_output_dir: \"${output_dir}/projects/${project_name}\"\ndevice: \"auto\"  # auto, cuda, cuda:0, cpu\n</code></pre> <p>Variable Interpolation: Use <code>${section.key}</code> to reference other config values.</p>"},{"location":"user-guide/configuration/#input-sources","title":"Input Sources","text":"<pre><code>input:\n  # YouTube search\n  search_enabled: true\n  search_queries:\n    - \"glass door installation\"\n  max_results_per_query: 50\n\n  # Direct URLs\n  urls:\n    - \"https://www.youtube.com/watch?v=abc123\"\n\n  # URL file (one URL per line)\n  url_file: \"urls.txt\"\n</code></pre>"},{"location":"user-guide/configuration/#database","title":"Database","text":"<pre><code>database:\n  url: \"postgresql://postgres:postgres@localhost:5432/data_miner\"\n</code></pre>"},{"location":"user-guide/configuration/#supervisor-worker-counts","title":"Supervisor (Worker Counts)","text":"<pre><code>supervisor:\n  download_workers: 3    # Parallel downloaders\n  extract_workers: 2     # Frame extractors\n  filter_workers: 1      # ML filter workers (GPU-bound)\n  dedup_workers: 1       # Deduplication workers\n  detect_workers: 1      # Detection workers\n</code></pre> <p>Set any worker count to <code>0</code> to disable that stage.</p>"},{"location":"user-guide/configuration/#download-stage","title":"Download Stage","text":"<pre><code>download:\n  output_dir: \"${output_dir}/videos\"\n  format: \"bestvideo[height&lt;=1080]+bestaudio/best[height&lt;=1080]\"\n  max_resolution: 1080\n  timeout: 300\n\n  # Rate limiting (avoid YouTube blocks)\n  sleep_interval: 30         # Min seconds between downloads\n  max_sleep_interval: 60     # Max seconds (randomized)\n  sleep_requests: 10         # Seconds between API requests\n\n  # Hashtag blocklist file\n  blocked_hashtag_patterns: \"blocked_hashtags.txt\"\n</code></pre>"},{"location":"user-guide/configuration/#extract-stage","title":"Extract Stage","text":"<pre><code>extract:\n  output_dir: \"${output_dir}/frames_raw\"\n  strategy: \"interval\"       # interval, time, keyframe\n  interval_frames: 30        # Every N frames\n  interval_seconds: 1.0      # Every N seconds (for time strategy)\n  max_frames_per_video: 5000\n  image_format: \"jpg\"        # jpg, png, webp\n  quality: 95                # JPEG/WebP quality (1-100)\n</code></pre>"},{"location":"user-guide/configuration/#filter-stage-siglip2","title":"Filter Stage (SigLIP2)","text":"<pre><code>filter:\n  output_dir: \"${project_output_dir}/frames_filtered\"\n  device: \"${device}\"\n  model_id: \"siglip2-so400m\"   # siglip2-so400m, siglip2-giant\n  batch_size: 32\n\n  # Thresholds\n  threshold: 0.25              # Min positive match score\n  margin_threshold: 0.05       # Positive must beat negative by this\n\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding door\"\n\n  negative_prompts:\n    - \"a glass wall\"\n    - \"a mirror\"\n</code></pre>"},{"location":"user-guide/configuration/#dedup-stage-faiss","title":"Dedup Stage (FAISS)","text":"<pre><code>dedup:\n  output_dir: \"${project_output_dir}/frames_dedup\"\n  device: \"${device}\"\n  model_type: \"dino\"           # dino, siglip\n  dino_model_id: \"dinov3-base\" # dinov2-base, dinov3-base, etc.\n  threshold: 0.90              # Similarity threshold\n  batch_size: 64\n  k_neighbors: 50              # FAISS KNN search depth\n</code></pre>"},{"location":"user-guide/configuration/#detect-stage","title":"Detect Stage","text":"<pre><code>detect:\n  output_dir: \"${project_output_dir}/detections\"\n  device: \"${device}\"\n  detector: \"grounding_dino\"   # grounding_dino, owlv2, florence2\n  threshold: 0.3\n  confidence_threshold: 0.3\n  batch_size: 16\n  save_visualizations: true\n</code></pre>"},{"location":"user-guide/configuration/#monitor-settings","title":"Monitor Settings","text":"<p>The monitor worker handles:</p> <ul> <li>Project stage transitions (e.g., FILTERING \u2192 DEDUP_READY)</li> <li>Stale lock recovery (resets locks from crashed workers)</li> <li>Frame count aggregation</li> </ul> <pre><code>monitor:\n  poll_interval: 10                   # Seconds between checks\n  stale_threshold_minutes: 2          # Reset stale locks after N minutes\n  long_running_threshold_minutes: 30  # Warn about old locks\n  cleanup_extracted_videos: false     # Delete videos after extraction\n</code></pre>"},{"location":"user-guide/configuration/#backup-settings","title":"Backup Settings","text":"<p>The backup worker syncs <code>frames_raw/</code> to a remote destination after videos are extracted.</p> <pre><code>backup:\n  enabled: false                    # Enable backup worker\n  remote_dest: \"user@host:/path\"    # SSH destination or local path\n  delete_after_backup: false        # Delete local frames after verified backup\n  poll_interval: 300                # Seconds between backup checks\n  verification_timeout: 1800        # Seconds for rsync verification\n</code></pre> <p>Note: Backup uses rsync over SSH. Ensure SSH keys are configured for passwordless access.</p>"},{"location":"user-guide/configuration/#logging-grafana-loki","title":"Logging (Grafana + Loki)","text":"<pre><code>logging:\n  level: \"INFO\"                                        # DEBUG, INFO, WARNING, ERROR\n  loki_url: \"http://localhost:3100/loki/api/v1/push\"   # Loki push endpoint\n  log_dir: \"output/logs\"                               # Local log directory\n</code></pre> <p>Logs are automatically sent to:</p> <ol> <li>Console - Always enabled</li> <li>File - If <code>LOG_FILE</code> env var is set</li> <li>Loki - If <code>python-logging-loki</code> is installed and Loki is running</li> </ol> <p>Access logs in Grafana:</p> <ol> <li>Open <code>http://localhost:3000</code></li> <li>Add Loki data source: <code>http://loki:3100</code></li> <li>Use LogQL queries: <code>{application=\"data_miner\"}</code></li> </ol>"},{"location":"user-guide/configuration/#model-id-reference","title":"Model ID Reference","text":"Stage Model ID Full HuggingFace Path Filter <code>siglip2-so400m</code> <code>google/siglip2-so400m-patch14-384</code> Filter <code>siglip2-giant</code> <code>google/siglip2-giant-opt-patch16-384</code> Dedup <code>dinov3-base</code> <code>facebook/dinov3-vitb16-pretrain-lvd1689m</code> Dedup <code>dinov2-large</code> <code>facebook/dinov2-large</code> Detect <code>grounding_dino</code> <code>IDEA-Research/grounding-dino-base</code> Detect <code>florence2</code> <code>microsoft/Florence-2-large</code>"},{"location":"user-guide/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>CLI Reference - Available commands</li> <li>Quickstart - Run the pipeline</li> </ul>"},{"location":"user-guide/fabric-deployment/","title":"Fabric Deployment Guide","text":"<p>This guide explains how to use Fabric to deploy and manage the Data Miner across distributed machines.</p>"},{"location":"user-guide/fabric-deployment/#prerequisites","title":"Prerequisites","text":"<ol> <li> <p>Install Fabric (included in project dependencies):    <pre><code>uv sync\n</code></pre></p> </li> <li> <p>Configure SSH access to all machines (master and workers)</p> </li> <li> <p>Update <code>docker_configs/cluster.yaml</code> with your machine details</p> </li> </ol>"},{"location":"user-guide/fabric-deployment/#configuration","title":"Configuration","text":"<p>Edit <code>docker_configs/cluster.yaml</code>:</p> <pre><code>cluster:\n  master:\n    host: \"192.168.1.100\"\n    user: \"admin\"\n    key_file: \"~/.ssh/id_rsa\"\n    local_disk: \"/data/seaweed\"\n\n  workers:\n    - host: \"192.168.1.101\"\n      user: \"worker\"\n      key_file: \"~/.ssh/id_rsa\"\n      local_disk: \"/data/seaweed\"\n\nstorage:\n  seaweed_data_dir: \"/data/seaweed\"      # All machines\n  persistent_data_dir: \"/data/data_miner\" # Master only\n</code></pre>"},{"location":"user-guide/fabric-deployment/#deployment-modes","title":"Deployment Modes","text":""},{"location":"user-guide/fabric-deployment/#standalone-single-machine","title":"Standalone (Single Machine)","text":"<p>For development or testing on one machine:</p> <pre><code># Deploy standalone stack\nfab deploy-standalone\n</code></pre>"},{"location":"user-guide/fabric-deployment/#docker-swarm-distributed","title":"Docker Swarm (Distributed)","text":"<p>For production with multiple machines:</p> <pre><code># 1. Initialize swarm on master\nfab swarm-init\n\n# 2. Join all workers to swarm\nfab swarm-join\n\n# 3. Deploy the stack\nfab swarm-deploy\n\n# Optional: Use a registry for images\n# Optional: Use a registry for images\nfab swarm-deploy --registry=myregistry.com:5000\n</code></pre>"},{"location":"user-guide/fabric-deployment/#seaweedfs-only-testing-distributed-storage","title":"SeaweedFS Only (Testing Distributed Storage)","text":"<p>Deploy just SeaweedFS to test distributed storage before full deployment:</p> <pre><code># After swarm-init and swarm-join\nfab swarm-deploy-seaweed\n\n# This deploys only:\n# - seaweed-master (manager node)\n# - seaweed-filer (manager node)  \n# - seaweed-volume (all nodes, global)\n# - seaweed-mount (all nodes, global)\n\n# Check services\ndocker service ls | grep dm-seaweed\n\n# Remove when done\ndocker stack rm dm-seaweed\n</code></pre>"},{"location":"user-guide/fabric-deployment/#common-tasks","title":"Common Tasks","text":""},{"location":"user-guide/fabric-deployment/#check-status","title":"Check Status","text":"<pre><code>fab status              # Swarm and service status\nfab swarm-status        # Detailed swarm info\n</code></pre>"},{"location":"user-guide/fabric-deployment/#view-logs","title":"View Logs","text":"<pre><code>fab logs                           # Download service logs\nfab logs --service=master-workers  # Master workers logs\nfab logs --lines=100               # Last 100 lines\n</code></pre>"},{"location":"user-guide/fabric-deployment/#scale-services","title":"Scale Services","text":"<pre><code>fab swarm-scale --service=download --replicas=30\n</code></pre>"},{"location":"user-guide/fabric-deployment/#stoprestart","title":"Stop/Restart","text":"<pre><code>fab stop                # Stop the swarm stack\nfab swarm-down          # Same as stop\n</code></pre>"},{"location":"user-guide/fabric-deployment/#setup-tasks","title":"Setup Tasks","text":""},{"location":"user-guide/fabric-deployment/#install-docker-on-remote-machines","title":"Install Docker on Remote Machines","text":"<pre><code># Run on a specific host\nfab -H 192.168.1.101 install-docker\nfab -H 192.168.1.101 install-nvidia-docker\n</code></pre>"},{"location":"user-guide/fabric-deployment/#sync-project-files","title":"Sync Project Files","text":"<pre><code>fab -H 192.168.1.100 sync-project\n</code></pre>"},{"location":"user-guide/fabric-deployment/#database-tasks","title":"Database Tasks","text":"<pre><code>fab init-db          # Initialize database schema\nfab populate         # Populate with data sources\nfab pipeline-status  # Check pipeline progress\n</code></pre>"},{"location":"user-guide/fabric-deployment/#swarm-management","title":"Swarm Management","text":""},{"location":"user-guide/fabric-deployment/#build-images-on-all-nodes","title":"Build Images on All Nodes","text":"<p>For registry-less deployments:</p> <pre><code>fab swarm-build-all\n</code></pre>"},{"location":"user-guide/fabric-deployment/#leave-swarm","title":"Leave Swarm","text":"<pre><code>fab swarm-leave-all  # Remove all nodes from swarm\n</code></pre>"},{"location":"user-guide/fabric-deployment/#task-reference","title":"Task Reference","text":"Task Description <code>deploy-standalone</code> Deploy single-machine stack <code>prepare-storage</code> Create storage dirs on all machines <code>swarm-init</code> Initialize Docker Swarm <code>swarm-join</code> Join workers to swarm <code>swarm-deploy</code> Deploy full stack to swarm <code>swarm-deploy-seaweed</code> Deploy SeaweedFS only (testing) <code>swarm-scale</code> Scale a service <code>swarm-status</code> Check swarm status <code>swarm-logs</code> View service logs <code>swarm-down</code> Remove swarm stack <code>swarm-leave-all</code> Leave swarm on all nodes <code>swarm-build-all</code> Build image on all nodes <code>status</code> Alias for swarm-status <code>logs</code> View service logs <code>stop</code> Alias for swarm-down <code>init-db</code> Initialize database <code>populate</code> Run populate command <code>pipeline-status</code> Check pipeline status <code>install-docker</code> Install Docker <code>install-nvidia-docker</code> Install NVIDIA toolkit <code>sync-project</code> Sync project to remote"},{"location":"user-guide/fabric-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/fabric-deployment/#ssh-connection-issues","title":"SSH Connection Issues","text":"<p>Ensure your SSH key is added: <pre><code>ssh-add ~/.ssh/id_rsa\n</code></pre></p>"},{"location":"user-guide/fabric-deployment/#swarm-join-failures","title":"Swarm Join Failures","text":"<p>If a worker fails to join: <pre><code># On the worker machine\ndocker swarm leave --force\n\n# Then retry\nfab swarm-join\n</code></pre></p>"},{"location":"user-guide/fabric-deployment/#image-not-found","title":"Image Not Found","text":"<p>For registry-less deployments, build on all nodes: <pre><code>fab swarm-build-all\n</code></pre></p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers installing Data Miner and its dependencies.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12+</li> <li>PostgreSQL 15+ (local or remote)</li> <li>FFmpeg (for video processing)</li> </ul>"},{"location":"user-guide/installation/#quick-install","title":"Quick Install","text":"<pre><code># Clone repository\ngit clone https://github.com/tycoai/data_miner.git\ncd data_miner\n\n# Install with uv (recommended)\nuv pip install -e .\n\n# Or with pip\npip install -e .\n</code></pre>"},{"location":"user-guide/installation/#postgresql-setup","title":"PostgreSQL Setup","text":""},{"location":"user-guide/installation/#option-1-docker-compose-recommended","title":"Option 1: Docker Compose (Recommended)","text":"<pre><code># Start PostgreSQL container\ndocker compose up -d\n\n# Verify it's running\ndocker compose ps\n</code></pre> <p>The included <code>docker-compose.yaml</code> starts PostgreSQL on port 5432 with default credentials. It also includes:</p> <ul> <li>Loki - Log aggregation at <code>http://localhost:3100</code></li> <li>Grafana - Log visualization at <code>http://localhost:3000</code></li> <li>Adminer - Database admin UI at <code>http://localhost:8880</code></li> </ul> <pre><code># Fix permissions for Loki and Grafana (first time only)\nsudo chown -R 10001:10001 data/loki\nsudo chown -R 472:472 data/grafana\n</code></pre>"},{"location":"user-guide/installation/#option-2-local-postgresql","title":"Option 2: Local PostgreSQL","text":"<pre><code># Create database\ncreatedb data_miner\n\n# Or via psql\npsql -c \"CREATE DATABASE data_miner;\"\n</code></pre>"},{"location":"user-guide/installation/#environment-configuration","title":"Environment Configuration","text":"<p>Copy the example environment file:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> with your settings:</p> <pre><code># Database URL (default works with Docker Compose)\nDATABASE_URL=postgresql://postgres:postgres@localhost:5432/data_miner\n\n# Hugging Face token (optional, for private models)\n# Get from: https://huggingface.co/settings/tokens\nHF_TOKEN=your_token_here\n\n# Debug mode (disables heartbeat - for development only)\n# DATA_MINER_DEBUG=1\n</code></pre>"},{"location":"user-guide/installation/#initialize-database","title":"Initialize Database","text":"<pre><code># Create tables\ndata-miner init-db\n\n# Verify connection\ndata-miner status\n</code></pre>"},{"location":"user-guide/installation/#gpu-setup-optional","title":"GPU Setup (Optional)","text":"<p>For ML inference, ensure CUDA is available:</p> <pre><code># Check CUDA availability\npython -c \"import torch; print(torch.cuda.is_available())\"\n</code></pre> <p>The pipeline automatically falls back to CPU if CUDA is unavailable.</p>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Check CLI is available\ndata-miner --help\n\n# Check database connection\ndata-miner status\n</code></pre>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - Set up your pipeline config</li> <li>Quickstart - Run your first pipeline</li> </ul>"},{"location":"user-guide/quickstart/","title":"Quickstart","text":"<p>This guide walks through running a complete video mining pipeline.</p>"},{"location":"user-guide/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Data Miner installed</li> <li>PostgreSQL running (via Docker Compose or local)</li> <li>Database initialized (<code>data-miner init-db</code>)</li> </ul>"},{"location":"user-guide/quickstart/#step-1-create-configuration","title":"Step 1: Create Configuration","text":"<p>Create a config file <code>config.yaml</code>:</p> <pre><code>project_name: \"glass_doors_demo\"\noutput_dir: \"./output\"\n\ninput:\n  search_queries:\n    - \"glass door installation tutorial\"\n  max_results_per_query: 10  # Start small for testing\n\n# Reduced workers for demo\nsupervisor:\n  download_workers: 2\n  extract_workers: 1\n  filter_workers: 1\n  dedup_workers: 1\n  detect_workers: 1\n\nfilter:\n  threshold: 0.25\n  positive_prompts:\n    - \"a glass door\"\n    - \"a sliding glass door\"\n  negative_prompts:\n    - \"a window\"\n    - \"a mirror\"\n</code></pre>"},{"location":"user-guide/quickstart/#step-2-initialize-database","title":"Step 2: Initialize Database","text":"<pre><code># Create tables (first time only)\ndata-miner init-db\n\n# Verify\ndata-miner status\n</code></pre>"},{"location":"user-guide/quickstart/#step-3-populate-videos","title":"Step 3: Populate Videos","text":"<pre><code># Search YouTube and add videos to database\ndata-miner populate --config config.yaml\n\n# Check status\ndata-miner status --project glass_doors_demo\n</code></pre> <p>Expected output: <pre><code>Project: glass_doors_demo\n  Stage: POPULATING\n  Videos: 10 total\n    PENDING: 10\n</code></pre></p>"},{"location":"user-guide/quickstart/#step-4-setup-workers","title":"Step 4: Setup Workers","text":"<pre><code># Generate supervisor config\ndata-miner workers setup --config config.yaml\n\n# Verify config was created\ncat /etc/supervisor/conf.d/data_miner.conf\n</code></pre>"},{"location":"user-guide/quickstart/#step-5-start-pipeline","title":"Step 5: Start Pipeline","text":"<pre><code># Start all workers\ndata-miner workers start\n\n# Monitor progress\nwatch -n 5 \"data-miner status --project glass_doors_demo\"\n</code></pre>"},{"location":"user-guide/quickstart/#step-6-monitor-progress","title":"Step 6: Monitor Progress","text":"<pre><code># Check worker status\ndata-miner workers status\n\n# Check pipeline status\ndata-miner status --project glass_doors_demo\n</code></pre> <p>As the pipeline progresses, you'll see:</p> <ol> <li>POPULATING \u2192 Videos being downloaded/extracted</li> <li>FILTERING \u2192 Frames being filtered</li> <li>DEDUP_READY \u2192 All videos filtered, cross-dedup starting</li> <li>DETECT_READY \u2192 Dedup complete, detection starting</li> <li>COMPLETE \u2192 Pipeline finished</li> </ol>"},{"location":"user-guide/quickstart/#step-7-view-results","title":"Step 7: View Results","text":"<pre><code># Output directory structure\ntree output/projects/glass_doors_demo/\n</code></pre> <pre><code>output/projects/glass_doors_demo/\n\u251c\u2500\u2500 frames_filtered/     # Frames that passed filter\n\u2502   \u2514\u2500\u2500 {video_id}/\n\u251c\u2500\u2500 frames_dedup/        # Unique frames (flat)\n\u2514\u2500\u2500 detections/\n    \u251c\u2500\u2500 annotations.json # COCO-format annotations\n    \u2514\u2500\u2500 visualizations/  # Bounding box images\n</code></pre>"},{"location":"user-guide/quickstart/#common-workflows","title":"Common Workflows","text":""},{"location":"user-guide/quickstart/#re-run-deduplication","title":"Re-run Deduplication","text":"<pre><code>data-miner force-dedup glass_doors_demo\ndata-miner workers restart\n</code></pre>"},{"location":"user-guide/quickstart/#re-run-detection","title":"Re-run Detection","text":"<pre><code>data-miner force-detect glass_doors_demo\ndata-miner workers restart\n</code></pre>"},{"location":"user-guide/quickstart/#stop-pipeline","title":"Stop Pipeline","text":"<pre><code>data-miner workers stop\n</code></pre>"},{"location":"user-guide/quickstart/#delete-and-start-over","title":"Delete and Start Over","text":"<pre><code>data-miner delete-project glass_doors_demo --files --yes\ndata-miner init-db --force\n</code></pre>"},{"location":"user-guide/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/quickstart/#workers-not-starting","title":"Workers Not Starting","text":"<pre><code># Check supervisor logs\nsudo tail -f /var/log/supervisor/supervisord.log\n\n# Check worker logs\ntail -f output/logs/download_*.log\n</code></pre>"},{"location":"user-guide/quickstart/#videos-stuck","title":"Videos Stuck","text":"<pre><code># Check for stale locks (monitor worker handles this automatically)\ndata-miner status --project glass_doors_demo\n</code></pre>"},{"location":"user-guide/quickstart/#gpu-memory-issues","title":"GPU Memory Issues","text":"<p>Reduce batch size in config:</p> <pre><code>filter:\n  batch_size: 16  # Default: 32\n\ndedup:\n  batch_size: 32  # Default: 64\n</code></pre>"},{"location":"user-guide/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration - All config options</li> <li>Architecture Overview - System design</li> </ul>"}]}